83
15996
Overview of Azure managed disks, which handle the storage accounts for you when using VMs.
https://learn.microsoft.com/en-us/azure/virtual-machines/managed-disks-overview 

>>>
Azure Disk Storage overview - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Introduction to Azure managed disks

Article
06/06/2023

																	13 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Azure managed disks are block-level storage volumes that are managed by Azure and used with Azure Virtual Machines. Managed disks are like a physical disk in an on-premises server but, virtualized. With managed disks, all you have to do is specify the disk size, the disk type, and provision the disk. Once you provision the disk, Azure handles the rest.
The available types of disks are ultra disks, premium solid-state drives (SSD), standard SSDs, and standard hard disk drives (HDD). For information about each individual disk type, see Select a disk type for IaaS VMs.
Benefits of managed disks
Let's go over some of the benefits you gain by using managed disks.
Highly durable and available
Managed disks are designed for 99.999% availability. Managed disks achieve this by providing you with three replicas of your data, allowing for high durability. If one or even two replicas experience issues, the remaining replicas help ensure persistence of your data and high tolerance against failures. This architecture has helped Azure consistently deliver enterprise-grade durability for infrastructure as a service (IaaS) disks, with an industry-leading ZERO% annualized failure rate. Locally redundant storage (LRS) disks provide at least 99.999999999% (11 9's) of durability over a given year and zone-redundant storage (ZRS) disks provide at least 99.9999999999% (12 9's) of durability over a given year.
Simple and scalable VM deployment
Using managed disks, you can create up to 50,000 VM disks of a type in a subscription per region, allowing you to create thousands of VMs in a single subscription. This feature also further increases the scalability of virtual machine scale sets by allowing you to create up to 1,000 VMs in a virtual machine scale set using a Marketplace image.
Integration with availability sets
Managed disks are integrated with availability sets to ensure that the disks of VMs in an availability set are sufficiently isolated from each other to avoid a single point of failure. Disks are automatically placed in different storage scale units (stamps). If a stamp fails due to hardware or software failure, only the VM instances with disks on those stamps fail. For example, let's say you have an application running on five VMs, and the VMs are in an Availability Set. The disks for those VMs won't all be stored in the same stamp, so if one stamp goes down, the other instances of the application continue to run.
Integration with Availability Zones
Managed disks support Availability Zones, which is a high-availability offering that protects your applications from datacenter failures. Availability Zones are unique physical locations within an Azure region. Each zone is made up of one or more datacenters equipped with independent power, cooling, and networking. To ensure resiliency, there's a minimum of three separate zones in all enabled regions. With Availability Zones, Azure offers industry best 99.99% VM uptime SLA.
Azure Backup support
To protect against regional disasters, Azure Backup can be used to create a backup job with time-based backups and backup retention policies. This allows you to perform VM or managed disk restorations at will. Currently Azure Backup supports disk sizes up to 32 tebibyte (TiB) disks. Learn more about Azure VM backup support.
Azure Disk Backup
Azure Backup offers Azure Disk Backup (preview) as a  native, cloud-based backup solution that protects your data in managed disks. It's a simple, secure, and cost-effective solution that enables you to configure protection for managed disks in a few steps. Azure Disk Backup offers a turnkey solution that provides snapshot lifecycle management for managed disks by automating periodic creation of snapshots and retaining it for configured duration using backup policy. For details on Azure Disk Backup, see Overview of Azure Disk Backup.
Granular access control
You can use Azure role-based access control (Azure RBAC) to assign specific permissions for a managed disk to one or more users. Managed disks expose a variety of operations, including read, write (create/update), delete, and retrieving a shared access signature (SAS) URI for the disk. You can grant access to only the operations a person needs to perform their job. For example, if you don't want a person to copy a managed disk to a storage account, you can choose not to grant access to the export action for that managed disk. Similarly, if you don't want a person to use an SAS URI to copy a managed disk, you can choose not to grant that permission to the managed disk.
Upload your vhd
Direct upload makes it easy to transfer your vhd to an Azure managed disk. Previously, you had to follow a more involved process that included staging your data in a storage account. Now, there are fewer steps. It is easier to upload on premises VMs to Azure, upload to large managed disks, and the backup and restore process is simplified. It also reduces cost by allowing you to upload data to managed disks directly without attaching them to VMs. You can use direct upload to upload vhds up to 32 TiB in size.
To learn how to transfer your vhd to Azure, see the CLI or PowerShell articles.
Security
Private Links
Private Link support for managed disks can be used to import or export a managed disk internal to your network. Private Links allow you to generate a time bound Shared Access Signature (SAS) URI for unattached managed disks and snapshots that you can use to export the data to other regions for regional expansion, disaster recovery, and forensic analysis. You can also use the SAS URI to directly upload a VHD to an empty disk from on-premises. Now you can leverage Private Links to restrict the export and import of managed disks so that it can only occur within your Azure virtual network. Private Links allows you to ensure your data only travels within the secure Microsoft backbone network.
To learn how to enable Private Links for importing or exporting a managed disk, see the CLI or Portal articles.
Encryption
Managed disks offer two different kinds of encryption. The first is Server Side Encryption (SSE), which is performed by the storage service. The second one is Azure Disk Encryption (ADE), which you can enable on the OS and data disks for your VMs.
Server-side encryption
Server-side encryption provides encryption-at-rest and safeguards your data to meet your organizational security and compliance commitments. Server-side encryption is enabled by default for all managed disks, snapshots, and images, in all the regions where managed disks are available. (Temporary disks, on the other hand, are not encrypted by server-side encryption unless you enable encryption at host; see Disk Roles: temporary disks).
You can either allow Azure to manage your keys for you, these are platform-managed keys, or you can manage the keys yourself, these are customer-managed keys. Visit the Server-side encryption of Azure Disk Storage article for details.
Azure Disk Encryption
Azure Disk Encryption allows you to encrypt the OS and Data disks used by an IaaS Virtual Machine. This encryption includes managed disks. For Windows, the drives are encrypted using industry-standard BitLocker encryption technology. For Linux, the disks are encrypted using the DM-Crypt technology. The encryption process is integrated with Azure Key Vault to allow you to control and manage the disk encryption keys. For more information, see Azure Disk Encryption for Linux VMs or Azure Disk Encryption for Windows VMs.
Disk roles
There are three main disk roles in Azure: the data disk, the OS disk, and the temporary disk. These roles map to disks that are attached to your virtual machine.
Data disk
A data disk is a managed disk that's attached to a virtual machine to store application data, or other data you need to keep. Data disks are registered as SCSI drives and are labeled with a letter that you choose. Each data disk has a maximum capacity of 32,767 gibibytes (GiB). The size of the virtual machine determines how many data disks you can attach to it and the type of storage you can use to host the disks.
OS disk
Every virtual machine has one attached operating system disk. That OS disk has a pre-installed OS, which was selected when the VM was created. This disk contains the boot volume.
This disk has a maximum capacity of 4,095 GiB, however, many operating systems are partitioned with master boot record (MBR) by default. MBR limits the usable size to 2 TiB. If you need more than 2 TiB, create and attach data disks and use them for data storage. If you need to store data on the OS disk and require the additional space, convert it to GUID Partition Table (GPT). To learn about the differences between MBR and GPT on Windows deployments, see Windows and GPT FAQ.
Temporary disk
Most VMs contain a temporary disk, which is not a managed disk. The temporary disk provides short-term storage for applications and processes, and is intended to only store data such as page files, swap files, or SQL Server tempdb. Data on the temporary disk may be lost during a maintenance event or when you redeploy a VM. During a successful standard reboot of the VM, data on the temporary disk will persist. For more information about VMs without temporary disks, see Azure VM sizes with no local temporary disk.
On Azure Linux VMs, the temporary disk is typically /dev/sdb and on Windows VMs the temporary disk is D: by default. The temporary disk is not encrypted unless (for server side encryption) you enable encryption at host or (for Azure Disk Encryption) with the VolumeType parameter set to All on Windows or EncryptFormatAll on Linux.
Managed disk snapshots
A managed disk snapshot is a read-only crash-consistent full copy of a managed disk that is stored as a standard managed disk by default. With snapshots, you can back up your managed disks at any point in time. These snapshots exist independent of the source disk and can be used to create new managed disks.
Snapshots are billed based on the used size. For example, if you create a snapshot of a managed disk with provisioned capacity of 64 GiB and actual used data size of 10 GiB, that snapshot is billed only for the used data size of 10 GiB. You can see the used size of your snapshots by looking at the Azure usage report. For example, if the used data size of a snapshot is 10 GiB, the daily usage report will show 10 GiB/(31 days) = 0.3226 as the consumed quantity.
To learn more about how to create snapshots for managed disks, see the Create a snapshot of a managed disk article.
Images
Managed disks also support creating a managed custom image. You can create an image from your custom VHD in a storage account or directly from a generalized (sysprepped) VM. This process captures a single image. This image contains all managed disks associated with a VM, including both the OS and data disks. This managed custom image enables creating hundreds of VMs using your custom image without the need to copy or manage any storage accounts.
For information on creating images, see the following articles:
How to capture a managed image of a generalized VM in Azure
How to generalize and capture a Linux virtual machine using the Azure CLI
Images versus snapshots
It's important to understand the difference between images and snapshots. With managed disks, you can take an image of a generalized VM that has been deallocated. This image includes all of the disks attached to the VM. You can use this image to create a VM, and it includes all of the disks.
A snapshot is a copy of a disk at the point in time the snapshot is taken. It applies only to one disk. If you have a VM that has one disk (the OS disk), you can take a snapshot or an image of it and create a VM from either the snapshot or the image.
A snapshot doesn't have awareness of any disk except the one it contains. This makes it problematic to use in scenarios that require the coordination of multiple disks, such as striping. Snapshots would need to be able to coordinate with each other and this is currently not supported.
Disk allocation and performance
The following diagram depicts real-time allocation of bandwidth and IOPS for disks, with three different paths an IO can take:
The first IO path is the uncached managed disk path. This path is taken if you are using a managed disk and set the host caching to none. An IO using this path will execute based on disk-level provisioning and then VM network-level provisioning for IOPs and throughput.
The second IO Path is the cached managed disk path. Cached managed disk IO uses an SSD close to the VM, which has its own own IOPs and throughput provisioned, and is labeled SSD-level provisioning in the diagram. When a cached managed disk initiates a read, the request first checks to see if the data is in the server SSD. If the data isn't present, this created a cached miss and the IO then executes based on SSD-level provisioning, disk-level provisioning and then VM network-level provisioning for IOPs and throughput. When the server SSD initiates reads on cached IO that are present on the server SSD, it creates a cache hit and the IO will then execute based on the SSD-level provisioning. Writes initiated by a cached managed disk always follow the path of a cached-miss, and need to go through SSD-level, disk-level, and VM network-level provisioning.
Finally, the third path is for the local/temp disk. This is available only on VMs that support local/temp disks. An IO using this path will execute based on SSD-Level Provisioning for IOPs and throughput.
As an example of these limitations, a Standard_D2s_v3 VM is prevented from achieving the 5,000 IOPS potential of a P30 disk, whether it is cached or not, because of limits at the SSD and network levels:
Azure uses prioritized network channel for disk traffic, which gets the precedence over other low priority of network traffic. This helps disks maintain their expected performance in case of network contentions. Similarly, Azure Storage handles resource contentions and other issues in the background with automatic load balancing. Azure Storage allocates required resources when you create a disk, and applies proactive and reactive balancing of resources to handle the traffic level. This further ensures disks can sustain their expected IOPS and throughput targets. You can use the VM-level and Disk-level metrics to track the performance and setup alerts as needed.
Refer to our design for high performance article, to learn the best practices for optimizing VM + Disk configurations so that you can achieve your desired performance
Next steps
If you'd like a video going into more detail on managed disks, check out: Better Azure VM Resiliency with Managed Disks.
Learn more about the individual disk types Azure offers, which type is a good fit for your needs, and learn about their performance targets in our article on disk types.
Select a disk type for IaaS VMs
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

25976
Learn about the available Azure disk types for virtual machines, including ultra disks, Premium SSDs v2, Premium SSDs, standard SSDs, and Standard HDDs.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-types 

>>>
Select a disk type for Azure IaaS VMs - managed disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Azure managed disk types

Article
06/13/2023

																	11 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Azure managed disks currently offers five disk types, each intended to address a specific customer scenario:
Ultra disks
Premium SSD v2
Premium SSDs (solid-state drives)
Standard SSDs
Standard HDDs (hard disk drives)
Disk type comparison
The following table provides a comparison of the five disk types to help you decide which to use.
Ultra disk
Premium SSD v2
Premium SSD
Standard SSD
Standard HDD
Disk type
SSD
SSD
SSD
SSD
HDD
Scenario
IO-intensive workloads such as SAP HANA, top tier databases (for example, SQL, Oracle), and other transaction-heavy workloads.
Production and performance-sensitive workloads that consistently require low latency and high IOPS and throughput
Production and performance sensitive workloads
Web servers, lightly used enterprise applications and dev/test
Backup, non-critical, infrequent access
Max disk size
65,536 GiB
65,536 GiB
32,767 GiB
32,767 GiB
32,767 GiB
Max throughput
4,000 MB/s
1,200 MB/s
900 MB/s
750 MB/s
500 MB/s
Max IOPS
160,000
80,000
20,000
6,000
2,000, 3,000*
Usable as OS Disk?
No
No
Yes
Yes
Yes
* Only applies to disks with performance plus (preview) enabled.
For more help deciding which disk type suits your needs, this decision tree should help with typical scenarios:
For a video that covers some high level differences for the different disk types, as well as some ways for determining what impacts your workload requirements, see Block storage options with Azure Disk Storage and Elastic SAN.
Ultra disks
Azure ultra disks are the highest-performing storage option for Azure virtual machines (VMs). You can change the performance parameters of an ultra disk without having to restart your VMs. Ultra disks are suited for data-intensive workloads such as SAP HANA, top-tier databases, and transaction-heavy workloads.
Ultra disks must be used as data disks and can only be created as empty disks. You should use Premium solid-state drives (SSDs) as operating system (OS) disks.
Ultra disk size
Azure ultra disks offer up to 32-TiB per region per subscription by default, but ultra disks support higher capacity by request. To request an increase in capacity, request a quota increase or contact Azure Support.
The following table provides a comparison of disk sizes and performance caps to help you decide which to use.
Disk Size (GiB)
IOPS Cap
Throughput Cap (MB/s)
4
1,200
300
8
2,400
600
16
4,800
1,200
32
9,600
2,400
64
19,200
4,000
128
38,400
4,000
256
76,800
4,000
512
153,600
4,000
1,024-65,536 (sizes in this range increasing in increments of 1 TiB)
160,000
4,000
Ultra disks are designed to provide submillisecond latencies and target IOPS and throughput described in the preceding table 99.99% of the time.
Ultra disk performance
Ultra disks feature a flexible performance configuration model that allows you to independently configure IOPS and throughput  both before and after you provision the disk. Ultra disks come in several fixed sizes, ranging from 4 GiB up to 64 TiB.
Ultra disk IOPS
Ultra disks support IOPS limits of 300 IOPS/GiB, up to a maximum of 160,000 IOPS per disk. To achieve the target IOPS for the disk, ensure that the selected disk IOPS are less than the VM IOPS limit.
The current maximum limit for IOPS for a single VM in generally available sizes is 80,000. Ultra disks with greater IOPS can be used as shared disks to support multiple VMs.
The minimum guaranteed IOPS per disk are 1 IOPS/GiB, with an overall baseline minimum of 100 IOPS. For example, if you provisioned a 4-GiB ultra disk, the minimum IOPS for that disk is 100, instead of four.
For more information about IOPS, see Virtual machine and disk performance.
Ultra disk throughput
The throughput limit of a single ultra disk is 256-kB/s for each provisioned IOPS, up to a maximum of 4000 MB/s per disk (where MB/s = 10^6 Bytes per second). The minimum guaranteed throughput per disk is 4kB/s for each provisioned IOPS, with an overall baseline minimum of 1 MB/s.
You can adjust ultra disk IOPS and throughput performance at runtime without detaching the disk from the virtual machine. After a performance resize operation has been issued on a disk, it can take up to an hour for the change to take effect. Up to four performance resize operations are permitted during a 24-hour window.
It's possible for a performance resize operation to fail because of a lack of performance bandwidth capacity.
Ultra disk limitations
Ultra disks can't be used as OS disks, they can only be created as empty data disks. Ultra disks also can't be used with some features and functionality, including disk export, changing disk type, VM images, availability sets, or Azure disk encryption. The size of an Ultra Disk can't be expanded without either deallocating the VM or detaching the disk. Azure Backup and Azure Site Recovery do not support ultra disks. In addition, only un-cached reads and un-cached writes are supported. Snapshots for ultra disks are available but have additional limitations. See Incremental snapshots of Premium SSD v2 and Ultra Disks for details.
Ultra disks support a 4k physical sector size by default. A 512E sector size is available as a generally available offering with no sign-up required. While most applications are compatible with 4k sector sizes, some require 512 byte sector sizes. Oracle Database, for example, requires release 12.2 or later in order to support 4k native disks. For older versions of Oracle DB, 512 byte sector size is required.
The only infrastructure redundancy options currently available to ultra disks are availability zones. VMs using any other redundancy options cannot attach an ultra disk.
The following table outlines the regions ultra disks are available in, as well as their corresponding availability options.
Note
If a region in the following list lacks availability zones that support ultra disks, then a VM in that region must be deployed without infrastructure redundancy in order to attach an ultra disk.
Redundancy options
Regions
Single VMs
Australia CentralBrazil SouthCentral IndiaEast AsiaGermany West CentralKorea CentralKorea SouthNorth Central US, South Central US, West USUS Gov Arizona, US Gov Texas, US Gov Virginia
One availability zone
Brazil Southeast  Switzerland North  UAE North
Two availability zones
South Africa North  China North 3 France Central Qatar Central  Switzerland North
Three availability zones
Australia EastCanada CentralNorth Europe, West EuropeJapan EastSoutheast AsiaSweden CentralUK SouthCentral US, East US, East US 2, West US 2, West US 3
Not every VM size is available in every supported region with ultra disks. The following table lists VM series which are compatible with ultra disks.
VM Type
Sizes
Description
General purpose
DSv3-series, Ddsv4-series, Dsv4-series, Dasv4-series, Dsv5-series, Ddsv5-series, Dasv5-series
Balanced CPU-to-memory ratio. Ideal for testing and development, small to medium databases, and low to medium traffic web servers.
Compute optimized
FSv2-series
High CPU-to-memory ratio. Good for medium traffic web servers, network appliances, batch processes, and application servers.
Memory optimized
ESv3-series, Easv4-series, Edsv4-series, Esv4-series, Esv5-series, Edsv5-series, Easv5-series, Ebsv5 series, Ebdsv5 series, M-series, Mv2-series, Msv2/Mdsv2-series
High memory-to-CPU ratio. Great for relational database servers, medium to large caches, and in-memory analytics.
Storage optimized
LSv2-series, Lsv3-series, Lasv3-series
High disk throughput and IO ideal for Big Data, SQL, NoSQL databases, data warehousing and large transactional databases.
GPU optimized
NCv2-series, NCv3-series, NCasT4_v3-series, ND-series, NDv2-series, NVv3-series, NVv4-series, NVadsA10 v5-series
Specialized virtual machines targeted for heavy graphic rendering and video editing, as well as model training and inferencing (ND) with deep learning. Available with single or multiple GPUs.
Performance optimized
HB-series, HC-series, HBv2-series
The fastest and most powerful CPU virtual machines with optional high-throughput network interfaces (RDMA).
If you would like to start using ultra disks, see the article on using Azure Ultra Disks.
Premium SSD v2
Premium SSD v2 offers higher performance than Premium SSDs while also generally being less costly. You can individually tweak the performance (capacity, throughput, and IOPS) of Premium SSD v2 disks at any time, allowing workloads to be cost efficient while meeting shifting performance needs. For example, a transaction-intensive database may need a large amount of IOPS at a small size, or a gaming application may need a large amount of IOPS but only during peak hours. Because of this, for most general purpose workloads, Premium SSD v2 can provide the best price performance.
Premium SSD v2 is suited for a broad range of workloads such as SQL server, Oracle, MariaDB, SAP, Cassandra, Mongo DB, big data/analytics, and gaming, on virtual machines or stateful containers.
Premium SSD v2 support a 4k physical sector size by default, but can be configured to use a 512E sector size as well. While most applications are compatible with 4k sector sizes, some require 512 byte sector sizes. Oracle Database, for example, requires release 12.2 or later in order to support 4k native disks. For older versions of Oracle DB, 512 byte sector size is required.
Differences between Premium SSD and Premium SSD v2
Unlike Premium SSDs, Premium SSD v2 doesn't have dedicated sizes. You can set a Premium SSD v2 to any supported size you prefer, and make granular adjustments to the performance without downtime. Premium SSD v2 doesn't support host caching but, benefits significantly from lower latency, which addresses some of the same core problems host caching addresses. The ability to adjust IOPS, throughput, and size at any time also means you can avoid the maintenance overhead of having to stripe disks to meet your needs.
Premium SSD v2 limitations
Premium SSD v2 disks can't be used as an OS disk.
Currently, Premium SSD v2 disks can only be attached to zonal VMs.
Currently, encryption at host isn't supported for Premium SSD v2 disks. You can still attach Premium SSD v2 disks to VMs where you have enabled encryption at host for disk types.
Azure Disk Encryption (guest VM encryption via Bitlocker/DM-Crypt) isn't supported for VMs with Premium SSD v2 disks. We recommend you to use encryption at rest with platform-managed or customer-managed keys, which is supported for Premium SSD v2.
Currently, Premium SSD v2 disks can't be attached to VMs in Availability Sets.
Azure Backup and Azure Site Recovery aren't supported for VMs with Premium SSD v2 disks.
The size of a Premium SSD v2 can't be expanded without either deallocating the VM or detaching the disk.
Regional availability
Currently only available in the following regions:
South Africa North (Three availability zones)
Southeast Asia (Two availability zones)
Canada Central (Three availability zones)
North Europe (Three availability zones)
West Europe (Three availability zones)
Japan East (Two availability zones)
Korea Central (Two availability zones)
Sweden Central (Two availability zone)
Switzerland North (Two availability zones)
UK South (Three availability zones)
Central US (One availability zone)
East US (Three availability zones)
East US 2 (Three availability zones)
South Central US (Three availability zones)
West US 2 (Three availability zones)
West US 3 (Three availability zones)
Premium SSD v2 performance
With Premium SSD v2 disks, you can individually set the capacity, throughput, and IOPS of a disk based on your workload needs, providing you with more flexibility and reduced costs. Each of these values determines the cost of your disk.
Premium SSD v2 capacities
Premium SSD v2 capacities range from 1 GiB to 64 TiBs, in 1-GiB increments. You're billed on a per GiB ratio, see the pricing page for details.
Premium SSD v2 offers up to 32 TiBs per region per subscription by default, but supports higher capacity by request. To request an increase in capacity, request a quota increase or contact Azure Support.
Premium SSD v2 IOPS
All Premium SSD v2 disks have a baseline IOPS of 3000 that is free of charge. After 6 GiB, the maximum IOPS a disk can have increases at a rate of 500 per GiB, up to 80,000 IOPS. So an 8 GiB disk can have up to 4,000 IOPS, and a 10 GiB can have up to 5,000 IOPS. To be able to set 80,000 IOPS on a disk, that disk must have at least 160 GiBs. Increasing your IOPS beyond 3000 increases the price of your disk.
Premium SSD v2 throughput
All Premium SSD v2 disks have a baseline throughput of 125 MB/s that is free of charge. After 6 GiB, the maximum throughput that can be set increases by 0.25 MB/s per set IOPS. If a disk has 3,000 IOPS, the max throughput it can set is 750 MB/s. To raise the throughput for this disk beyond 750 MB/s, its IOPS must be increased. For example, if you increased the IOPS to 4,000, then the max throughput that can be set is 1,000. 1,200 MB/s is the maximum throughput supported for disks that have 5,000 IOPS or more. Increasing your throughput beyond 125 increases the price of your disk.
Premium SSD v2 Sector Sizes
Premium SSD v2 supports a 4k physical sector size by default. A 512E sector size is also supported. While most applications are compatible with 4k sector sizes, some require 512-byte sector sizes. Oracle Database, for example, requires release 12.2 or later in order to support 4k native disks. For older versions of Oracle DB, 512-byte sector size is required.
Summary
The following table provides a comparison of disk capacities and performance maximums to help you decide which to use.
Disk Size
Maximum available IOPS
Maximum available throughput (MB/s)
1 GiB-64 TiBs
3,000-80,000 (Increases by 500 IOPS per GiB)
125-1,200 (increases by 0.25 MB/s per set IOPS)
To deploy a Premium SSD v2, see Deploy a Premium SSD v2.
Premium SSDs
Azure Premium SSDs deliver high-performance and low-latency disk support for virtual machines (VMs) with input/output (IO)-intensive workloads. To take advantage of the speed and performance of Premium SSDs, you can migrate existing VM disks to Premium SSDs. Premium SSDs are suitable for mission-critical production applications, but you can use them only with compatible VM series.
To learn more about individual Azure VM types and sizes for Windows or Linux, including size compatibility for premium storage, see Sizes for virtual machines in Azure. You'll need to check each individual VM size article to determine if it's premium storage-compatible.
Premium SSD size
Premium SSD sizes 
P1
P2
P3
P4
P6
P10
P15
P20
P30
P40
P50
P60
P70
P80
Disk size in GiB
4
8
16
32
64
128
256
512
1,024
2,048
4,096
8,192
16,384
32,767
Base provisioned IOPS per disk
120
120
120
120
240
500
1,100
2,300
5,000
7,500
7,500
16,000
18,000
20,000
**Expanded provisioned IOPS per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
8,000
16,000
20,000
20,000
20,000
20,000
Base provisioned Throughput per disk
25 MB/s
25 MB/s
25 MB/s
25 MB/s
50 MB/s
100 MB/s
125 MB/s
150 MB/s
200 MB/s
250 MB/s
250 MB/s
500 MB/s
750 MB/s
900 MB/s
**Expanded provisioned Throughput per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
300 MB/s
600 MB/s
900 MB/s
900 MB/s
900 MB/s
900 MB/s
Max burst IOPS per disk
3,500
3,500
3,500
3,500
3,500
3,500
3,500
3,500
30,000*
30,000*
30,000*
30,000*
30,000*
30,000*
Max burst throughput per disk
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
Max burst duration
30 min
30 min
30 min
30 min
30 min
30 min
30 min
30 min
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Eligible for reservation
No
No
No
No
No
No
No
No
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
*Applies only to disks with on-demand bursting enabled.
** Only applies to disks with performance plus (preview) enabled.
Capacity, IOPS, and throughput are guaranteed when a premium storage disk is provisioned. For example, if you create a P50 disk, Azure provisions 4,095-GB storage capacity, 7,500 IOPS, and 250-MB/s throughput for that disk. Your application can use all or part of the capacity and performance. Premium SSDs are designed to provide the single-digit millisecond latencies, target IOPS, and throughput described in the preceding table 99.9% of the time.
Premium SSD bursting
Premium SSDs offer disk bursting, which provides better tolerance on unpredictable changes of IO patterns. Disk bursting is especially useful during OS disk boot and for applications with spiky traffic. To learn more about how bursting for Azure disks works, see Disk-level bursting.
Premium SSD transactions
For Premium SSDs, each I/O operation less than or equal to 256 kB of throughput is considered a single I/O operation. I/O operations larger than 256 kB of throughput are considered multiple I/Os of size 256 kB.
Standard SSDs
Azure standard SSDs are optimized for workloads that need consistent performance at lower IOPS levels. They're an especially good choice for customers with varying workloads supported by on-premises hard disk drive (HDD) solutions. Compared to standard HDDs, standard SSDs deliver better availability, consistency, reliability, and latency. Standard SSDs are suitable for web servers, low IOPS application servers, lightly used enterprise applications, and non-production workloads. Like standard HDDs, standard SSDs are available on all Azure VMs.
Standard SSD size
Standard SSD sizes
E1
E2
E3
E4
E6
E10
E15
E20
E30
E40
E50
E60
E70
E80
Disk size in GiB
4
8
16
32
64
128
256
512
1,024
2,048
4,096
8,192
16,384
32,767
Base IOPS per disk
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 2,000
Up to 4,000
Up to 6,000
*Expanded IOPS per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
Up to 1,500
Up to 3,000
Up to 6,000
Up to 6,000
Up to 6,000
Up to 6,000
Base throughput per disk
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 400 MB/s
Up to 600 MB/s
Up to 750 MB/s
*Expanded throughput per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
Up to 150 MB/s
Up to 300 MB/s
Up to 600 MB/s
Up to 750 MB/s
Up to 750 MB/s
Up to 750 MB/s
Max burst IOPS per disk
600
600
600
600
600
600
600
600
1000
Max burst throughput per disk
150 MB/s
150 MB/s
150 MB/s
150 MB/s
150 MB/s
150 MB/s
150 MB/s
150 MB/s
250 MB/s
Max burst duration
30 min
30 min
30 min
30 min
30 min
30 min
30 min
30 min
30 min
* Only applies to disks with performance plus (preview) enabled.
Standard SSDs are designed to provide single-digit millisecond latencies and the IOPS and throughput up to the limits described in the preceding table 99% of the time. Actual IOPS and throughput may vary sometimes depending on the traffic patterns. Standard SSDs provide more consistent performance than the HDD disks with the lower latency.
Standard SSD transactions
For standard SSDs, each I/O operation less than or equal to 256 kB of throughput is considered a single I/O operation. I/O operations larger than 256 kB of throughput are considered multiple I/Os of size 256 kB. These transactions incur a billable cost but, there's an hourly limit on the number of transactions that can incur a billable cost. If that hourly limit is reached, additional transactions during that hour no longer incur a cost. For details, see the blog post.
Standard SSD Bursting
Standard SSDs offer disk bursting, which provides better tolerance for the unpredictable IO pattern changes. OS boot disks and applications prone to traffic spikes will both benefit from disk bursting. To learn more about how bursting for Azure disks works, see Disk-level bursting.
Standard HDDs
Azure standard HDDs deliver reliable, low-cost disk support for VMs running latency-tolerant workloads. With standard storage, your data is stored on HDDs, and performance may vary more widely than that of SSD-based disks. Standard HDDs are designed to deliver write latencies of less than 10 ms and read latencies of less than 20 ms for most IO operations. Actual performance may vary depending on IO size and workload pattern, however. When working with VMs, you can use standard HDD disks for dev/test scenarios and less critical workloads. Standard HDDs are available in all Azure regions and can be used with all Azure VMs.
Standard HDD size
Standard Disk Type
S4
S6
S10
S15
S20
S30
S40
S50
S60
S70
S80
Disk size in GiB
32
64
128
256
512
1,024
2,048
4,096
8,192
16,384
32,767
Base IOPS per disk
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 1,300
Up to 2,000
Up to 2,000
*Expanded IOPS per disk
N/A
N/A
N/A
N/A
N/A
Up to 1,500
Up to 3,000
Up to 3,000
Up to 3,000
Up to 3,000
Up to 3,000
Base throughput per disk
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 300 MB/s
Up to 500 MB/s
Up to 500 MB/s
*Expanded throughput per disk
N/A
N/A
N/A
N/A
N/A
Up to 150 MB/s
Up to 300 MB/s
Up to 500 MB/s
Up to 500 MB/s
Up to 500 MB/s
Up to 500 MB/s
* Only applies to disks with performance plus (preview) enabled.
Standard HDD Transactions
For Standard HDDs, each I/O operation is considered as a single transaction, whatever the I/O size. These transactions have a billing impact.
Billing
When using managed disks, the following billing considerations apply:
Disk type
Managed disk Size
Snapshots
Outbound data transfers
Number of transactions
Managed disk size: Managed disks are billed according to their provisioned size. Azure maps the provisioned size (rounded up) to the nearest offered disk size. For details of the disk sizes offered, see the previous tables. Each disk maps to a supported provisioned disk-size offering and is billed accordingly. For example, if you provisioned a 200-GiB standard SSD, it maps to the disk size offer of E15 (256 GiB). Billing for any provisioned disk is prorated hourly by using the monthly price for the storage offering. For example, you provision an E10 disk and delete it after 20 hours of use. In this case, you're billed for the E10 offering prorated to 20 hours, regardless of the amount of data written to the disk.
Snapshots: Snapshots are billed based on the size used. For example, you create a snapshot of a managed disk with provisioned capacity of 64 GiB and actual used data size of 10 GiB. In this case, the snapshot is billed only for the used data size of 10 GiB.
For more information on snapshots, see the section on snapshots in the managed disk overview.
Outbound data transfers: Outbound data transfers (data going out of Azure data centers) incur billing for bandwidth usage.
Transactions: You're billed for the number of transactions performed on a standard managed disk. For standard SSDs, each I/O operation less than or equal to 256 kB of throughput is considered a single I/O operation. I/O operations larger than 256 kB of throughput are considered multiple I/Os of size 256 kB. For Standard HDDs, each IO operation is considered a single transaction, whatever the I/O size.
For detailed information on pricing for managed disks (including transaction costs), see Managed Disks Pricing.
Ultra disks VM reservation fee
Azure VMs have the capability to indicate if they're compatible with ultra disks. An ultra disk-compatible VM allocates dedicated bandwidth capacity between the compute VM instance and the block storage scale unit to optimize the performance and reduce latency. When you add this capability on the VM, it results in a reservation charge. The reservation charge is only imposed if you enabled ultra disk capability on the VM without an attached ultra disk. When an ultra disk is attached to the ultra disk compatible VM, the reservation charge wouldn't be applied. This charge is per vCPU provisioned on the VM.
Note
For constrained core VM sizes, the reservation fee is based on the actual number of vCPUs and not the constrained cores. For Standard_E32-8s_v3, the reservation fee will be based on 32 cores.
Refer to the Azure Disks pricing page for ultra disk pricing details.
Azure disk reservation
Disk reservation provides you with a discount on the advance purchase of one year's of disk storage, reducing your total cost. When you purchase a disk reservation, you select a specific disk SKU in a target region. For example, you may choose five P30 (1 TiB) Premium SSDs in the Central US region for a one year term. The disk reservation experience is similar to Azure reserved VM instances. You can bundle VM and Disk reservations to maximize your savings. For now, Azure Disks Reservation offers one year commitment plan for Premium SSD SKUs from P30 (1 TiB) to P80 (32 TiB) in all production regions. For more information about reserved disks pricing, see Azure Disks pricing page.
Next steps
See Managed Disks pricing to get started.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4272
Learn about zone-redundant storage and locally redundant storage for Azure managed disks.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-redundancy 

>>>
Redundancy options for Azure managed disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Redundancy options for managed disks

Article
05/05/2023

																	6 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Azure managed disks offer two storage redundancy options, zone-redundant storage (ZRS), and locally redundant storage. ZRS provides higher availability for managed disks than locally redundant storage (LRS) does. However, the write latency for LRS disks is better than ZRS disks because LRS disks synchronously write data to three copies in a single data center.
Locally redundant storage for managed disks
Locally redundant storage (LRS) replicates your data three times within a single data center in the selected region. LRS protects your data against server rack and drive failures. LRS disks provide at least 99.999999999% (11 9's) of durability over a given year. To protect an LRS disk from a zonal failure like a natural disaster or other issues, take the following steps:
Use applications that can synchronously write data to two zones, and automatically failover to another zone during a disaster.
An example would be SQL Server Always On.
Take frequent backups of LRS disks with ZRS snapshots.
Enable cross-zone disaster recovery for LRS disks via Azure Site Recovery. However, cross-zone disaster recovery doesn't provide zero Recovery Point Objective (RPO).
If your workflow doesn't support application-level synchronous writes across zones, or your application must meet zero RPO, then ZRS disks would ideal.
Zone-redundant storage for managed disks
Zone-redundant storage (ZRS) synchronously replicates your Azure managed disk across three Azure availability zones in the region you select. Each availability zone is a separate physical location with independent power, cooling, and networking. ZRS disks provide at least 99.9999999999% (12 9's) of durability over a given year.
A ZRS disk lets you recover from failures in availability zones. If a zone went down, a ZRS disk can be attached to a virtual machine (VM) in a different zone. ZRS disks can also be shared between VMs for improved availability with clustered or distributed applications like SQL FCI, SAP ASCS/SCS, or GFS2. A shared ZRS disk can be attached to primary and secondary VMs in different zones to take advantage of both ZRS and availability zones. If your primary zone fails, you can quickly fail over to the secondary VM using SCSI persistent reservation.
For more information on ZRS disks, see Zone Redundant Storage (ZRS) option for Azure Disks for high availability.
Limitations
ZRS for managed disks is only supported with Premium SSD and Standard SSD managed disks. ZRS for managed disks isn't supported with Premium SSD v2 managed disks.
Regional availability
ZRS disks are currently available in the following regions:
Southeast Asia
Australia East
Brazil South
North Europe
West Europe
France Central
Japan East
Korea Central
Qatar Central
UK South
East US
East US 2
South Central US
West US 2
Billing implications
For details see the Azure pricing page.
Comparison with other disk types
Except for more write latency, disks using ZRS are identical to disks using LRS, they have the same scale targets. Benchmark your disks to simulate the workload of your application and compare the latency between LRS and ZRS disks.
Next steps
To learn how to create a ZRS disk, see Deploy a ZRS managed disk.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

22251
Learn about ultra disks for Azure VMs
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-enable-ultra-ssd 

>>>
Ultra disks for VMs - Azure managed disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Using Azure ultra disks

Article
06/07/2023

																	9 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
This article explains how to deploy and use an ultra disk, for conceptual information about ultra disks, refer to What disk types are available in Azure?.
Azure ultra disks offer high throughput, high IOPS, and consistent low latency disk storage for Azure IaaS virtual machines (VMs). This new offering provides top of the line performance at the same availability levels as our existing disks offerings. One major benefit of ultra disks is the ability to dynamically change the performance of the SSD along with your workloads without the need to restart your VMs. Ultra disks are suited for data-intensive workloads such as SAP HANA, top tier databases, and transaction-heavy workloads.
GA scope and limitations
Ultra disks can't be used as OS disks, they can only be created as empty data disks. Ultra disks also can't be used with some features and functionality, including disk export, changing disk type, VM images, availability sets, or Azure disk encryption. The size of an Ultra Disk can't be expanded without either deallocating the VM or detaching the disk. Azure Backup and Azure Site Recovery do not support ultra disks. In addition, only un-cached reads and un-cached writes are supported. Snapshots for ultra disks are available but have additional limitations. See Incremental snapshots of Premium SSD v2 and Ultra Disks for details.
Ultra disks support a 4k physical sector size by default. A 512E sector size is available as a generally available offering with no sign-up required. While most applications are compatible with 4k sector sizes, some require 512 byte sector sizes. Oracle Database, for example, requires release 12.2 or later in order to support 4k native disks. For older versions of Oracle DB, 512 byte sector size is required.
The only infrastructure redundancy options currently available to ultra disks are availability zones. VMs using any other redundancy options cannot attach an ultra disk.
The following table outlines the regions ultra disks are available in, as well as their corresponding availability options.
Note
If a region in the following list lacks availability zones that support ultra disks, then a VM in that region must be deployed without infrastructure redundancy in order to attach an ultra disk.
Redundancy options
Regions
Single VMs
Australia CentralBrazil SouthCentral IndiaEast AsiaGermany West CentralKorea CentralKorea SouthNorth Central US, South Central US, West USUS Gov Arizona, US Gov Texas, US Gov Virginia
One availability zone
Brazil Southeast  Switzerland North  UAE North
Two availability zones
South Africa North  China North 3 France Central Qatar Central  Switzerland North
Three availability zones
Australia EastCanada CentralNorth Europe, West EuropeJapan EastSoutheast AsiaSweden CentralUK SouthCentral US, East US, East US 2, West US 2, West US 3
Not every VM size is available in every supported region with ultra disks. The following table lists VM series which are compatible with ultra disks.
VM Type
Sizes
Description
General purpose
DSv3-series, Ddsv4-series, Dsv4-series, Dasv4-series, Dsv5-series, Ddsv5-series, Dasv5-series
Balanced CPU-to-memory ratio. Ideal for testing and development, small to medium databases, and low to medium traffic web servers.
Compute optimized
FSv2-series
High CPU-to-memory ratio. Good for medium traffic web servers, network appliances, batch processes, and application servers.
Memory optimized
ESv3-series, Easv4-series, Edsv4-series, Esv4-series, Esv5-series, Edsv5-series, Easv5-series, Ebsv5 series, Ebdsv5 series, M-series, Mv2-series, Msv2/Mdsv2-series
High memory-to-CPU ratio. Great for relational database servers, medium to large caches, and in-memory analytics.
Storage optimized
LSv2-series, Lsv3-series, Lasv3-series
High disk throughput and IO ideal for Big Data, SQL, NoSQL databases, data warehousing and large transactional databases.
GPU optimized
NCv2-series, NCv3-series, NCasT4_v3-series, ND-series, NDv2-series, NVv3-series, NVv4-series, NVadsA10 v5-series
Specialized virtual machines targeted for heavy graphic rendering and video editing, as well as model training and inferencing (ND) with deep learning. Available with single or multiple GPUs.
Performance optimized
HB-series, HC-series, HBv2-series
The fastest and most powerful CPU virtual machines with optional high-throughput network interfaces (RDMA).
Determine VM size and region availability
VMs using availability zones
To leverage ultra disks, you need to determine which availability zone you are in. Not every region supports every VM size with ultra disks. To determine if your region, zone, and VM size support ultra disks, run either of the following commands, make sure to replace the region, vmSize, and subscription values first:
CLI
subscription="<yourSubID>"
# example value is southeastasia
region="<yourLocation>"
# example value is Standard_E64s_v3
vmSize="<yourVMSize>"
az vm list-skus --resource-type virtualMachines  --location $region --query "[?name=='$vmSize'].locationInfo[0].zoneDetails[0].Name" --subscription $subscription
PowerShell
$region = "southeastasia"
$vmSize = "Standard_E64s_v3"
$sku = (Get-AzComputeResourceSku | where {$_.Locations.Contains($region) -and ($_.Name -eq $vmSize) -and $_.LocationInfo[0].ZoneDetails.Count -gt 0})
if($sku){$sku[0].LocationInfo[0].ZoneDetails} Else {Write-host "$vmSize is not supported with Ultra Disk in $region region"}
The response will be similar to the form below, where X is the zone to use for deploying in your chosen region. X could be either 1, 2, or 3.
Preserve the Zones value, it represents your availability zone and you will need it in order to deploy an Ultra disk.
ResourceType
Name
Location
Zones
Restriction
Capability
Value
disks
UltraSSD_LRS
eastus2
X
Note
If there was no response from the command, then the selected VM size is not supported with ultra disks in the selected region.
Now that you know which zone to deploy to, follow the deployment steps in this article to either deploy a VM with an ultra disk attached or attach an ultra disk to an existing VM.
VMs with no redundancy options
Ultra disks deployed in select regions must be deployed without any redundancy options, for now. However, not every disk size that supports ultra disks may be in these regions. To determine which disk sizes support ultra disks, you can use either of the following code snippets. Make sure to replace the vmSize and subscription values first:
subscription="<yourSubID>"
region="westus"
# example value is Standard_E64s_v3
vmSize="<yourVMSize>"
az vm list-skus --resource-type virtualMachines  --location $region --query "[?name=='$vmSize'].capabilities" --subscription $subscription
$region = "westus"
$vmSize = "Standard_E64s_v3"
(Get-AzComputeResourceSku | where {$_.Locations.Contains($region) -and ($_.Name -eq $vmSize) })[0].Capabilities
The response will be similar to the following form, UltraSSDAvailable   True indicates whether the VM size supports ultra disks in this region.
Name                                         Value
----                                         -----
MaxResourceVolumeMB                          884736
OSVhdSizeMB                                  1047552
vCPUs                                        64
HyperVGenerations                            V1,V2
MemoryGB                                     432
MaxDataDiskCount                             32
LowPriorityCapable                           True
PremiumIO                                    True
VMDeploymentTypes                            IaaS
vCPUsAvailable                               64
ACUs                                         160
vCPUsPerCore                                 2
CombinedTempDiskAndCachedIOPS                128000
CombinedTempDiskAndCachedReadBytesPerSecond  1073741824
CombinedTempDiskAndCachedWriteBytesPerSecond 1073741824
CachedDiskBytes                              1717986918400
UncachedDiskIOPS                             80000
UncachedDiskBytesPerSecond                   1258291200
EphemeralOSDiskSupported                     True
AcceleratedNetworkingEnabled                 True
RdmaEnabled                                  False
MaxNetworkInterfaces                         8
UltraSSDAvailable                            True
Deploy an ultra disk using Azure Resource Manager
First, determine the VM size to deploy. For a list of supported VM sizes, see the GA scope and limitations section.
If you would like to create a VM with multiple ultra disks, refer to the sample Create a VM with multiple ultra disks.
If you intend to use your own template, make sure that apiVersion for Microsoft.Compute/virtualMachines and Microsoft.Compute/Disks is set as 2018-06-01 (or later).
Set the disk sku to UltraSSD_LRS, then set the disk capacity, IOPS, availability zone, and throughput in MBps to create an ultra disk.
Once the VM is provisioned, you can partition and format the data disks and configure them for your workloads.
Deploy an ultra disk
Portal
Azure CLI
PowerShell
This section covers deploying a virtual machine equipped with an ultra disk as a data disk. It assumes you have familiarity with deploying a virtual machine, if you do not, see our Quickstart: Create a Windows virtual machine in the Azure portal.
Sign in to the Azure portal and navigate to deploy a virtual machine (VM).
Make sure to choose a supported VM size and region.
Select Availability zone in Availability options.
Fill in the remaining entries with selections of your choice.
Select Disks.
On the Disks blade, select Yes for Enable Ultra Disk compatibility.
Select Create and attach a new disk to attach an ultra disk now.
On the Create a new disk blade, enter a name, then select Change size.
Change the Disk SKU to Ultra Disk.
Change the values of Custom disk size (GiB), Disk IOPS, and Disk throughput to ones of your choice.
Select OK in both blades.
Continue with the VM deployment, it will be the same as you would deploy any other VM.
First, determine the VM size to deploy. See the GA scope and limitations section for a list of supported VM sizes.
You must create a VM that is capable of using ultra disks, in order to attach an ultra disk.
Replace or set the $vmname, $rgname, $diskname, $location, $password, $user variables with your own values. Set $zone  to the value of your availability zone that you got from the start of this article. Then run the following CLI command to create an ultra enabled VM:
az disk create --subscription $subscription -n $diskname -g $rgname --size-gb 1024 --location $location --sku UltraSSD_LRS --disk-iops-read-write 8192 --disk-mbps-read-write 400
az vm create --subscription $subscription -n $vmname -g $rgname --image Win2016Datacenter --ultra-ssd-enabled true --zone $zone --authentication-type password --admin-password $password --admin-username $user --size Standard_D4s_v3 --location $location --attach-data-disks $diskname
First, determine the VM size to deploy. See the GA scope and limitations section for a list of supported VM sizes.
To use ultra disks, you must create a VM that is capable of using ultra disks. Replace or set the $resourcegroup and $vmName variables with your own values. Set $zone to the value of your availability zone that you got from the start of this article. Then run the following New-AzVm command to create an ultra enabled VM:
New-AzVm `
    -ResourceGroupName $resourcegroup `
    -Name $vmName `
    -Location "eastus2" `
    -Image "Win2016Datacenter" `
    -EnableUltraSSD `
    -size "Standard_D4s_v3" `
    -zone $zone
Create and attach the disk
Once your VM has been deployed, you can create and attach an ultra disk to it, use the following script:
# Set parameters and select subscription
$subscription = "<yourSubscriptionID>"
$resourceGroup = "<yourResourceGroup>"
$vmName = "<yourVMName>"
$diskName = "<yourDiskName>"
$lun = 1
Connect-AzAccount -SubscriptionId $subscription
# Create the disk
$diskconfig = New-AzDiskConfig `
-Location 'EastUS2' `
-DiskSizeGB 8 `
-DiskIOPSReadWrite 1000 `
-DiskMBpsReadWrite 100 `
-AccountType UltraSSD_LRS `
-CreateOption Empty `
-zone $zone;
New-AzDisk `
-ResourceGroupName $resourceGroup `
-DiskName $diskName `
-Disk $diskconfig;
# add disk to VM
$vm = Get-AzVM -ResourceGroupName $resourceGroup -Name $vmName
$disk = Get-AzDisk -ResourceGroupName $resourceGroup -Name $diskName
$vm = Add-AzVMDataDisk -VM $vm -Name $diskName -CreateOption Attach -ManagedDiskId $disk.Id -Lun $lun
Update-AzVM -VM $vm -ResourceGroupName $resourceGroup
Deploy an ultra disk - 512 byte sector size
Portal
Azure CLI
PowerShell
Sign in to the Azure portal, then search for and select Disks.
Select + New to create a new disk.
Select a region that supports ultra disks and select an availability zone, fill in the rest of the values as you desire.
Select Change size.
For Disk SKU select Ultra disk, then fill in the values for the desired performance and select OK.
On the Basics blade, select the Advanced tab.
Select 512 for Logical sector size, then select Review + Create.
First, determine the VM size to deploy. See the GA scope and limitations section for a list of supported VM sizes.
You must create a VM that is capable of using ultra disks, in order to attach an ultra disk.
Replace or set the $vmname, $rgname, $diskname, $location, $password, $user variables with your own values. Set $zone  to the value of your availability zone that you got from the start of this article. Then run the following CLI command to  create a VM with an ultra disk that has a 512 byte sector size:
#create an ultra disk with 512 sector size
az disk create --subscription $subscription -n $diskname -g $rgname --size-gb 1024 --location $location --sku UltraSSD_LRS --disk-iops-read-write 8192 --disk-mbps-read-write 400 --logical-sector-size 512
az vm create --subscription $subscription -n $vmname -g $rgname --image Win2016Datacenter --ultra-ssd-enabled true --zone $zone --authentication-type password --admin-password $password --admin-username $user --size Standard_D4s_v3 --location $location --attach-data-disks $diskname
First, determine the VM size to deploy. See the GA scope and limitations section for a list of supported VM sizes.
To use ultra disks, you must create a VM that is capable of using ultra disks. Replace or set the $resourcegroup and $vmName variables with your own values. Set $zone to the value of your availability zone that you got from the start of this article. Then run the following New-AzVm command to create an ultra enabled VM:
New-AzVm `
    -ResourceGroupName $resourcegroup `
    -Name $vmName `
    -Location "eastus2" `
    -Image "Win2016Datacenter" `
    -EnableUltraSSD `
    -size "Standard_D4s_v3" `
    -zone $zone
To create and attach an ultra disk that has a 512 byte sector size, you can use the following script:
# Set parameters and select subscription
$subscription = "<yourSubscriptionID>"
$resourceGroup = "<yourResourceGroup>"
$vmName = "<yourVMName>"
$diskName = "<yourDiskName>"
$lun = 1
Connect-AzAccount -SubscriptionId $subscription
# Create the disk
$diskconfig = New-AzDiskConfig `
-Location 'EastUS2' `
-DiskSizeGB 8 `
-DiskIOPSReadWrite 1000 `
-DiskMBpsReadWrite 100 `
-LogicalSectorSize 512 `
-AccountType UltraSSD_LRS `
-CreateOption Empty `
-zone $zone;
New-AzDisk `
-ResourceGroupName $resourceGroup `
-DiskName $diskName `
-Disk $diskconfig;
# add disk to VM
$vm = Get-AzVM -ResourceGroupName $resourceGroup -Name $vmName
$disk = Get-AzDisk -ResourceGroupName $resourceGroup -Name $diskName
$vm = Add-AzVMDataDisk -VM $vm -Name $diskName -CreateOption Attach -ManagedDiskId $disk.Id -Lun $lun
Update-AzVM -VM $vm -ResourceGroupName $resourceGroup
Attach an ultra disk
Portal
Azure CLI
PowerShell
Alternatively, if your existing VM is in a region/availability zone that is capable of using ultra disks, you can make use of ultra disks without having to create a new VM. By enabling ultra disks on your existing VM, then attaching them as data disks. To enable ultra disk compatibility, you must stop the VM. After you stop the VM, you may enable compatibility, then restart the VM. Once compatibility is enabled you can attach an ultra disk:
Navigate to your VM and stop it, wait for it to deallocate.
Once your VM has been deallocated, select Disks.
Select Additional settings.
Select Yes for Enable Ultra Disk compatibility.
Select Save.
Select Create and attach a new disk and fill in a name for your new disk.
For Storage type select Ultra Disk.
Change the values of Size (GiB), Max IOPS, and Max throughput to ones of your choice.
After you are returned to your disk's blade, select Save.
Start your VM again.
Alternatively, if your existing VM is in a region/availability zone that is capable of using ultra disks, you can make use of ultra disks without having to create a new VM.
Enable ultra disk compatibility on an existing VM - CLI
If your VM meets the requirements outlined in GA scope and limitations and is in the appropriate zone for your account, then you can enable ultra disk compatibility on your VM.
To enable ultra disk compatibility, you must stop the VM. After you stop the VM, you may enable compatibility, then restart the VM. Once compatibility is enabled you can attach an ultra disk:
az vm deallocate -n $vmName -g $rgName
az vm update -n $vmName -g $rgName --ultra-ssd-enabled true
az vm start -n $vmName -g $rgName
Create an ultra disk - CLI
Now that you have a VM that is capable of attaching ultra disks, you can create and attach an ultra disk to it.
location="eastus2"
subscription="xxx"
rgname="ultraRG"
diskname="ssd1"
vmname="ultravm1"
zone=123
#create an ultra disk
az disk create `
--subscription $subscription `
-n $diskname `
-g $rgname `
--size-gb 4 `
--location $location `
--zone $zone `
--sku UltraSSD_LRS `
--disk-iops-read-write 1000 `
--disk-mbps-read-write 50
Attach the disk - CLI
rgName="<yourResourceGroupName>"
vmName="<yourVMName>"
diskName="<yourDiskName>"
subscriptionId="<yourSubscriptionID>"
az vm disk attach -g $rgName --vm-name $vmName --disk $diskName --subscription $subscriptionId
Alternatively, if your existing VM is in a region/availability zone that is capable of using ultra disks, you can make use of ultra disks without having to create a new VM.
Enable ultra disk compatibility on an existing VM - PowerShell
If your VM meets the requirements outlined in GA scope and limitations and is in the appropriate zone for your account, then you can enable ultra disk compatibility on your VM.
To enable ultra disk compatibility, you must stop the VM. After you stop the VM, you may enable compatibility, then restart the VM. Once compatibility is enabled you can attach an ultra disk:
#Stop the VM
Stop-AzVM -Name $vmName -ResourceGroupName $rgName
#Enable ultra disk compatibility
$vm1 = Get-AzVM -name $vmName -ResourceGroupName $rgName
Update-AzVM -ResourceGroupName $rgName -VM $vm1 -UltraSSDEnabled $True
#Start the VM
Start-AzVM -Name $vmName -ResourceGroupName $rgName
Create and attach an ultra disk - PowerShell
Now that you have a VM that is capable of using ultra disks, you can create and attach an ultra disk to it:
# Set parameters and select subscription
$subscription = "<yourSubscriptionID>"
$resourceGroup = "<yourResourceGroup>"
$vmName = "<yourVMName>"
$diskName = "<yourDiskName>"
$lun = 1
Connect-AzAccount -SubscriptionId $subscription
# Create the disk
$diskconfig = New-AzDiskConfig `
-Location 'EastUS2' `
-DiskSizeGB 8 `
-DiskIOPSReadWrite 1000 `
-DiskMBpsReadWrite 100 `
-AccountType UltraSSD_LRS `
-CreateOption Empty `
-zone $zone;
New-AzDisk `
-ResourceGroupName $resourceGroup `
-DiskName $diskName `
-Disk $diskconfig;
# add disk to VM
$vm = Get-AzVM -ResourceGroupName $resourceGroup -Name $vmName
$disk = Get-AzDisk -ResourceGroupName $resourceGroup -Name $diskName
$vm = Add-AzVMDataDisk -VM $vm -Name $diskName -CreateOption Attach -ManagedDiskId $disk.Id -Lun $lun
Update-AzVM -VM $vm -ResourceGroupName $resourceGroup
Adjust the performance of an ultra disk
Portal
Azure CLI
PowerShell
Ultra disks offer a unique capability that allows you to adjust their performance. You can make these adjustments from the Azure portal, on the disks themselves.
Navigate to your VM and select Disks.
Select the ultra disk you'd like to modify the performance of.
Select Size + performance and then make your modifications.
Select Save.
Ultra disks offer a unique capability that allows you to adjust their performance, the following command depicts how to use this feature:
az disk update --subscription $subscription --resource-group $rgname --name $diskName --disk-iops-read-write=5000 --disk-mbps-read-write=200
Adjust the performance of an ultra disk using PowerShell
Ultra disks have a unique capability that allows you to adjust their performance, the following command is an example that adjusts the performance without having to detach the disk:
$diskupdateconfig = New-AzDiskUpdateConfig -DiskMBpsReadWrite 2000
Update-AzDisk -ResourceGroupName $resourceGroup -DiskName $diskName -DiskUpdate $diskupdateconfig
Next steps
Use Azure ultra disks on Azure Kubernetes Service (preview).
Migrate log disk to an ultra disk.
For additional questions on Ultra Disks, see the Ultra Disks section of the FAQ.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

9256
Learn how to deploy a Premium SSD v2.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-deploy-premium-v2 

>>>
Deploy a Premium SSD v2 managed disk - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Deploy a Premium SSD v2

Article
05/11/2023

																	3 contributors
Feedback
In this article
Azure Premium SSD v2 is designed for IO-intense enterprise workloads that require sub-millisecond disk latencies and high IOPS and throughput at a low cost. Premium SSD v2 is suited for a broad range of workloads such as SQL server, Oracle, MariaDB, SAP, Cassandra, Mongo DB, big data/analytics, gaming, on virtual machines or stateful containers. For conceptual information on Premium SSD v2, see Premium SSD v2.
Premium SSD v2 support a 4k physical sector size by default, but can be configured to use a 512E sector size as well. While most applications are compatible with 4k sector sizes, some require 512 byte sector sizes. Oracle Database, for example, requires release 12.2 or later in order to support 4k native disks. For older versions of Oracle DB, 512 byte sector size is required.
Limitations
Premium SSD v2 disks can't be used as an OS disk.
Currently, Premium SSD v2 disks can only be attached to zonal VMs.
Currently, encryption at host isn't supported for Premium SSD v2 disks. You can still attach Premium SSD v2 disks to VMs where you have enabled encryption at host for disk types.
Azure Disk Encryption (guest VM encryption via Bitlocker/DM-Crypt) isn't supported for VMs with Premium SSD v2 disks. We recommend you to use encryption at rest with platform-managed or customer-managed keys, which is supported for Premium SSD v2.
Currently, Premium SSD v2 disks can't be attached to VMs in Availability Sets.
Azure Backup and Azure Site Recovery aren't supported for VMs with Premium SSD v2 disks.
The size of a Premium SSD v2 can't be expanded without either deallocating the VM or detaching the disk.
Regional availability
Currently only available in the following regions:
South Africa North (Three availability zones)
Southeast Asia (Two availability zones)
Canada Central (Three availability zones)
North Europe (Three availability zones)
West Europe (Three availability zones)
Japan East (Two availability zones)
Korea Central (Two availability zones)
Sweden Central (Two availability zone)
Switzerland North (Two availability zones)
UK South (Three availability zones)
Central US (One availability zone)
East US (Three availability zones)
East US 2 (Three availability zones)
South Central US (Three availability zones)
West US 2 (Three availability zones)
West US 3 (Three availability zones)
Prerequisites
Install either the latest Azure CLI or the latest Azure PowerShell module.
Determine region availability programmatically
To use a Premium SSD v2, you need to determine the regions and zones where it's supported. Not every region and zones support Premium SSD v2. To determine regions, and zones support premium SSD v2, replace yourSubscriptionId then run the following command:
Azure CLI
PowerShell
Azure portal
az login
subscriptionId="<yourSubscriptionId>"
az account set --subscription $subscriptionId
az vm list-skus --resource-type disks --query "[?name=='PremiumV2_LRS'].{Region:locationInfo[0].location, Zones:locationInfo[0].zones}"
Connect-AzAccount
$subscriptionId="yourSubscriptionId"
Set-AzContext -Subscription $subscriptionId
Get-AzComputeResourceSku | where {$_.ResourceType -eq 'disks' -and $_.Name -eq 'Premiumv2_LRS'}
To programmatically determine the regions and zones you can deploy to, use either the Azure CLI or Azure PowerShell Module.
Now that you know the region and zone to deploy to, follow the deployment steps in this article to create a Premium SSD v2 disk and attach it to a VM.
Use a Premium SSD v2
Azure CLI
PowerShell
Azure portal
Create a Premium SSD v2 disk in an availability zone. Then create a VM in the same region and availability zone that supports Premium Storage and attach the disk to it. The following script creates a Premium SSD v2 with a 4k sector size, to deploy one with a 512 sector size, update the $logicalSectorSize parameter. Replace the values of all the variables with your own, then run the following script:
## Initialize variables
diskName="yourDiskName"
resourceGroupName="yourResourceGroupName"
region="yourRegionName"
zone="yourZoneNumber"
##Replace 4096 with 512 to deploy a disk with 512 sector size
logicalSectorSize=4096
vmName="yourVMName"
vmImage="Win2016Datacenter"
adminPassword="yourAdminPassword"
adminUserName="yourAdminUserName"
vmSize="Standard_D4s_v3"
## Create a Premium SSD v2 disk
az disk create -n $diskName -g $resourceGroupName \
--size-gb 100 \
--disk-iops-read-write 5000 \
--disk-mbps-read-write 150 \
--location $region \
--zone $zone \
--sku PremiumV2_LRS \
--logical-sector-size $logicalSectorSize
## Create the VM
az vm create -n $vmName -g $resourceGroupName \
--image $vmImage \
--zone $zone \
--authentication-type password --admin-password $adminPassword --admin-username $adminUserName \
--size $vmSize \
--location $region \
--attach-data-disks $diskName
Create a Premium SSD v2 disk in an availability zone. Then create a VM in the same region and availability zone that supports Premium Storage and attach the disk to it. The following script creates a Premium SSD v2 with a 4k sector size, to deploy one with a 512 sector size, update the $logicalSectorSize parameter. Replace the values of all the variables with your own, then run the following script:
# Initialize variables
$resourceGroupName = "yourResourceGroupName"
$region = "useast"
$zone = "yourZoneNumber"
$diskName = "yourDiskName"
$diskSizeInGiB = 100
$diskIOPS = 5000
$diskThroughputInMBPS = 150
#To use a 512 sector size, replace 4096 with 512
$logicalSectorSize=4096
$lun = 1
$vmName = "yourVMName"
$vmImage = "Win2016Datacenter"
$vmSize = "Standard_D4s_v3"
$vmAdminUser = "yourAdminUserName"
$vmAdminPassword = ConvertTo-SecureString "yourAdminUserPassword" -AsPlainText -Force
$credential = New-Object System.Management.Automation.PSCredential ($vmAdminUser, $vmAdminPassword);
# Create a Premium SSD v2
$diskconfig = New-AzDiskConfig `
-Location $region `
-Zone $zone `
-DiskSizeGB $diskSizeInGiB `
-DiskIOPSReadWrite $diskIOPS `
-DiskMBpsReadWrite $diskThroughputInMBPS `
-AccountType PremiumV2_LRS `
-LogicalSectorSize $logicalSectorSize `
-CreateOption Empty
New-AzDisk `
-ResourceGroupName $resourceGroupName `
-DiskName $diskName `
-Disk $diskconfig
# Create the VM
New-AzVm `
    -ResourceGroupName $resourceGroupName `
    -Name $vmName `
    -Location $region `
    -Zone $zone `
    -Image $vmImage `
    -Size $vmSize `
    -Credential $credential
# Attach the disk to the VM
$vm = Get-AzVM -ResourceGroupName $resourceGroupName -Name $vmName
$disk = Get-AzDisk -ResourceGroupName $resourceGroupName -Name $diskName
$vm = Add-AzVMDataDisk -VM $vm -Name $diskName -CreateOption Attach -ManagedDiskId $disk.Id -Lun $lun
Update-AzVM -VM $vm -ResourceGroupName $resourceGroupName
Sign in to the Azure portal.
Navigate to Virtual machines and follow the normal VM creation process.
On the Basics page, select a supported region and set Availability options to Availability zone.
Select one of the zones.
Fill in the rest of the values on the page as you like.
Proceed to the Disks page.
Under Data disks select Create and attach a new disk.
Select the Disk SKU and select Premium SSD v2.
Select whether you'd like to deploy a 4k or 512 logical sector size.
Proceed through the rest of the VM deployment, making any choices that you desire.
You've now deployed a VM with a premium SSD v2.
Adjust disk performance
Unlike other managed disks, the performance of a Premium SSD v2 can be configured independently of its size. For conceptual information on this, see Premium SSD v2 performance.
Azure CLI
PowerShell
Azure portal
The following command changes the performance of your disk, update the values as you like, then run the command:
az disk update --subscription $subscription --resource-group $rgname --name $diskName --disk-iops-read-write=5000 --disk-mbps-read-write=200
The following command changes the performance of your disk, update the values as you like, then run the command:
$diskupdateconfig = New-AzDiskUpdateConfig -DiskMBpsReadWrite 2000
Update-AzDisk -ResourceGroupName $resourceGroup -DiskName $diskName -DiskUpdate $diskupdateconfig
Currently, adjusting disk performance is only supported with Azure CLI or the Azure PowerShell module.
Next steps
Add a data disk using either the Azure portal, CLI, or PowerShell.
Provide feedback on Premium SSD v2.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

14091
Learn how to deploy a managed disk that uses zone-redundant storage (ZRS).
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-deploy-zrs 

>>>
Deploy a ZRS managed disk - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Deploy a managed disk that uses zone-redundant storage

Article
05/05/2023

																	2 contributors
Feedback
In this article
This article covers how to deploy a disk that uses zone-redundant storage (ZRS) as a redundancy option. ZRS replicates your Azure managed disk synchronously across three Azure availability zones in the selected region. Each availability zone is a separate physical location with independent power, cooling, and networking.
For conceptual information on ZRS, see Zone-redundant storage for managed disks
Limitations
ZRS for managed disks is only supported with Premium SSD and Standard SSD managed disks. ZRS for managed disks isn't supported with Premium SSD v2 managed disks.
Regional availability
ZRS disks are currently available in the following regions:
Southeast Asia
Australia East
Brazil South
North Europe
West Europe
France Central
Japan East
Korea Central
Qatar Central
UK South
East US
East US 2
South Central US
West US 2
Azure portal
Azure CLI
Azure PowerShell
Resource Manager Template
Create a VM with a ZRS OS disk
Sign in to the Azure portal.
Navigate to Virtual machines and follow the normal VM creation process.
Select a supported region and set Availability options to No infrastructure redundancy required.
Proceed to the Disks pane.
Select your disk and select one of the ZRS disks in the drop-down.
Proceed through the rest of the VM deployment, making any choices that you desire.
You've now deployed a VM with a ZRS OS disk.
Create a ZRS disk
In the Azure portal, search for and select Disks.
Select + Add to create a new disk.
Select a supported region and Availability zone to None.
Select Change size.
Select one of the available ZRS disks and select OK.
Continue through the deployment process.
You have now created a managed disk that uses ZRS.
Create a VM with ZRS disks
rgName=yourRGName
vmName=yourVMName
location=westus2
vmSize=Standard_DS2_v2
image=UbuntuLTS
osDiskSku=StandardSSD_ZRS
dataDiskSku=Premium_ZRS
az vm create -g $rgName \
-n $vmName \
-l $location \
--image $image \
--size $vmSize \
--generate-ssh-keys \
--data-disk-sizes-gb 128 \
--storage-sku os=$osDiskSku 0=$dataDiskSku
Create VMs with a shared ZRS disk attached to the VMs in different zones
location=westus2
rgName=yourRGName
vmNamePrefix=yourVMNamePrefix
vmSize=Standard_DS2_v2
image=UbuntuLTS
osDiskSku=StandardSSD_LRS
sharedDiskName=yourSharedDiskName
sharedDataDiskSku=Premium_ZRS
az disk create -g $rgName \
-n $sharedDiskName \
-l $location \
--size-gb 1024 \
--sku $sharedDataDiskSku \
--max-shares 2
sharedDiskId=$(az disk show -g $rgName -n $sharedDiskName --query 'id' -o tsv)
az vm create -g $rgName \
-n $vmNamePrefix"01" \
-l $location \
--image $image \
--size $vmSize \
--generate-ssh-keys \
--zone 1 \
--attach-data-disks $sharedDiskId \
--storage-sku os=$osDiskSku \
--vnet-name $vmNamePrefix"_vnet" \
--subnet $vmNamePrefix"_subnet"
az vm create -g $rgName \
-n $vmNamePrefix"02" \
-l $location \
--image $image \
--size $vmSize \
--generate-ssh-keys \
--zone 2 \
--attach-data-disks $sharedDiskId \
--storage-sku os=$osDiskSku \
--vnet-name $vmNamePrefix"_vnet" \
--subnet $vmNamePrefix"_subnet"
Create a Virtual Machine Scale Set with ZRS Disks
location=westus2
rgName=yourRGName
vmssName=yourVMSSName
vmSize=Standard_DS3_V2
image=UbuntuLTS
osDiskSku=StandardSSD_ZRS
dataDiskSku=Premium_ZRS
az vmss create -g $rgName \
-n $vmssName \
--encryption-at-host \
--image UbuntuLTS \
--upgrade-policy automatic \
--generate-ssh-keys \
--data-disk-sizes-gb 128 \
--storage-sku os=$osDiskSku 0=$dataDiskSku
Create a VM with ZRS disks
$subscriptionId="yourSubscriptionId"
$vmLocalAdminUser = "yourAdminUserName"
$vmLocalAdminSecurePassword = ConvertTo-SecureString "yourVMPassword" -AsPlainText -Force
$location = "westus2"
$rgName = "yourResourceGroupName"
$vmName = "yourVMName"
$vmSize = "Standard_DS2_v2"
$osDiskSku = "StandardSSD_ZRS"
$dataDiskSku = "Premium_ZRS"
Connect-AzAccount
Set-AzContext -Subscription $subscriptionId
$subnet = New-AzVirtualNetworkSubnetConfig -Name $($vmName+"_subnet") `
                                           -AddressPrefix "10.0.0.0/24"
$vnet = New-AzVirtualNetwork -Name $($vmName+"_vnet") `
                             -ResourceGroupName $rgName `
                             -Location $location `
                             -AddressPrefix "10.0.0.0/16" `
                             -Subnet $subnet
$nic = New-AzNetworkInterface -Name $($vmName+"_nic") `
                              -ResourceGroupName $rgName `
                              -Location $location `
                              -SubnetId $vnet.Subnets[0].Id
$vm = New-AzVMConfig -VMName $vmName `
                     -VMSize $vmSize
$credential = New-Object System.Management.Automation.PSCredential ($vmLocalAdminUser, $vmLocalAdminSecurePassword);
$vm = Set-AzVMOperatingSystem -VM $vm `
                              -ComputerName $vmName `
                              -Windows `
                              -Credential $credential
$vm = Add-AzVMNetworkInterface -VM $vm -Id $NIC.Id
$vm = Set-AzVMSourceImage -VM $vm `
                          -PublisherName 'MicrosoftWindowsServer' `
                          -Offer 'WindowsServer' `
                          -Skus '2012-R2-Datacenter' `
                          -Version latest
$vm = Set-AzVMOSDisk -VM $vm `
                     -Name $($vmName +"_OSDisk") `
                     -CreateOption FromImage `
                     -StorageAccountType $osDiskSku
$vm = Add-AzVMDataDisk -VM $vm `
                       -Name $($vmName +"_DataDisk1") `
                       -DiskSizeInGB 128 `
                       -StorageAccountType $dataDiskSku `
                       -CreateOption Empty -Lun 0
New-AzVM -ResourceGroupName $rgName `
         -Location $location `
         -VM $vm -Verbose
Create VMs with a shared ZRS disk attached to the VMs in different zones
$location = "westus2"
$rgName = "yourResourceGroupName"
$vmNamePrefix = "yourVMPrefix"
$vmSize = "Standard_DS2_v2"
$sharedDiskName = "yourSharedDiskName"
$sharedDataDiskSku = "Premium_ZRS"
$vmLocalAdminUser = "yourVMAdminUserName"
$vmLocalAdminSecurePassword = ConvertTo-SecureString "yourPassword" -AsPlainText -Force
$datadiskconfig = New-AzDiskConfig -Location $location `
                                   -DiskSizeGB 1024 `
                                   -AccountType $sharedDataDiskSku `
                                   -CreateOption Empty `
                                   -MaxSharesCount 2 `
$sharedDisk=New-AzDisk -ResourceGroupName $rgName `
            -DiskName $sharedDiskName `
            -Disk $datadiskconfig
$credential = New-Object System.Management.Automation.PSCredential ($vmLocalAdminUser, $vmLocalAdminSecurePassword);
$vm1 = New-AzVm `
        -ResourceGroupName $rgName `
        -Name $($vmNamePrefix+"01") `
        -Zone 1 `
        -Location $location `
        -Size $vmSize `
        -VirtualNetworkName $($vmNamePrefix+"_vnet") `
        -SubnetName $($vmNamePrefix+"_subnet") `
        -SecurityGroupName $($vmNamePrefix+"01_sg") `
        -PublicIpAddressName $($vmNamePrefix+"01_ip") `
        -Credential $credential
$vm1 = Add-AzVMDataDisk -VM $vm1 -Name $sharedDiskName -CreateOption Attach -ManagedDiskId $sharedDisk.Id -Lun 0
update-AzVm -VM $vm1 -ResourceGroupName $rgName
$vm2 =  New-AzVm `
        -ResourceGroupName $rgName `
        -Name $($vmNamePrefix+"02") `
        -Zone 2 `
        -Location $location `
        -Size $vmSize `
        -VirtualNetworkName $($vmNamePrefix+"_vnet") `
        -SubnetName ($vmNamePrefix+"_subnet") `
        -SecurityGroupName $($vmNamePrefix+"02_sg") `
        -PublicIpAddressName $($vmNamePrefix+"02_ip") `
        -Credential $credential `
        -OpenPorts 80,3389
$vm2 = Add-AzVMDataDisk -VM $vm1 -Name $sharedDiskName -CreateOption Attach -ManagedDiskId $sharedDisk.Id -Lun 0
update-AzVm -VM $vm1 -ResourceGroupName $rgName
Create a Virtual Machine Scale Set with ZRS Disks
$vmLocalAdminUser = "yourLocalAdminUser"
$vmLocalAdminSecurePassword = ConvertTo-SecureString "yourVMPassword" -AsPlainText -Force
$location = "westus2"
$rgName = "yourResourceGroupName"
$vmScaleSetName = "yourScaleSetName"
$vmSize = "Standard_DS3_v2"
$osDiskSku = "StandardSSD_ZRS"
$dataDiskSku = "Premium_ZRS"
$subnet = New-AzVirtualNetworkSubnetConfig -Name $($vmScaleSetName+"_subnet") `
                                                 -AddressPrefix "10.0.0.0/24"
$vnet = New-AzVirtualNetwork -Name $($vmScaleSetName+"_vnet") `
                             -ResourceGroupName $rgName `
                             -Location $location `
                             -AddressPrefix "10.0.0.0/16" `
                             -Subnet $subnet
$ipConfig = New-AzVmssIpConfig -Name "myIPConfig" `
                               -SubnetId $vnet.Subnets[0].Id
$vmss = New-AzVmssConfig -Location $location `
                         -SkuCapacity 2 `
                         -SkuName $vmSize `
                         -UpgradePolicyMode 'Automatic'
$vmss = Add-AzVmssNetworkInterfaceConfiguration -Name "myVMSSNetworkConfig" `
                                                -VirtualMachineScaleSet $vmss `
                                                -Primary $true `
                                                -IpConfiguration $ipConfig
$vmss = Set-AzVmssStorageProfile $vmss -OsDiskCreateOption "FromImage" `
                                       -ImageReferenceOffer 'WindowsServer' `
                                       -ImageReferenceSku '2012-R2-Datacenter' `
                                       -ImageReferenceVersion latest `
                                       -ImageReferencePublisher 'MicrosoftWindowsServer' `
                                       -ManagedDisk $osDiskSku
$vmss = Set-AzVmssOsProfile $vmss -ComputerNamePrefix $vmScaleSetName `
                                  -AdminUsername $vmLocalAdminUser `
                                  -AdminPassword $vmLocalAdminSecurePassword
$vmss = Add-AzVmssDataDisk -VirtualMachineScaleSet $vmss `
                           -CreateOption Empty `
                           -Lun 1 `
                           -DiskSizeGB 128 `
                           -StorageAccountType $dataDiskSku
New-AzVmss -VirtualMachineScaleSet $vmss `
           -ResourceGroupName $rgName `
           -VMScaleSetName $vmScaleSetName
Use the 2020-12-01 API with your Azure Resource Manager template to create a ZRS disk.
Prerequisites
You must enable the feature for your subscription. Use the following steps to enable the feature for your subscription:
Execute the following command to register the feature for your subscription
 Register-AzProviderFeature -FeatureName "SsdZrsManagedDisks" -ProviderNamespace "Microsoft.Compute"
Confirm that the registration state is Registered (it may take a few minutes) using the following command before trying out the feature.
 Get-AzProviderFeature -FeatureName "SsdZrsManagedDisks" -ProviderNamespace "Microsoft.Compute"
Create a VM with ZRS disks
$vmName = "yourVMName"
$adminUsername = "yourAdminUsername"
$adminPassword = ConvertTo-SecureString "yourAdminPassword" -AsPlainText -Force
$osDiskType = "StandardSSD_ZRS"
$dataDiskType = "Premium_ZRS"
$region = "eastus2euap"
$resourceGroupName = "yourResourceGroupName"
New-AzResourceGroup -Name $resourceGroupName -Location $region
New-AzResourceGroupDeployment -ResourceGroupName $resourceGroupName `
-TemplateUri "https://raw.githubusercontent.com/Azure-Samples/managed-disks-powershell-getting-started/master/ZRSDisks/CreateVMWithZRSDataDisks.json" `
-resourceName $vmName `
-adminUsername $adminUsername `
-adminPassword $adminPassword `
-region $region `
-osDiskType $osDiskType `
-dataDiskType $dataDiskType
Create VMs with a shared ZRS disk attached to the VMs in different zones
$vmNamePrefix = "yourVMNamePrefix"
$adminUsername = "yourAdminUserName"
$adminPassword = ConvertTo-SecureString "yourAdminPassword" -AsPlainText -Force
$osDiskType = "StandardSSD_LRS"
$sharedDataDiskType = "Premium_ZRS"
$region = "eastus2euap"
$resourceGroupName = "zrstesting1"
New-AzResourceGroupDeployment -ResourceGroupName $resourceGroupName `
-TemplateUri "https://raw.githubusercontent.com/Azure-Samples/managed-disks-powershell-getting-started/master/ZRSDisks/CreateVMsWithASharedDisk.json" `
-vmNamePrefix $vmNamePrefix `
-adminUsername $adminUsername `
-adminPassword $adminPassword `
-region $region `
-osDiskType $osDiskType `
-dataDiskType $sharedDataDiskType
Create a Virtual Machine Scale Set with ZRS Disks
$vmssName="yourVMSSName"
$adminUsername="yourAdminName"
$adminPassword=ConvertTo-SecureString "yourAdminPassword" -AsPlainText -Force
$region="eastus2euap"
$osDiskType="StandardSSD_LRS"
$dataDiskType="Premium_ZRS"
New-AzResourceGroupDeployment -ResourceGroupName zrstesting `
-TemplateUri "https://raw.githubusercontent.com/Azure-Samples/managed-disks-powershell-getting-started/master/ZRSDisks/CreateVMSSWithZRSDisks.json" `
-vmssName "yourVMSSName" `
-adminUsername "yourAdminName" `
-adminPassword $password `
-region "eastus2euap" `
-osDiskType "StandardSSD_LRS" `
-dataDiskType "Premium_ZRS" `
Next steps
Check out more Azure Resource Manager templates to create a VM with ZRS disks.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

17756
Learn about sharing Azure managed disks across multiple Linux VMs.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-shared 

>>>
Share an Azure managed disk across VMs - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Share an Azure managed disk

Article
06/19/2023

																	11 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Azure shared disks is a feature for Azure managed disks that allow you to attach a managed disk to multiple virtual machines (VMs) simultaneously. Attaching a managed disk to multiple VMs allows you to either deploy new or migrate existing clustered applications to Azure.
How it works
VMs in the cluster can read or write to their attached disk based on the reservation chosen by the clustered application using SCSI Persistent Reservations (SCSI PR). SCSI PR is an industry standard used by applications running on Storage Area Network (SAN) on-premises. Enabling SCSI PR on a managed disk allows you to migrate these applications to Azure as-is.
Shared managed disks offer shared block storage that can be accessed from multiple VMs, these are exposed as logical unit numbers (LUNs). LUNs are then presented to an initiator (VM) from a target (disk). These LUNs look like direct-attached-storage (DAS) or a local drive to the VM.
Shared managed disks don't natively offer a fully managed file system that can be accessed using SMB/NFS. You need to use a cluster manager, like Windows Server Failover Cluster (WSFC), or Pacemaker, that handles cluster node communication and write locking.
Limitations
General limitations
Shared disks have general limitations that apply to all shared disks, regardless of disk type. As well as additional limitations that only apply to specific types of shared disks. The following list is the list of general limitations:
Currently, only Ultra Disks, Premium SSD v2, Premium SSD, and Standard SSDs can be used as a shared disk
Shared disks can be attached to individual Virtual Machine Scale Sets but can't be defined in the Virtual Machine Scale Set models or automatically deployed
A shared disk can't be expanded without either deallocating all VMs the disk is attached to, or detaching the disk from all of these VMs
Write accelerator isn't supported for shared disks
Host caching isn't supported for shared disks
Each managed disk that has shared disks enabled are also subject to the following limitations, organized by disk type:
Ultra disks
Ultra disks have their own separate list of limitations, unrelated to shared disks. For ultra disk limitations, refer to Using Azure ultra disks.
When sharing ultra disks, they have the following additional limitations:
Only basic disks can be used with some versions of Windows Server Failover Cluster, for details see Failover clustering hardware requirements and storage options.
Can't be shared across availability zones.
Premium SSD v2
Premium SSD v2 managed disks have their own separate list of limitations, unrelated to shared disks. For these limitations, see Premium SSD v2 limitations.
When sharing Premium SSD v2 disks, they have the following additional limitation:
Only basic disks can be used with some versions of Windows Server Failover Cluster, for details see Failover clustering hardware requirements and storage options.
Can't be shared across availability zones.
Premium SSD
Can only be enabled on data disks, not OS disks.
Host caching isn't available for premium SSD disks with maxShares>1.
Disk bursting isn't available for premium SSD disks with maxShares>1.
When using Availability sets or Virtual Machine Scale Sets with Azure shared disks, storage fault domain alignment with virtual machine fault domain isn't enforced for the shared data disk.
When using proximity placement groups (PPG), all virtual machines sharing a disk must be part of the same PPG.
Only basic disks can be used with some versions of Windows Server Failover Cluster, for details see Failover clustering hardware requirements and storage options.
Azure Site Recovery support isn't yet available.
Azure Backup is available through Azure Disk Backup.
Only server-side encryption is supported, Azure Disk Encryption isn't currently supported.
Can only be shared across availability zones if using Zone-redundant storage for managed disks.
Standard SSDs
Can only be enabled on data disks, not OS disks.
Host caching isn't available for standard SSDs with maxShares>1.
When using Availability sets and Virtual Machine Scale Sets with Azure shared disks, storage fault domain alignment with virtual machine fault domain isn't enforced for the shared data disk.
When using proximity placement groups (PPG), all virtual machines sharing a disk must be part of the same PPG.
Only basic disks can be used with some versions of Windows Server Failover Cluster, for details see Failover clustering hardware requirements and storage options.
Azure Site Recovery support isn't yet available.
Azure Backup is available through Azure Disk Backup.
Only server-side encryption is supported, Azure Disk Encryption isn't currently supported.
Can only be shared across availability zones if using Zone-redundant storage for managed disks.
Operating system requirements
Shared disks support several operating systems. See the Windows or Linux sections for the supported operating systems.
Billing implications
When you share a disk, your billing could be impacted in two different ways, depending on the type of disk.
For shared premium SSD disks, in addition to cost of the disk's tier, there's an extra charge that increases with each VM the SSD is mounted to. See managed disks pricing for details.
Ultra disks don't have an extra charge for each VM that they're mounted to. They're billed on the total IOPS and MB/s that the disk is configured for. Normally, an ultra disk has two performance throttles that determine its total IOPS/MB/s. However, when configured as a shared ultra disk, two more performance throttles are exposed, for a total of four. These two additional throttles allow for increased performance at an extra expense and each meter has a default value, which raises the performance and cost of the disk.
The four performance throttles a shared ultra disk has are diskIOPSReadWrite, diskMB/sReadWrite, diskIOPSReadOnly, and diskMB/sReadOnly. Each performance throttle can be configured to change the performance of your disk. The performance for shared ultra disk is calculated in the following ways: total provisioned IOPS (diskIOPSReadWrite + diskIOPSReadOnly) and for total provisioned throughput MB/s (diskMB/sReadWrite + diskMB/sReadOnly).
Once you've determined your total provisioned IOPS and total provisioned throughput, you can use them in the pricing calculator to determine the cost of an ultra shared disk.
Disk sizes
For now, only ultra disks, premium SSD v2, premium SSD, and standard SSDs can enable shared disks. Different disk sizes may have a different maxShares limit, which you can't exceed when setting the maxShares value.
For each disk, you can define a maxShares value that represents the maximum number of nodes that can simultaneously share the disk. For example, if you plan to set up a 2-node failover cluster, you would set maxShares=2. The maximum value is an upper bound. Nodes can join or leave the cluster (mount or unmount the disk) as long as the number of nodes is lower than the specified maxShares value.
Note
The maxShares value can only be set or edited when the disk is detached from all nodes.
Premium SSD ranges
The following table illustrates the allowed maximum values for maxShares by premium SSD sizes:
Disk sizes
maxShares limit
P1,P2,P3,P4,P6,P10,P15,P20
3
P30, P40, P50
5
P60, P70, P80
10
The IOPS and bandwidth limits for a disk aren't affected by the maxShares value. For example, the max IOPS of a P15 disk is 1100 whether maxShares = 1 or maxShares > 1.
Standard SSD ranges
The following table illustrates the allowed maximum values for maxShares by standard SSD sizes:
Disk sizes
maxShares limit
E1,E2,E3,E4,E6,E10,E15,E20
3
E30, E40, E50
5
E60, E70, E80
10
The IOPS and bandwidth limits for a disk aren't affected by the maxShares value. For example, the max IOPS of a E15 disk is 500 whether maxShares = 1 or maxShares > 1.
Ultra disk ranges
The minimum maxShares value is 1, while the maximum maxShares value is 15. There are no size restrictions on ultra disks, any size ultra disk can use any value for maxShares, up to and including the maximum value.
Premium SSD v2 ranges
The minimum maxShares value is 1, while the maximum maxShares value is 15. There are no size restrictions on Premium SSD v2, any size Premium SSD v2 disk can use any value for maxShares, up to and including the maximum value.
Sample workloads
Windows
Azure shared disks are supported on Windows Server 2008 and newer. Most Windows-based clustering builds on WSFC, which handles all core infrastructure for cluster node communication, allowing your applications to take advantage of parallel access patterns. WSFC enables both CSV and non-CSV-based options depending on your version of Windows Server. For details, refer to Create a failover cluster.
Some popular applications running on WSFC include:
Create an FCI with Azure shared disks (SQL Server on Azure VMs)
Migrate your failover cluster instance to SQL Server on Azure VMs with shared disks
Scale-out File Server (SoFS) template
SAP ASCS/SCS template
File Server for General Use (IW workload)
Remote Desktop Server User Profile Disk (RDS UPD)
Linux
Azure shared disks are supported on:
SUSE SLE HA 15 SP1 and above
Ubuntu 18.04 and above
Red Hat Enterprise Linux (RHEL) (support policy)
RHEL 7.9
RHEL 8.3 and above
Oracle Enterprise Linux
Linux clusters can use cluster managers such as Pacemaker. Pacemaker builds on Corosync, enabling cluster communications for applications deployed in highly available environments. Some common clustered filesystems include ocfs2 and gfs2. You can use SCSI Persistent Reservation (SCSI PR) and/or STONITH Block Device (SBD) based clustering models for arbitrating access to the disk. When using SCSI PR, you can manipulate reservations and registrations using utilities such as fence_scsi and sg_persist.
Persistent reservation flow
The following diagram illustrates a sample 2-node clustered database application that uses SCSI PR to enable failover from one node to the other.
The flow is as follows:
The clustered application running on both Azure VM1 and VM2 registers its intent to read or write to the disk.
The application instance on VM1 then takes exclusive reservation to write to the disk.
This reservation is enforced on your Azure disk and the database can now exclusively write to the disk. Any writes from the application instance on VM2 won't succeed.
If the application instance on VM1 goes down, the instance on VM2 can now initiate a database failover and take-over of the disk.
This reservation is now enforced on the Azure disk and the disk will no longer accept writes from VM1. It will only accept writes from VM2.
The clustered application can complete the database failover and serve requests from VM2.
The following diagram illustrates another common clustered workload consisting of multiple nodes reading data from the disk for running parallel processes, such as training of machine learning models.
The flow is as follows:
The clustered application running on all VMs registers the intent to read or write to the disk.
The application instance on VM1 takes an exclusive reservation to write to the disk while opening up reads to the disk from other VMs.
This reservation is enforced on your Azure disk.
All nodes in the cluster can now read from the disk. Only one node writes back results to the disk, on behalf of all nodes in the cluster.
Ultra Disk and Premium SSD v2 reservation flow
Both Ultra disks and Premium SSD v2 managed disks offer two extra throttles, giving each of them a total of four throttles. Due to this, the reservation flow can work as described in the earlier section, or it can throttle and distribute performance more granularly.
Performance throttles
Premium SSD performance throttles
With premium SSD, the disk IOPS and throughput is fixed, for example, IOPS of a P30 is 5000. This value remains whether the disk is shared across 2 VMs or 5 VMs. The disk limits can be reached from a single VM or divided across two or more VMs.
Ultra Disk and Premium SSD v2 performance throttles
Both Ultra Disks and Premium SSD v2 managed disks have the unique capability of allowing you to set your performance by exposing modifiable attributes and allowing you to modify them. By default, there are only two modifiable attributes but, shared Ultra Disks and shared Premium SSD v2 managed disks have two more attributes. Ultra Disks and Premium SSD v2 split these attributes across each attached VM. For some examples on how this distribution of capacity, IOPS, and throughput works, see the Examples section.
Attribute
Description
DiskIOPSReadWrite (Read/write disk IOPS)
The total number of IOPS allowed across all VMs mounting the shared disk with write access.
DiskMB/sReadWrite (Read/write disk throughput)
The total throughput (MB/s) allowed across all VMs mounting the shared disk with write access.
DiskIOPSReadOnly* (Read-only disk IOPS)
The total number of IOPS allowed across all VMs mounting the shared disk as ReadOnly.
DiskMB/sReadOnly* (Read-only disk throughput)
The total throughput (MB/s) allowed across all VMs mounting the shared disk as ReadOnly.
* Applies to shared Ultra Disks and shared Premium SSD v2 managed disks only
The following formulas explain how the performance attributes can be set, since they're user modifiable:
DiskIOPSReadWrite (Read/write disk IOPS):
Has a baseline minimum IOPS of 100, for disks 100 GiB and smaller.
For disks larger than 100 GiB, the baseline minimum IOPS you can set increases by 1 per GiB. So the lowest you can set DiskIOPSReadWrite for a 101 GiB disk is 101 IOPS.
The maximum you can set this attribute is determined by the size of your disk, the formula is 300 * GiB, up to a maximum of 160,000.
DiskMB/sReadWrite (Read/write disk throughput)
The minimum throughput (MB/s) of this attribute is determined by your IOPS, the formula is 4 KiB per second per IOPS. So if you had 101 IOPS, the minimum MB/s you can set is 1.
The maximum you can set this attribute is determined by the amount of IOPS you set, the formula is 256 KiB per second per IOPS, up to a maximum of 4,000 MB/s.
DiskIOPSReadOnly (Read-only disk IOPS)
The minimum baseline IOPS for this attribute is 100. For DiskIOPSReadOnly, the baseline doesn't increase with disk size.
The maximum you can set this attribute is determined by the size of your disk, the formula is 300 * GiB, up to a maximum of 160,000.
DiskMB/sReadOnly (Read-only disk throughput)
The minimum throughput (MB/s) for this attribute is 1. For DiskMB/sReadOnly, the baseline doesn't increase with IOPS.
The maximum you can set this attribute is determined by the amount of IOPS you set, the formula is 256 KiB per second per IOPS, up to a maximum of 4,000 MB/s.
Examples
The following examples depict a few scenarios that show how the throttling can work with shared ultra disks, specifically.
Two nodes cluster using cluster shared volumes
The following is an example of a 2-node WSFC using clustered shared volumes. With this configuration, both VMs have simultaneous write-access to the disk, which results in the ReadWrite throttle being split across the two VMs and the ReadOnly throttle not being used.
Two node cluster without cluster share volumes
The following is an example of a 2-node WSFC that isn't using clustered shared volumes. With this configuration, only one VM has write-access to the disk. This results in the ReadWrite throttle being used exclusively for the primary VM and the ReadOnly throttle only being used by the secondary.
Four node Linux cluster
The following is an example of a 4-node Linux cluster with a single writer and three scale-out readers. With this configuration, only one VM has write-access to the disk. This results in the ReadWrite throttle being used exclusively for the primary VM and the ReadOnly throttle being split by the secondary VMs.
Shared Ultra Disk and Premium SSD v2 pricing
Both shared Ultra Disks and shared Premium SSD v2 managed disks are priced based on provisioned capacity, total provisioned IOPS (diskIOPSReadWrite + diskIOPSReadOnly) and total provisioned Throughput MB/s (diskMB/sReadWrite + diskMB/sReadOnly). There's no extra charge for each additional VM mount. For example, a shared Ultra Disk with the following configuration (diskSizeGB: 1024, DiskIOPSReadWrite: 10000, DiskMB/sReadWrite: 600, DiskIOPSReadOnly: 100, DiskMB/sReadOnly: 1) is charged with 1024 GiB, 10100 IOPS, and 601 MB/s regardless of whether it is mounted to two VMs or five VMs.
Next steps
If you're interested in enabling and using shared disks for your managed disks, proceed to our article Enable shared disk
If you've additional questions, see the shared disks section of the FAQ.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

17498
Configure an Azure managed disk with shared disks so that you can share it across multiple VMs
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-shared-enable 

>>>
Enable shared disks for Azure managed disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Enable shared disk

Article
04/11/2023

																	8 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
This article covers how to enable the shared disks feature for Azure managed disks. Azure shared disks is a new feature for Azure managed disks that enables you to attach a managed disk to multiple virtual machines (VMs) simultaneously. Attaching a managed disk to multiple VMs allows you to either deploy new or migrate existing clustered applications to Azure.
If you are looking for conceptual information on managed disks that have shared disks enabled, see Azure shared disks.
Prerequisites
The scripts and commands in this article require either:
Version 6.0.0 or newer of the Azure PowerShell module.
Or
The latest version of the Azure CLI.
Limitations
General limitations
Shared disks have general limitations that apply to all shared disks, regardless of disk type. As well as additional limitations that only apply to specific types of shared disks. The following list is the list of general limitations:
Currently, only Ultra Disks, Premium SSD v2, Premium SSD, and Standard SSDs can be used as a shared disk
Shared disks can be attached to individual Virtual Machine Scale Sets but can't be defined in the Virtual Machine Scale Set models or automatically deployed
A shared disk can't be expanded without either deallocating all VMs the disk is attached to, or detaching the disk from all of these VMs
Write accelerator isn't supported for shared disks
Host caching isn't supported for shared disks
Each managed disk that has shared disks enabled are also subject to the following limitations, organized by disk type:
Ultra disks
Ultra disks have their own separate list of limitations, unrelated to shared disks. For ultra disk limitations, refer to Using Azure ultra disks.
When sharing ultra disks, they have the following additional limitations:
Only basic disks can be used with some versions of Windows Server Failover Cluster, for details see Failover clustering hardware requirements and storage options.
Can't be shared across availability zones.
Premium SSD v2
Premium SSD v2 managed disks have their own separate list of limitations, unrelated to shared disks. For these limitations, see Premium SSD v2 limitations.
When sharing Premium SSD v2 disks, they have the following additional limitation:
Only basic disks can be used with some versions of Windows Server Failover Cluster, for details see Failover clustering hardware requirements and storage options.
Can't be shared across availability zones.
Premium SSD
Can only be enabled on data disks, not OS disks.
Host caching isn't available for premium SSD disks with maxShares>1.
Disk bursting isn't available for premium SSD disks with maxShares>1.
When using Availability sets or Virtual Machine Scale Sets with Azure shared disks, storage fault domain alignment with virtual machine fault domain isn't enforced for the shared data disk.
When using proximity placement groups (PPG), all virtual machines sharing a disk must be part of the same PPG.
Only basic disks can be used with some versions of Windows Server Failover Cluster, for details see Failover clustering hardware requirements and storage options.
Azure Site Recovery support isn't yet available.
Azure Backup is available through Azure Disk Backup.
Only server-side encryption is supported, Azure Disk Encryption isn't currently supported.
Can only be shared across availability zones if using Zone-redundant storage for managed disks.
Standard SSDs
Can only be enabled on data disks, not OS disks.
Host caching isn't available for standard SSDs with maxShares>1.
When using Availability sets and Virtual Machine Scale Sets with Azure shared disks, storage fault domain alignment with virtual machine fault domain isn't enforced for the shared data disk.
When using proximity placement groups (PPG), all virtual machines sharing a disk must be part of the same PPG.
Only basic disks can be used with some versions of Windows Server Failover Cluster, for details see Failover clustering hardware requirements and storage options.
Azure Site Recovery support isn't yet available.
Azure Backup is available through Azure Disk Backup.
Only server-side encryption is supported, Azure Disk Encryption isn't currently supported.
Can only be shared across availability zones if using Zone-redundant storage for managed disks.
Supported operating systems
Shared disks support several operating systems. See the Windows and Linux sections of the conceptual article for the supported operating systems.
Disk sizes
For now, only ultra disks, premium SSD v2, premium SSD, and standard SSDs can enable shared disks. Different disk sizes may have a different maxShares limit, which you can't exceed when setting the maxShares value.
For each disk, you can define a maxShares value that represents the maximum number of nodes that can simultaneously share the disk. For example, if you plan to set up a 2-node failover cluster, you would set maxShares=2. The maximum value is an upper bound. Nodes can join or leave the cluster (mount or unmount the disk) as long as the number of nodes is lower than the specified maxShares value.
Note
The maxShares value can only be set or edited when the disk is detached from all nodes.
Premium SSD ranges
The following table illustrates the allowed maximum values for maxShares by premium SSD sizes:
Disk sizes
maxShares limit
P1,P2,P3,P4,P6,P10,P15,P20
3
P30, P40, P50
5
P60, P70, P80
10
The IOPS and bandwidth limits for a disk aren't affected by the maxShares value. For example, the max IOPS of a P15 disk is 1100 whether maxShares = 1 or maxShares > 1.
Standard SSD ranges
The following table illustrates the allowed maximum values for maxShares by standard SSD sizes:
Disk sizes
maxShares limit
E1,E2,E3,E4,E6,E10,E15,E20
3
E30, E40, E50
5
E60, E70, E80
10
The IOPS and bandwidth limits for a disk aren't affected by the maxShares value. For example, the max IOPS of a E15 disk is 500 whether maxShares = 1 or maxShares > 1.
Ultra disk ranges
The minimum maxShares value is 1, while the maximum maxShares value is 15. There are no size restrictions on ultra disks, any size ultra disk can use any value for maxShares, up to and including the maximum value.
Premium SSD v2 ranges
The minimum maxShares value is 1, while the maximum maxShares value is 15. There are no size restrictions on Premium SSD v2, any size Premium SSD v2 disk can use any value for maxShares, up to and including the maximum value.
Deploy shared disks
Deploy a premium SSD as a shared disk
To deploy a managed disk with the shared disk feature enabled, use the new property maxShares and define a value greater than 1. This makes the disk shareable across multiple VMs.
Important
Host caching isn't supported for shared disks.
The value of maxShares can only be set or changed when a disk is unmounted from all VMs. See the Disk sizes for the allowed values for maxShares.
Portal
Azure CLI
PowerShell
Resource Manager Template
Sign in to the Azure portal.
Search for and Select Disks.
Select + Create to create a new managed disk.
Fill in the details and select an appropriate region, then select Change size.
Select the premium SSD size and SKU that you want and select OK.
Proceed through the deployment until you get to the Advanced pane.
Select Yes for Enable shared disk and select the amount of Max shares you want.
Select Review + Create.
az disk create -g myResourceGroup -n mySharedDisk --size-gb 1024 -l westcentralus --sku Premium_LRS --max-shares 2
$dataDiskConfig = New-AzDiskConfig -Location 'WestCentralUS' -DiskSizeGB 1024 -AccountType Premium_LRS -CreateOption Empty -MaxSharesCount 2
New-AzDisk -ResourceGroupName 'myResourceGroup' -DiskName 'mySharedDisk' -Disk $dataDiskConfig
Before using the following template, replace [parameters('dataDiskName')], [resourceGroup().location], [parameters('dataDiskSizeGB')], and [parameters('maxShares')] with your own values.
Premium SSD shared disk template
Deploy a standard SSD as a shared disk
To deploy a managed disk with the shared disk feature enabled, use the new property maxShares and define a value greater than 1. This makes the disk shareable across multiple VMs.
Important
Host caching isn't supported for shared disks.
The value of maxShares can only be set or changed when a disk is unmounted from all VMs. See the Disk sizes for the allowed values for maxShares.
Portal
Azure CLI
PowerShell
Resource Manager Template
Sign in to the Azure portal.
Search for and Select Disks.
Select + Create to create a new managed disk.
Fill in the details and select an appropriate region, then select Change size.
Select the standard SSD size and SKU that you want and select OK.
Proceed through the deployment until you get to the Advanced pane.
Select Yes for Enable shared disk and select the amount of Max shares you want.
Select Review + Create.
az disk create -g myResourceGroup -n mySharedDisk --size-gb 1024 -l westcentralus --sku StandardSSD_LRS --max-shares 2
$dataDiskConfig = New-AzDiskConfig -Location 'WestCentralUS' -DiskSizeGB 1024 -AccountType StandardSSD_LRS -CreateOption Empty -MaxSharesCount 2
New-AzDisk -ResourceGroupName 'myResourceGroup' -DiskName 'mySharedDisk' -Disk $dataDiskConfig
Replace the values in this Azure Resource Manager template with your own, before using it:
{
  "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "dataDiskName": {
      "type": "string",
      "defaultValue": "mySharedDisk"
    },
    "dataDiskSizeGB": {
      "type": "int",
      "defaultValue": 1024
    },
    "maxShares": {
      "type": "int",
      "defaultValue": 2
    }
  },
  "resources": [
    {
      "type": "Microsoft.Compute/disks",
      "name": "[parameters('dataDiskName')]",
      "location": "[resourceGroup().location]",
      "apiVersion": "2019-07-01",
      "sku": {
        "name": "StandardSSD_LRS"
      },
      "properties": {
        "creationData": {
          "createOption": "Empty"
        },
        "diskSizeGB": "[parameters('dataDiskSizeGB')]",
        "maxShares": "[parameters('maxShares')]"
      }
    }
  ]
}
Deploy an ultra disk as a shared disk
To deploy a managed disk with the shared disk feature enabled, change the maxShares parameter to a value greater than 1. This makes the disk shareable across multiple VMs.
Important
The value of maxShares can only be set or changed when a disk is unmounted from all VMs. See the Disk sizes for the allowed values for maxShares.
Portal
Azure CLI
PowerShell
Resource Manager Template
Sign in to the Azure portal.
Search for and Select Disks.
Select + Create to create a new managed disk.
Fill in the details, then select Change size.
Select ultra disk for the Disk SKU.
Select the disk size that you want and select OK.
Proceed through the deployment until you get to the Advanced pane.
Select Yes for Enable shared disk and select the amount of Max shares you want.
Select Review + Create.
Regional disk example
#Creating an Ultra shared Disk
az disk create -g rg1 -n clidisk --size-gb 1024 -l westus --sku UltraSSD_LRS --max-shares 5 --disk-iops-read-write 2000 --disk-mbps-read-write 200 --disk-iops-read-only 100 --disk-mbps-read-only 1
#Updating an Ultra shared Disk
az disk update -g rg1 -n clidisk --disk-iops-read-write 3000 --disk-mbps-read-write 300 --set diskIopsReadOnly=100 --set diskMbpsReadOnly=1
#Show shared disk properties:
az disk show -g rg1 -n clidisk
Zonal disk example
This example is almost the same as the previous, except it creates a disk in availability zone 1.
#Creating an Ultra shared Disk
az disk create -g rg1 -n clidisk --size-gb 1024 -l westus --sku UltraSSD_LRS --max-shares 5 --disk-iops-read-write 2000 --disk-mbps-read-write 200 --disk-iops-read-only 100 --disk-mbps-read-only 1 --zone 1
#Updating an Ultra shared Disk
az disk update -g rg1 -n clidisk --disk-iops-read-write 3000 --disk-mbps-read-write 300 --set diskIopsReadOnly=100 --set diskMbpsReadOnly=1
#Show shared disk properties:
az disk show -g rg1 -n clidisk
Regional disk example
$datadiskconfig = New-AzDiskConfig -Location 'WestCentralUS' -DiskSizeGB 1024 -AccountType UltraSSD_LRS -CreateOption Empty -DiskIOPSReadWrite 2000 -DiskMBpsReadWrite 200 -DiskIOPSReadOnly 100 -DiskMBpsReadOnly 1 -MaxSharesCount 5
New-AzDisk -ResourceGroupName 'myResourceGroup' -DiskName 'mySharedDisk' -Disk $datadiskconfig
Zonal disk example
This example is almost the same as the previous, except it creates a disk in availability zone 1.
$datadiskconfig = New-AzDiskConfig -Location 'WestCentralUS' -DiskSizeGB 1024 -AccountType UltraSSD_LRS -CreateOption Empty -DiskIOPSReadWrite 2000 -DiskMBpsReadWrite 200 -DiskIOPSReadOnly 100 -DiskMBpsReadOnly 1 -MaxSharesCount 5 -Zone 1
New-AzDisk -ResourceGroupName 'myResourceGroup' -DiskName 'mySharedDisk' -Disk $datadiskconfig
Regional disk example
Before using the following template, replace [parameters('dataDiskName')], [resourceGroup().location], [parameters('dataDiskSizeGB')], [parameters('maxShares')], [parameters('diskIOPSReadWrite')], [parameters('diskMBpsReadWrite')], [parameters('diskIOPSReadOnly')], and [parameters('diskMBpsReadOnly')] with your own values.
Regional shared ultra disks template
Zonal disk example
Before using the following template, replace [parameters('dataDiskName')], [resourceGroup().location], [parameters('dataDiskSizeGB')], [parameters('maxShares')], [parameters('diskIOPSReadWrite')], [parameters('diskMBpsReadWrite')], [parameters('diskIOPSReadOnly')], and [parameters('diskMBpsReadOnly')] with your own values.
Zonal shared ultra disks template
Share an existing disk
To share an existing disk, or update how many VMs it can mount to, set the maxShares parameter with either the Azure PowerShell module or Azure CLI. You can also set maxShares to 1, if you want to disable sharing.
Important
Host caching isn't supported for shared disks.
The value of maxShares can only be set or changed when a disk is unmounted from all VMs. See the Disk sizes for the allowed values for maxShares.
Before detaching a disk, record the LUN ID for when you re-attach it.
PowerShell
$datadiskconfig = Get-AzDisk -DiskName "mySharedDisk"
$datadiskconfig.maxShares = 3
Update-AzDisk -ResourceGroupName 'myResourceGroup' -DiskName 'mySharedDisk' -Disk $datadiskconfig
CLI
#Modifying a disk to enable or modify sharing configuration
az disk update --name mySharedDisk --max-shares 5 --resource-group myResourceGroup
Using Azure shared disks with your VMs
Once you've deployed a shared disk with maxShares>1, you can mount the disk to one or more of your VMs.
Note
Host caching isn't supported for shared disks.
If you are deploying an ultra disk, make sure it matches the necessary requirements. See Using Azure ultra disks for details.
$resourceGroup = "myResourceGroup"
$location = "WestCentralUS"
$vm = New-AzVm -ResourceGroupName $resourceGroup -Name "myVM" -Location $location -VirtualNetworkName "myVnet" -SubnetName "mySubnet" -SecurityGroupName "myNetworkSecurityGroup" -PublicIpAddressName "myPublicIpAddress"
$dataDisk = Get-AzDisk -ResourceGroupName $resourceGroup -DiskName "mySharedDisk"
$vm = Add-AzVMDataDisk -VM $vm -Name "mySharedDisk" -CreateOption Attach -ManagedDiskId $dataDisk.Id -Lun 0
update-AzVm -VM $vm -ResourceGroupName $resourceGroup
Supported SCSI PR commands
Once you've mounted the shared disk to your VMs in your cluster, you can establish quorum and read/write to the disk using SCSI PR. The following PR commands are available when using Azure shared disks:
To interact with the disk, start with the persistent-reservation-action list:
PR_REGISTER_KEY
PR_REGISTER_AND_IGNORE
PR_GET_CONFIGURATION
PR_RESERVE
PR_PREEMPT_RESERVATION
PR_CLEAR_RESERVATION
PR_RELEASE_RESERVATION
When using PR_RESERVE, PR_PREEMPT_RESERVATION, or  PR_RELEASE_RESERVATION, provide one of the following persistent-reservation-type:
PR_NONE
PR_WRITE_EXCLUSIVE
PR_EXCLUSIVE_ACCESS
PR_WRITE_EXCLUSIVE_REGISTRANTS_ONLY
PR_EXCLUSIVE_ACCESS_REGISTRANTS_ONLY
PR_WRITE_EXCLUSIVE_ALL_REGISTRANTS
PR_EXCLUSIVE_ACCESS_ALL_REGISTRANTS
You also need to provide a persistent-reservation-key when using PR_RESERVE, PR_REGISTER_AND_IGNORE, PR_REGISTER_KEY, PR_PREEMPT_RESERVATION, PR_CLEAR_RESERVATION, or PR_RELEASE-RESERVATION.
Next steps
If you prefer to use Azure Resource Manager templates to deploy your disk, the following sample templates are available:
Premium SSD
Regional ultra disks
Zonal ultra disks
If you've additional questions, see the shared disks section of the FAQ.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4977
Increase the performance of Azure Premium SSDs and Standard SSD/HDDs using performance plus.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-enable-performance 

>>>
Preview - Increase performance of Premium SSDs and Standard SSD/HDDs - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Preview - Increase IOPS and throughput limits for Azure Premium SSDs and Standard SSD/HDDs

Article
04/04/2023

																	3 contributors
Feedback
In this article
The Input/Output Operations Per Second (IOPS) and throughput limits for Azure Premium solid-state drives (SSD), Standard SSDs, and Standard hard disk drives (HDD) that are 513 GiB and larger can be increased by enabling performance plus. Enabling performance plus (preview) improves the experience for workloads that require high IOPS and throughput, such as database and transactional workloads. There's no extra charge for enabling performance plus on a disk.
Once enabled, the IOPS and throughput limits for an eligible disk increase to the higher maximum limits. To see the new IOPS and throughput limits for eligible disks, consult the columns that begin with "*Expanded" in the Scalability and performance targets for VM disks article.
Limitations
Can only be enabled on Standard HDD, Standard SSD, and Premium SSD managed disks that are 513 GiB or larger.
Can only be enabled on new disks.
To work around this, create a snapshot of your disk, then create a new disk from the snapshot.
Not supported for disks recovered with Azure Site Recovery or Azure Backup.
Can't be enabled in the Azure portal.
Prerequisites
Either use the Azure Cloud Shell to run your commands or install a version of the Azure PowerShell module 9.5 or newer, or a version of the Azure CLI that is 2.44.0 or newer.
Enable performance plus
You need to create a new disk to use performance plus. The following script creates a disk that has performance plus enabled and attach it to a VM:
Azure CLI
Azure PowerShell
myRG=yourResourceGroupName
myDisk=yourDiskName
myVM=yourVMName
region=desiredRegion
# Valid values are Premium_LRS, Premium_ZRS, StandardSSD_LRS, StandardSSD_ZRS, or Standard_LRS
sku=desiredSKU
#Size must be 513 or larger
size=513
az disk create -g $myRG -n $myDisk --size-gb $size --sku $sku -l $region –performance-plus true
az vm disk attach --vm-name $myVM --name $myDisk --resource-group $myRG
To migrate data from an existing disk or snapshot to a new disk with performance plus enabled, use the following script:
myRG=yourResourceGroupName
myDisk=yourDiskName
myVM=yourVMName
region=desiredRegion
# Valid values are Premium_LRS, Premium_ZRS, StandardSSD_LRS, StandardSSD_ZRS, or Standard_LRS
sku=desiredSKU
#Size must be 513 or larger
size=513
sourceURI=yourDiskOrSnapshotURI
az disk create --name $myDisk --resource-group $myRG --size-gb $size -- --performance-plus true --sku $sku --source $sourceURI --location $region
You need to create a new disk to use performance plus. The following script creates a disk that has performance plus enabled and attach it to a VM:
$myRG=yourResourceGroupName
$myDisk=yourDiskName
$myVM=yourVMName
$region=desiredRegion
# Valid values are Premium_LRS, Premium_ZRS, StandardSSD_LRS, StandardSSD_ZRS, or Standard_LRS
$sku=desiredSKU
#Size must be 513 or larger
$size=513
Set-AzContext -SubscriptionName <yourSubscriptionName>
$diskConfig = New-AzDiskConfig -Location $region -CreateOption Empty -DiskSizeGB $size -SkuName $sku -PerformancePlus $true
$dataDisk = New-AzDisk -ResourceGroupName $myRG -DiskName $myDisk -Disk $diskConfig
To migrate data from an existing disk or snapshot to a new disk with performance plus enabled, use the following script:
$myDisk=yourDiskOrSnapshotName
$myVM=yourVMName
$region=desiredRegion
# Valid values are Premium_LRS, Premium_ZRS, StandardSSD_LRS, StandardSSD_ZRS, or Standard_LRS
$sku=desiredSKU
#Size must be 513 or larger
$size=513
$sourceURI=diskOrSnapshotURI
Set-AzContext -SubscriptionName <<yourSubscriptionName>>
$diskConfig = New-AzDiskConfig -Location $region -CreateOption Copy -DiskSizeGB $size -SkuName $sku -PerformancePlus $true -SourceResourceID $sourceURI
$dataDisk = New-AzDisk -ResourceGroupName $myRG  -DiskName $myDisk -Disk $diskconfig
Next steps
Create an incremental snapshot for managed disks
Expand virtual hard disks on a Linux VM
How to expand virtual hard disks attached to a Windows virtual machine
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

8856
Learn more about how virtual machines and their attached disks work in combination for performance.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-performance 

>>>
Virtual machine and disk performance - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Virtual machine and disk performance

Article
05/31/2023

																	3 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
This article helps clarify disk performance and how it works when you combine Azure Virtual Machines and Azure disks. It also describes how you can diagnose bottlenecks for your disk IO and the changes you can make to optimize for performance.
How does disk performance work?
Azure virtual machines have input/output operations per second (IOPS) and throughput performance limits based on the virtual machine type and size. OS disks and data disks can be attached to virtual machines. The disks have their own IOPS and throughput limits.
Your application's performance gets capped when it requests more IOPS or throughput than what is allotted for the virtual machines or attached disks. When capped, the application experiences suboptimal performance. This can lead to negative consequences like increased latency. Let's run through a couple of examples to clarify this concept. To make these examples easy to follow, we'll only look at IOPS. But, the same logic applies to throughput.
Disk IO capping
Setup:
Standard_D8s_v3
Uncached IOPS: 12,800
E30 OS disk
IOPS: 500
Two E30 data disks × 2
IOPS: 500
The application running on the virtual machine makes a request that requires 10,000 IOPS to the virtual machine. All of which are allowed by the VM because the Standard_D8s_v3 virtual machine can execute up to 12,800 IOPS.
The 10,000 IOPS requests are broken down into three different requests to the different disks:
1,000 IOPS are requested to the operating system disk.
4,500 IOPS are requested to each data disk.
All attached disks are E30 disks and can only handle 500 IOPS. So, they respond back with 500 IOPS each. The application's performance is capped by the attached disks, and it can only process 1,500 IOPS. The application could work at peak performance at 10,000 IOPS if better-performing disks are used, such as Premium SSD P30 disks.
Virtual machine IO capping
Setup:
Standard_D8s_v3
Uncached IOPS: 12,800
P30 OS disk
IOPS: 5,000
Two P30 data disks × 2
IOPS: 5,000
The application running on the virtual machine makes a request that requires 15,000 IOPS. Unfortunately, the Standard_D8s_v3 virtual machine is only provisioned to handle 12,800 IOPS. The application is capped by the virtual machine limits and must allocate the allotted 12,800 IOPS.
Those 12,800 IOPS requested are broken down into three different requests to the different disks:
4,267 IOPS are requested to the operating system disk.
4,266 IOPS are requested to each data disk.
All attached disks are P30 disks that can handle 5,000 IOPS. So, they respond back with their requested amounts.
Virtual machine uncached vs cached limits
Virtual machines that are enabled for both premium storage and premium storage caching have two different storage bandwidth limits. Let's look at the Standard_D8s_v3 virtual machine as an example. Here is the documentation on the Dsv3-series and the Standard_D8s_v3:
The max uncached disk throughput is the default storage maximum limit that the virtual machine can handle.
The max cached storage throughput limit is a separate limit when you enable host caching.
Host caching works by bringing storage closer to the VM that can be written or read to quickly. The amount of storage that is available to the VM for host caching is in the documentation. For example, you can see the Standard_D8s_v3 comes with 200 GiB of cache storage.
You can enable host caching when you create your virtual machine and attach disks. You can also turn on and off host caching on your disks on an existing VM. By default, cache-capable data disks will have read-only caching enabled. Cache-capable OS disks will have read/write caching enabled.
You can adjust the host caching to match your workload requirements for each disk. You can set your host caching to be:
Read-only: For workloads that only do read operations
Read/write: For workloads that do a balance of read and write operations
If your workload doesn't follow either of these patterns, we don't recommend that you use host caching.
Let's run through a couple examples of different host cache settings to see how it affects the data flow and performance. In this first example, we'll look at what happens with IO requests when the host caching setting is set to Read-only.
Setup:
Standard_D8s_v3
Cached IOPS: 16,000
Uncached IOPS: 12,800
P30 data disk
IOPS: 5,000
Host caching: Read-only
When a read is performed and the desired data is available on the cache, the cache returns the requested data. There is no need to read from the disk. This read is counted toward the VM's cached limits.
When a read is performed and the desired data is not available on the cache, the read request is relayed to the disk. Then the disk surfaces it to both the cache and the VM. This read is counted toward both the VM's uncached limit and the VM's cached limit.
When a write is performed, the write has to be written to both the cache and the disk before it is considered complete. This write is counted toward the VM's uncached limit and the VM's cached limit.
Next let's look at what happens with IO requests when the host cache setting is set to Read/write.
Setup:
Standard_D8s_v3
Cached IOPS: 16,000
Uncached IOPS: 12,800
P30 data disk
IOPS: 5,000
Host caching: Read/write
A read is handled the same way as a read-only. Writes are the only thing that's different with read/write caching. When writing with host caching is set to Read/write, the write only needs to be written to the host cache to be considered complete. The write is then lazily written to the disk when the cache is flushed periodically. Customers can additionally force a flush by issuing an f/sync or fua command. This means that a write is counted toward cached IO when it is written to the cache. When it is lazily written to the disk, it counts toward the uncached IO.
Let’s continue with our Standard_D8s_v3 virtual machine. Except this time, we'll enable host caching on the disks. This makes the VM's IOPS limit 16,000 IOPS. Attached to the VM are three underlying P30 disks that can each handle 5,000 IOPS.
Setup:
Standard_D8s_v3
Cached IOPS: 16,000
Uncached IOPS: 12,800
P30 OS disk
IOPS: 5,000
Host caching: Read/write
Two P30 data disks × 2
IOPS: 5,000
Host caching: Read/write
The application uses a Standard_D8s_v3 virtual machine with caching enabled. It makes a request for 16,000 IOPS. The requests are completed as soon as they are read or written to the cache. Writes are then lazily written to the attached Disks.
Combined uncached and cached limits
A virtual machine's cached limits are separate from its uncached limits. This means you can enable host caching on disks attached to a VM while  not enabling host caching on other disks. This configuration allows your virtual machines to get a total storage IO of the cached limit plus the uncached limit.
Let's run through an example to help you understand how these limits work together. We'll continue with the Standard_D8s_v3 virtual machine and premium disks attached configuration.
Setup:
Standard_D8s_v3
Cached IOPS: 16,000
Uncached IOPS: 12,800
P30 OS disk
IOPS: 5,000
Host caching: Read/write
Two P30 data disks × 2
IOPS: 5,000
Host caching: Read/write
Two P30 data disks × 2
IOPS: 5,000
Host caching: Disabled
In this case, the application running on a Standard_D8s_v3 virtual machine makes a request for 25,000 IOPS. The request is broken down as 5,000 IOPS to each of the attached disks. Three disks use host caching and two disks don't use host caching.
Since the three disks that use host caching are within the cached limits of 16,000, those requests are successfully completed. No storage performance capping occurs.
Since the two disks that don't use host caching are within the uncached limits of 12,800, those requests are also successfully completed. No capping occurs.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4060
Learn how an Azure reserved disks discount is applied to your Azure premium SSD managed disks.
https://learn.microsoft.com/en-us/azure/cost-management-billing/reservations/understand-disk-reservations?toc=/azure/virtual-machines/toc.json 

>>>
Understand reservations discount for Azure disk storage - Microsoft Cost Management | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Understand how your reservation discount is applied to Azure disk storage

Article
12/07/2022

																	3 contributors
Feedback
In this article
After you purchase Azure disk reserved capacity, a reservation discount is automatically applied to disk resources that match the terms of your reservation. The reservation discount applies to disk SKUs only. Disk snapshots are charged at pay-as-you-go rates.
For more information about Azure disk reservation, see Save costs with Azure disk reservation. For information about pricing for Azure disk reservation, see Azure Managed Disks pricing.
How the reservation discount is applied
The Azure disk reservation discount is a use-it-or-lose-it discount. It's applied to managed disk resources hourly. For a given hour, if you have no managed disk resources that meet the reservation terms, you lose a reservation quantity for that hour. Unused hours don't carry forward.
When you delete a resource, the reservation discount automatically applies to another matching resource in the specified scope. If no matching resource is found, the reserved hours are lost.
Stopped resources are billed and continue to use reservation hours. Deallocate or delete resources or scale-in other resources to use your available reservation hours with other workloads.
Discount examples
The following examples show how the Azure disk reservation discount applies depending on your deployment.
Suppose you purchase and reserve 100 P30 disks in the US West 2 region for a one-year term. Each disk has approximately 1 TiB of storage. Assume the cost of this sample reservation is $140,100‬. You can choose to pay either the full amount up front or fixed monthly installments of $11,675‬ for the next 12 months.
The following scenarios describe what happens if you underuse, overuse, or tier your reserved capacity. For these examples, assume you've signed up for a monthly reservation-payment plan.
Underusing your capacity
Suppose you deploy only 99 of your 100 reserved Azure premium solid-state drive (SSD) P30 disks for an hour within the reservation period. The remaining P30 disk isn't applied during that hour. It also doesn't carry over.
Overusing your capacity
Suppose that for an hour within the reservation period, you use 101 premium SSD P30 disks. The reservation discount applies only to 100 P30 disks. The remaining P30 disk is charged at pay-as-you-go rates for that hour. For the next hour, if your usage goes down to 100 P30 disks, all usage is covered by the reservation.
Tiering your capacity
Suppose that in a given hour within your reservation period, you want to use a total of 200 P30 premium SSDs. Also suppose you use only 100 for the first 30 minutes. During this period, your use is fully covered because you made a reservation for 100 P30 disks. If you then discontinue the use of the first 100 (so that you're using zero) and then begin to use the other 100 for the remaining 30 minutes, that usage is also covered under your reservation.
Need help? Contact us
If you have questions or need help, create a support request.
Next steps
Reduce costs with Azure Disks Reservation
What are Azure Reservations?
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

9878
Learn about purchasing Azure Disk Storage reservations to save costs on premium SSD managed disks.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-reserved-capacity 

>>>
Optimize costs for Azure Disk Storage with reservations - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Reduce costs with Azure Disks Reservation

Article
01/25/2023

																	4 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Save on your Azure Disk Storage usage with reserved capacity. Azure Disk Storage reservations combined with Azure Reserved Virtual Machine Instances let you lower your total virtual machine (VM) costs. The reservation discount is applied automatically to the matching disks in the selected reservation scope. Because of this automatic application, you don't need to assign a reservation to a managed disk to get the discounts.
Discounts are applied hourly depending on the disk usage. Unused reserved capacity doesn't carry over. Azure Disk Storage reservation discounts don't apply to unmanaged disks, ultra disks, or page blob consumption.
Determine your storage needs
Before you purchase a reservation, determine your storage needs. Currently, Azure Disk Storage reservations are available only for select Azure premium SSD SKUs. The SKU of a premium SSD determines the disk's size and performance.
When determining your storage needs, don't think of disks based on just capacity. For example, you can't have a reservation for a P40 disk and use that to pay for two smaller P30 disks. When purchasing a reservation, you're only purchasing a reservation for the total number of disks per SKU.
A disk reservation is made per disk SKU. As a result, the reservation consumption is based on the unit of the disk SKUs instead of the provided size.
For example, assume you reserve one P40 disk that has 2 TiB of provisioned storage capacity. Also assume you allocate only two P30 disks. The P40 reservation in that case doesn't account for P30 consumption, and you pay the pay-as-you-go rate on the P30 disks.
Premium SSD sizes 
P1
P2
P3
P4
P6
P10
P15
P20
P30
P40
P50
P60
P70
P80
Disk size in GiB
4
8
16
32
64
128
256
512
1,024
2,048
4,096
8,192
16,384
32,767
Base provisioned IOPS per disk
120
120
120
120
240
500
1,100
2,300
5,000
7,500
7,500
16,000
18,000
20,000
**Expanded provisioned IOPS per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
8,000
16,000
20,000
20,000
20,000
20,000
Base provisioned Throughput per disk
25 MB/s
25 MB/s
25 MB/s
25 MB/s
50 MB/s
100 MB/s
125 MB/s
150 MB/s
200 MB/s
250 MB/s
250 MB/s
500 MB/s
750 MB/s
900 MB/s
**Expanded provisioned Throughput per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
300 MB/s
600 MB/s
900 MB/s
900 MB/s
900 MB/s
900 MB/s
Max burst IOPS per disk
3,500
3,500
3,500
3,500
3,500
3,500
3,500
3,500
30,000*
30,000*
30,000*
30,000*
30,000*
30,000*
Max burst throughput per disk
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
Max burst duration
30 min
30 min
30 min
30 min
30 min
30 min
30 min
30 min
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Eligible for reservation
No
No
No
No
No
No
No
No
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
*Applies only to disks with on-demand bursting enabled.
** Only applies to disks with performance plus (preview) enabled.
Purchase considerations
We recommend the following practices when considering disk reservation purchase:
Analyze your usage information to help determine which reservations you should purchase. Make sure you track the usage in disk SKUs instead of provisioned or used disk capacity.
Examine your disk reservation along with your VM reservation. We highly recommend making reservations for both VM usage and disk usage for maximum savings. You can start with determining the right VM reservation and then evaluate the disk reservation. Generally, you'll have a standard configuration for each of your workloads. For example, a SQL Server server might have two P40 data disks and one P30 operating system disk.
This kind of pattern can help you determine the reserved amount you might purchase. This approach can simplify the evaluation process and ensure that you have an aligned plan for both your VM and disks. The plan contains considerations like subscriptions or regions.
Purchase restrictions
Reservation discounts are currently unavailable for the following:
Unmanaged disks or page blobs
Ultra Disks
Standard solid-state drives (SSDs) or standard hard-disk drives (HDDs)
Premium SSD SKUs smaller than P30: P1, P2, P3, P4, P6, P10, P15, and P20 SSD SKUs
Disks in Azure Government, Azure Germany, or Azure China regions
In rare circumstances, Azure limits the purchase of new reservations to a subset of disk SKUs because of low capacity in a region.
Buy a disk reservation
You can purchase Azure Disk Storage reservations through the Azure portal. You can pay for the reservation either up front or with monthly payments. For more information about purchasing with monthly payments, see Purchase reservations with monthly payments.
Follow these steps to purchase reserved capacity:
Go to the Purchase reservations pane in the Azure portal.
Select Azure Managed Disks to purchase a reservation.
Specify the required values described in the following table:
Element
Description
Scope
How many subscriptions can use the billing benefit associated with the reservation. This value also specifies how the reservation is applied to specific subscriptions.  If you select Shared, the reservation discount is applied to Azure Storage capacity in every subscription within your billing context. The billing context is based on how you signed up for Azure. For enterprise customers, the shared scope is the enrollment and includes all subscriptions within the enrollment. For pay-as-you-go customers, the shared scope includes all individual subscriptions with pay-as-you-go rates created by the account administrator. If you select Management group, the reservation discount is applied to Azure Storage capacity in every subscription that is part of the management group and the billing scope.   If you select Single subscription, the reservation discount is applied to Azure Storage capacity in the selected subscription.  If you select Single resource group, the reservation discount is applied to Azure Storage capacity in the selected subscription and in that subscription's selected resource group.  You can change the reservation scope after you purchase the reservation.
Subscription
The subscription you use to pay for the Azure Storage reservation. The payment method on the selected subscription is used in charging the costs. The subscription must be one of the following types: Enterprise Agreement (offer numbers MS-AZR-0017P and MS-AZR-0148P). For an Enterprise subscription, the charges are deducted from the enrollment's Azure Prepayment (previously called monetary commitment) balance or charged as overage.Individual subscription with pay-as-you-go rates (offer numbers MS-AZR-0003P and MS-AZR-0023P). For an individual subscription with pay-as-you-go rates, the charges are billed to the credit card or invoice payment method on the subscription.
Disks
The SKU you want to create.
Region
The region where the reservation is in effect.
Billing frequency
How often the account is billed for the reservation. Options include Monthly and Upfront.
After you specify the values for your reservation, the Azure portal displays the cost. The portal also shows the discount percentage over pay-as-you-go billing. Select Next to continue to the Purchase reservations pane.
On the Purchase reservations pane, you can name your reservation and select the total quantity of reservations you want to make. The number of reservations maps to the number of disks. For example, if you want to reserve a hundred disks, enter the Quantity value 100.
Review the total cost of the reservation.
After you purchase a reservation, it's automatically applied to any existing Disk Storage resources that match the reservation terms. If you haven't created any Disk Storage resources yet, the reservation applies whenever you create a resource that matches the reservation terms. In either case, the reservation term begins immediately after a successful purchase.
Cancel, exchange, or refund reservations
You can cancel, exchange, or refund reservations within certain limitations. For more information, see Self-service exchanges and refunds for Azure Reservations.
Expiration of a reservation
When a reservation expires, any Azure Disk Storage capacity that you use under that reservation is billed at the pay-as-you-go rate. Reservations don't renew automatically.
You'll receive an email notification 30 days before the expiration of the reservation and again on the expiration date. To continue taking advantage of the cost savings that a reservation provides, renew it no later than the expiration date.
Need help? Contact us
If you have questions or need help, create a support request.
Next steps
What are Azure Reservations?
Understand how your reservation discount is applied to Azure Disk Storage
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

45426
Design high-performance applications using Azure premium SSD managed disks. Premium Storage offers high-performance, low-latency disk support for I/O-intensive workloads running on Azure Virtual Machines.
https://learn.microsoft.com/en-us/azure/virtual-machines/premium-storage-performance 

>>>
Azure Premium Storage: Design for high performance - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Azure premium storage: design for high performance

Article
01/09/2023

																	12 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
This article provides guidelines for building high performance applications using Azure Premium Storage. You can use the instructions provided in this document combined with performance best practices applicable to technologies used by your application. To illustrate the guidelines, we have used SQL Server running on Premium Storage as an example throughout this document.
While we address performance scenarios for the Storage layer in this article, you will need to optimize the application layer. For example, if you are hosting a SharePoint Farm on Azure Premium Storage, you can use the SQL Server examples from this article to optimize the database server. Additionally, optimize the SharePoint Farm's Web server and Application server to get the most performance.
This article will help answer following common questions about optimizing application performance on Azure Premium Storage,
How to measure your application performance?
Why are you not seeing expected high performance?
Which factors influence your application performance on Premium Storage?
How do these factors influence performance of your application on Premium Storage?
How can you optimize for IOPS, Bandwidth and Latency?
We have provided these guidelines specifically for Premium Storage because workloads running on Premium Storage are highly performance sensitive. We have provided examples where appropriate. You can also apply some of these guidelines to applications running on IaaS VMs with Standard Storage disks.
Note
Sometimes, what appears to be a disk performance issue is actually a network bottleneck. In these situations, you should optimize your network performance.
If you are looking to benchmark your disk, see our articles on benchmarking a disk:
For Linux: Benchmark your application on Azure Disk Storage
For Windows: Benchmarking a disk.
If your VM supports accelerated networking, you should make sure it is enabled. If it is not enabled, you can enable it on already deployed VMs on both Windows and Linux.
Before you begin, if you are new to Premium Storage, first read the Select an Azure disk type for IaaS VMs and Scalability targets for premium page blob storage accounts.
Application performance indicators
We assess whether an application is performing well or not using performance indicators like, how fast an application is processing a user request, how much data an application is processing per request, how many requests is an application processing in a specific period of time, how long a user has to wait to get a response after submitting their request. The technical terms for these performance indicators are, IOPS, Throughput or Bandwidth, and Latency.
In this section, we will discuss the common performance indicators in the context of Premium Storage. In the following section, Gathering Application Requirements, you will learn how to measure these performance indicators for your application. Later in Optimize application performance, you will learn about the factors affecting these performance indicators and recommendations to optimize them.
IOPS
IOPS, or Input/output Operations Per Second, is the number of requests that your application is sending to the storage disks in one second. An input/output operation could be read or write, sequential, or random. Online Transaction Processing (OLTP) applications like an online retail website need to process many concurrent user requests immediately. The user requests are insert and update intensive database transactions, which the application must process quickly. Therefore, OLTP applications require very high IOPS. Such applications handle millions of small and random IO requests. If you have such an application, you must design the application infrastructure to optimize for IOPS. In Optimize application performance, we discuss in detail all the factors that you must consider to get high IOPS.
When you attach a premium storage disk to your high scale VM, Azure provisions for you a guaranteed number of IOPS as per the disk specification. For example, a P50 disk provisions 7500 IOPS. Each high scale VM size also has a specific IOPS limit that it can sustain. For example, a Standard GS5 VM has 80,000 IOPS limit.
Throughput
Throughput, or bandwidth is the amount of data that your application is sending to the storage disks in a specified interval. If your application is performing input/output operations with large IO unit sizes, it requires high throughput. Data warehouse applications tend to issue scan intensive operations that access large portions of data at a time and commonly perform bulk operations. In other words, such applications require higher throughput. If you have such an application, you must design its infrastructure to optimize for throughput. In the next section, we discuss in detail the factors you must tune to achieve this.
When you attach a premium storage disk to a high scale VM, Azure provisions throughput as per that disk specification. For example, a P50 disk provisions 250 MB per second disk throughput. Each high scale VM size also has as specific throughput limit that it can sustain. For example, Standard GS5 VM has a maximum throughput of 2,000 MB per second.
There is a relation between throughput and IOPS as shown in the formula below.
Therefore, it is important to determine the optimal throughput and IOPS values that your application requires. As you try to optimize one, the other also gets affected. In Optimize application performance, we will discuss in more details about optimizing IOPS and Throughput.
Latency
Latency is the time it takes an application to receive a single request, send it to the storage disks and send the response to the client. This is a critical measure of an application's performance in addition to IOPS and Throughput. The Latency of a premium storage disk is the time it takes to retrieve the information for a request and communicate it back to your application. Premium Storage provides consistent low latencies. Premium Disks are designed to provide single-digit millisecond latencies for most IO operations. If you enable ReadOnly host caching on premium storage disks, you can get much lower read latency. We discuss Disk Caching in more detail in Disk caching.
When you are optimizing your application to get higher IOPS and Throughput, it will affect the latency of your application. After tuning the application performance, always evaluate the latency of the application to avoid unexpected high latency behavior.
The following control plane operations on Managed Disks may involve movement of the Disk from one Storage location to another. This is orchestrated via background copy of data that can take several hours to complete, typically less than 24 hours depending on the amount of data in the disks. During that time your application can experience higher than usual read latency as some reads can get redirected to the original location and can take longer to complete. There is no impact on write latency during this period.
Update the storage type.
Detach and attach a disk from one VM to another.
Create a managed disk from a VHD.
Create a managed disk from a snapshot.
Convert unmanaged disks to managed disks.
Performance Application Checklist for disks
The first step in designing high-performance applications running on Azure Premium Storage is understanding the performance requirements of your application. After you have gathered performance requirements, you can optimize your application to achieve the most optimal performance.
In the previous section, we explained the common performance indicators, IOPS, Throughput, and Latency. You must identify which of these performance indicators are critical to your application to deliver the desired user experience. For example, high IOPS matters most to OLTP applications processing millions of transactions in a second. Whereas, high Throughput is critical for Data Warehouse applications processing large amounts of data in a second. Extremely low Latency is crucial for real-time applications like live video streaming websites.
Next, measure the maximum performance requirements of your application throughout its lifetime. Use the sample checklist below as a start. Record the maximum performance requirements during normal, peak, and off-hours workload periods. By identifying requirements for all workloads levels, you will be able to determine the overall performance requirement of your application. For example, the normal workload of an e-commerce website will be the transactions it serves during most days in a year. The peak workload of the website will be the transactions it serves during holiday season or special sale events. The peak workload is typically experienced for a limited period, but can require your application to scale two or more times its normal operation. Find out the 50 percentile, 90 percentile, and 99 percentile requirements. This helps filter out any outliers in the performance requirements and you can focus your efforts on optimizing for the right values.
Application performance requirements checklist
Performance requirements
50 Percentile
90 Percentile
99  Percentile
Max. Transactions per second
% Read operations
% Write operations
% Random operations
% Sequential operations
IO request size
Average Throughput
Max. Throughput
Min. Latency
Average Latency
Max. CPU
Average CPU
Max. Memory
Average Memory
Queue Depth
Note
You should consider scaling these numbers based on expected future growth of your application. It is a good idea to plan for growth ahead of time, because it could be harder to change the infrastructure for improving performance later.
If you have an existing application and want to move to Premium Storage, first build the checklist above for the existing application. Then, build a prototype of your application on Premium Storage and design the application based on guidelines described in Optimize application performance. The next article describes the tools you can use to gather the performance measurements.
Counters to measure application performance requirements
The best way to measure performance requirements of your application, is to use performance-monitoring tools provided by the operating system of the server. You can use PerfMon for Windows and iostat for Linux. These tools capture counters corresponding to each measure explained in the above section. You must capture the values of these counters when your application is running its normal, peak, and off-hours workloads.
The PerfMon counters are available for processor, memory and, each logical disk and physical disk of your server. When you use premium storage disks with a VM, the physical disk counters are for each premium storage disk, and logical disk counters are for each volume created on the premium storage disks. You must capture the values for the disks that host your application workload. If there is a one to one mapping between logical and physical disks, you can refer to physical disk counters; otherwise refer to the logical disk counters. On Linux, the iostat command generates a CPU and disk utilization report. The disk utilization report provides statistics per physical device or partition. If you have a database server with its data and logs on separate disks, collect this data for both disks. Below table describes counters for disks, processors, and memory:
Counter
Description
PerfMon
iostat
IOPS or Transactions per second
Number of I/O requests issued to the storage disk per second.
Disk Reads/sec  Disk Writes/sec
tps  r/s  w/s
Disk Reads and Writes
% of Reads and Write operations performed on the disk.
% Disk Read Time  % Disk Write Time
r/s  w/s
Throughput
Amount of data read from or written to the disk per second.
Disk Read Bytes/sec  Disk Write Bytes/sec
kB_read/s  kB_wrtn/s
Latency
Total time to complete a disk IO request.
Average Disk sec/Read  Average disk sec/Write
await  svctm
IO size
The size of I/O requests issues to the storage disks.
Average Disk Bytes/Read  Average Disk Bytes/Write
avgrq-sz
Queue Depth
Number of outstanding I/O requests waiting to be read from or written to the storage disk.
Current Disk Queue Length
avgqu-sz
Max. Memory
Amount of memory required to run application smoothly
% Committed Bytes in Use
Use vmstat
Max. CPU
Amount CPU required to run application smoothly
% Processor time
%util
Learn more about iostat and PerfMon.
Optimize application performance
The main factors that influence performance of an application running on Premium Storage are Nature of IO requests, VM size, Disk size, Number of disks, disk caching, multithreading, and queue depth. You can control some of these factors with knobs provided by the system. Most applications may not give you an option to alter the IO size and Queue Depth directly. For example, if you are using SQL Server, you cannot choose the IO size and queue depth. SQL Server chooses the optimal IO size and queue depth values to get the most performance. It is important to understand the effects of both types of factors on your application performance, so that you can provision appropriate resources to meet performance needs.
Throughout this section, refer to the application requirements checklist that you created, to identify how much you need to optimize your application performance. Based on that, you will be able to determine which factors from this section you will need to tune. To witness the effects of each factor on your application performance, run benchmarking tools on your application setup. Refer to the Benchmarking article, linked at the end, for steps to run common benchmarking tools on Windows and Linux VMs.
Optimize IOPS, throughput, and latency at a glance
The table below summarizes performance factors and the steps necessary to optimize IOPS, throughput, and latency. The sections following this summary will describe each factor in much more depth.
For more information on VM sizes and on the IOPS, throughput, and latency available for each type of VM, see Sizes for virtual machines in Azure.
IOPS
Throughput
Latency
Example Scenario
Enterprise OLTP application requiring very high transactions per second rate.
Enterprise Data warehousing application processing large amounts of data.
Near real-time applications requiring instant responses to user requests, like online gaming.
Performance factors
 
 
 
IO size
Smaller IO size yields higher IOPS.
Larger IO size to yields higher Throughput.
 
VM size
Use a VM size that offers IOPS greater than your application requirement.
Use a VM size with throughput limit greater than your application requirement.
Use a VM size that offers scale limits greater than your application requirement.
Disk size
Use a disk size that offers IOPS greater than your application requirement.
Use a disk size with Throughput limit greater than your application requirement.
Use a disk size that offers scale limits greater than your application requirement.
VM and Disk Scale Limits
IOPS limit of the VM size chosen should be greater than total IOPS driven by storage disks attached to it.
Throughput limit of the VM size chosen should be greater than total Throughput driven by premium storage disks attached to it.
Scale limits of the VM size chosen must be greater than total scale limits of attached premium storage disks.
Disk Caching
Enable ReadOnly Cache on premium storage disks with Read heavy operations to get higher Read IOPS.
 
Enable ReadOnly Cache on premium storage disks with Read heavy operations to get very low Read latencies.
Disk Striping
Use multiple disks and stripe them together to get a combined higher IOPS and Throughput limit. The combined limit per VM should be higher than the combined limits of attached premium disks.
 
 
Stripe Size
Smaller stripe size for random small IO pattern seen in OLTP applications. For example, use stripe size of 64 KB for SQL Server OLTP application.
Larger stripe size for sequential large IO pattern seen in Data Warehouse applications. For example, use 256 KB stripe size for SQL Server Data warehouse application.
 
Multithreading
Use multithreading to push higher number of requests to Premium Storage that will lead to higher IOPS and Throughput. For example, on SQL Server set a high MAXDOP value to allocate more CPUs to SQL Server.
 
 
Queue Depth
Larger Queue Depth yields higher IOPS.
Larger Queue Depth yields higher Throughput.
Smaller Queue Depth yields lower latencies.
Nature of IO requests
An IO request is a unit of input/output operation that your application will be performing. Identifying the nature of IO requests, random or sequential, read or write, small or large, will help you determine the performance requirements of your application. It is important to understand the nature of IO requests, to make the right decisions when designing your application infrastructure. IOs must be distributed evenly to achieve the best performance possible.
IO size is one of the more important factors. The IO size is the size of the input/output operation request generated by your application. The IO size has a significant impact on performance especially on the IOPS and Bandwidth that the application is able to achieve. The following formula shows the relationship between IOPS, IO size, and Bandwidth/Throughput.
Some applications allow you to alter their IO size, while some applications do not. For example, SQL Server determines the optimal IO size itself, and does not provide users with any knobs to change it. On the other hand, Oracle provides a parameter called DB_BLOCK_SIZE using which you can configure the I/O request size of the database.
If you are using an application, which does not allow you to change the IO size, use the guidelines in this article to optimize the performance KPI that is most relevant to your application. For example,
An OLTP application generates millions of small and random IO requests. To handle these types of IO requests, you must design your application infrastructure to get higher IOPS.
A data warehousing application generates large and sequential IO requests. To handle these types of IO requests, you must design your application infrastructure to get higher Bandwidth or Throughput.
If you are using an application, which allows you to change the IO size, use this rule of thumb for the IO size in addition to other performance guidelines,
Smaller IO size to get higher IOPS. For example, 8 KB for an OLTP application.
Larger IO size to get higher Bandwidth/Throughput. For example, 1024 KB for a data warehouse application.
Here is an example on how you can calculate the IOPS and Throughput/Bandwidth for your application. Consider an application using a P30 disk. The maximum IOPS and Throughput/Bandwidth a P30 disk can achieve is 5000 IOPS and 200 MB per second respectively. Now, if your application requires the maximum IOPS from the P30 disk and you use a smaller IO size like 8 KB, the resulting Bandwidth you will be able to get is 40 MB per second. However, if your application requires the maximum Throughput/Bandwidth from P30 disk, and you use a larger IO size like 1024 KB, the resulting IOPS will be less, 200 IOPS. Therefore, tune the IO size such that it meets both your application's IOPS and Throughput/Bandwidth requirement. The following table summarizes the different IO sizes and their corresponding IOPS and Throughput for a P30 disk.
Application Requirement
I/O size
IOPS
Throughput/Bandwidth
Max IOPS
8 KB
5,000
40 MB per second
Max Throughput
1024 KB
200
200 MB per second
Max Throughput + high IOPS
64 KB
3,200
200 MB per second
Max IOPS + high Throughput
32 KB
5,000
160 MB per second
To get IOPS and Bandwidth higher than the maximum value of a single premium storage disk, use multiple premium disks striped together. For example, stripe two P30 disks to get a combined IOPS of 10,000 IOPS or a combined Throughput of 400 MB per second. As explained in the next section, you must use a VM size that supports the combined disk IOPS and Throughput.
Note
As you increase either IOPS or Throughput the other also increases, make sure you do not hit throughput or IOPS limits of the disk or VM when increasing either one.
To witness the effects of IO size on application performance, you can run benchmarking tools on your VM and disks. Create multiple test runs and use different IO size for each run to see the impact. Refer to the Benchmarking article, linked at the end, for more details.
High scale VM sizes
When you start designing an application, one of the first things to do is, choose a VM to host your application. Premium Storage comes with High Scale VM sizes that can run applications requiring higher compute power and a high local disk I/O performance. These VMs provide faster processors, a higher memory-to-core ratio, and a Solid-State Drive (SSD) for the local disk. Examples of High Scale VMs supporting Premium Storage are the DS and GS series VMs.
High Scale VMs are available in different sizes with a different number of CPU cores, memory, OS, and temporary disk size. Each VM size also has maximum number of data disks that you can attach to the VM. Therefore, the chosen VM size will affect how much processing, memory, and storage capacity is available for your application. It also affects the Compute and Storage cost. For example, below are the specifications of the largest VM size in a DS series and a GS series:
VM size
CPU cores
Memory
VM disk sizes
Max. data disks
Cache size
IOPS
Bandwidth Cache IO limits
Standard_DS14
16
112 GB
OS = 1023 GB  Local SSD = 224 GB
32
576 GB
50,000 IOPS  512 MB per second
4,000 IOPS and 33 MB per second
Standard_GS5
32
448 GB
OS = 1023 GB  Local SSD = 896 GB
64
4224 GB
80,000 IOPS  2,000 MB per second
5,000 IOPS and 50 MB per second
To view a complete list of all available Azure VM sizes, refer to Sizes for virtual machines in Azure. Choose a VM size that can meet and scale to your desired application performance requirements. In addition to this, take into account following important considerations when choosing VM sizes.
Scale Limits
The maximum IOPS limits per VM and per disk are different and independent of each other. Make sure that the application is driving IOPS within the limits of the VM as well as the premium disks attached to it. Otherwise, application performance will experience throttling.
As an example, suppose an application requirement is a maximum of 4,000 IOPS. To achieve this, you provision a P30 disk on a DS1 VM. The P30 disk can deliver up to 5,000 IOPS. However, the DS1 VM is limited to 3,200 IOPS. Consequently, the application performance will be constrained by the VM limit at 3,200 IOPS and there will be degraded performance. To prevent this situation, choose a VM and disk size that will both meet application requirements.
Cost of Operation
In many cases, it is possible that your overall cost of operation using Premium Storage is lower than using Standard Storage.
For example, consider an application requiring 16,000 IOPS. To achieve this performance, you will need a Standard_D14 Azure IaaS VM, which can give a maximum IOPS of 16,000 using 32 standard storage 1 TB disks. Each 1-TB standard storage disk can achieve a maximum of 500 IOPS. The estimated cost of this VM per month will be $1,570. The monthly cost of 32 standard storage disks will be $1,638. The estimated total monthly cost will be $3,208.
However, if you hosted the same application on Premium Storage, you will need a smaller VM size and fewer premium storage disks, thus reducing the overall cost. A Standard_DS13 VM can meet the 16,000 IOPS requirement using four P30 disks. The DS13 VM has a maximum IOPS of 25,600 and each P30 disk has a maximum IOPS of 5,000. Overall, this configuration can achieve 5,000 x 4 = 20,000 IOPS. The estimated cost of this VM per month will be $1,003. The monthly cost of four P30 premium storage disks will be $544.34. The estimated total monthly cost will be $1,544.
Table below summarizes the cost breakdown of this scenario for Standard and Premium Storage.
 
Standard
Premium
Cost of VM per month
$1,570.58 (Standard_D14)
$1,003.66 (Standard_DS13)
Cost of Disks per month
$1,638.40 (32 x 1-TB disks)
$544.34 (4 x P30 disks)
Overall Cost per month
$3,208.98
$1,544.34
Linux Distros
With Azure Premium Storage, you get the same level of Performance for VMs running Windows and Linux. We support many flavors of Linux distros. For more information, see Linux distributions endorsed on Azure. It is important to note that different distros are better suited for different types of workloads. You will see different levels of performance depending on the distro your workload is running on. Test the Linux distros with your application and choose the one that works best.
When running Linux with Premium Storage, check the latest updates about required drivers to ensure high performance.
Premium storage disk sizes
Azure Premium Storage offers a variety of sizes so you can choose one that best suits your needs. Each disk size has a different scale limit for IOPS, bandwidth, and storage. Choose the right Premium Storage Disk size depending on the application requirements and the high scale VM size. The table below shows the disks sizes and their capabilities. P4, P6, P15, P60, P70, and P80 sizes are currently only supported for Managed Disks.
Premium SSD sizes 
P1
P2
P3
P4
P6
P10
P15
P20
P30
P40
P50
P60
P70
P80
Disk size in GiB
4
8
16
32
64
128
256
512
1,024
2,048
4,096
8,192
16,384
32,767
Base provisioned IOPS per disk
120
120
120
120
240
500
1,100
2,300
5,000
7,500
7,500
16,000
18,000
20,000
**Expanded provisioned IOPS per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
8,000
16,000
20,000
20,000
20,000
20,000
Base provisioned Throughput per disk
25 MB/s
25 MB/s
25 MB/s
25 MB/s
50 MB/s
100 MB/s
125 MB/s
150 MB/s
200 MB/s
250 MB/s
250 MB/s
500 MB/s
750 MB/s
900 MB/s
**Expanded provisioned Throughput per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
300 MB/s
600 MB/s
900 MB/s
900 MB/s
900 MB/s
900 MB/s
Max burst IOPS per disk
3,500
3,500
3,500
3,500
3,500
3,500
3,500
3,500
30,000*
30,000*
30,000*
30,000*
30,000*
30,000*
Max burst throughput per disk
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
Max burst duration
30 min
30 min
30 min
30 min
30 min
30 min
30 min
30 min
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Eligible for reservation
No
No
No
No
No
No
No
No
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
*Applies only to disks with on-demand bursting enabled.
** Only applies to disks with performance plus (preview) enabled.
How many disks you choose depends on the disk size chosen. You could use a single P50 disk or multiple P10 disks to meet your application requirement. Take into account considerations listed below when making the choice.
Scale Limits (IOPS and Throughput)
The IOPS and Throughput limits of each Premium disk size is different and independent from the VM scale limits. Make sure that the total IOPS and Throughput from the disks are within scale limits of the chosen VM size.
For example, if an application requirement is a maximum of 250 MB/sec Throughput and you are using a DS4 VM with a single P30 disk. The DS4 VM can give up to 256 MB/sec Throughput. However, a single P30 disk has Throughput limit of 200 MB/sec. Consequently, the application will be constrained at 200 MB/sec due to the disk limit. To overcome this limit, provision more than one data disks to the VM or resize your disks to P40 or P50.
Note
Reads served by the cache are not included in the disk IOPS and Throughput, hence not subject to disk limits. Cache has its separate IOPS and Throughput limit per VM.
For example, initially your reads and writes are 60MB/sec and 40MB/sec respectively. Over time, the cache warms up and serves more and more of the reads from the cache. Then, you can get higher write Throughput from the disk.
Number of Disks
Determine the number of disks you will need by assessing application requirements. Each VM size also has a limit on the number of disks that you can attach to the VM. Typically, this is twice the number of cores. Ensure that the VM size you choose can support the number of disks needed.
Remember, the Premium Storage disks have higher performance capabilities compared to Standard Storage disks. Therefore, if you are migrating your application from Azure IaaS VM using Standard Storage to Premium Storage, you will likely need fewer premium disks to achieve the same or higher performance for your application.
Disk caching
High Scale VMs that leverage Azure Premium Storage have a multi-tier caching technology called BlobCache. BlobCache uses a combination of the host RAM and local SSD for caching. This cache is available for the Premium Storage persistent disks and the VM local disks. By default, this cache setting is set to Read/Write for OS disks and ReadOnly for data disks hosted on Premium Storage. With disk caching enabled on the Premium Storage disks, the high scale VMs can achieve extremely high levels of performance that exceed the underlying disk performance.
Warning
Disk Caching is not supported for disks 4 TiB and larger. If multiple disks are attached to your VM, each disk that is smaller than 4 TiB will support caching.
Changing the cache setting of an Azure disk detaches and re-attaches the target disk. If it is the operating system disk, the VM is restarted. Stop all applications/services that might be affected by this disruption before changing the disk cache setting. Not following those recommendations could lead to data corruption.
To learn more about how BlobCache works, refer to the Inside Azure Premium Storage blog post.
It is important to enable cache on the right set of disks. Whether you should enable disk caching on a premium disk or not will depend on the workload pattern that disk will be handling. Table below shows the default cache settings for OS and Data disks.
Disk type
Default cache setting
OS disk
ReadWrite
Data disk
ReadOnly
Following are the recommended disk cache settings for data disks,
Disk caching setting
recommendation on when to use this setting
None
Configure host-cache as None for write-only and write-heavy disks.
ReadOnly
Configure host-cache as ReadOnly for read-only and read-write disks.
ReadWrite
Configure host-cache as ReadWrite only if your application properly  handles writing cached data to persistent disks when needed.
ReadOnly
By configuring ReadOnly caching on Premium Storage data disks, you can achieve low Read latency and get very high Read IOPS and Throughput for your application. This is due two reasons,
Reads performed from cache, which is on the VM memory and local SSD, are much faster than reads from the data disk, which is on the Azure blob storage.
Premium Storage does not count the Reads served from cache, towards the disk IOPS and Throughput. Therefore, your application is able to achieve higher total IOPS and Throughput.
ReadWrite
By default, the OS disks have ReadWrite caching enabled. We have recently added support for ReadWrite caching on data disks as well. If you are using ReadWrite caching, you must have a proper way to write the data from cache to persistent disks. For example, SQL Server handles writing cached data to the persistent storage disks on its own. Using ReadWrite cache with an application that does not handle persisting the required data can lead to data loss, if the VM crashes.
None
Currently, None is only supported on data disks. It is not supported on OS disks. If you set None on an OS disk it will override this internally and set it to ReadOnly.
As an example, you can apply these guidelines to SQL Server running on Premium Storage by doing the following,
Configure "ReadOnly" cache on premium storage disks hosting data files.
a.  The fast reads from cache lower the SQL Server query time since data pages are retrieved much faster from the cache compared to directly from the data disks.
b.  Serving reads from cache, means there is additional Throughput available from premium data disks. SQL Server can use this additional Throughput towards retrieving more data pages and other operations like backup/restore, batch loads, and index rebuilds.
Configure "None" cache on premium storage disks hosting the log files.
a.  Log files have primarily write-heavy operations. Therefore, they do not benefit from the ReadOnly cache.
Optimize performance on Linux VMs
For all premium SSDs or ultra disks, you may be able to disable “barriers” for file systems on the disk in order to improve performance when it is known that there are no caches that could lose data.  If Azure disk caching is set to ReadOnly or None, you can disable barriers.  But if caching is set to ReadWrite, barriers should remain enabled to ensure write durability.  Barriers are typically enabled by default, but you can disable barriers using one of the following methods depending on the file system type:
For reiserFS, use the barrier=none mount option to disable barriers.  To explicitly enable barriers, use barrier=flush.
For ext3/ext4, use the barrier=0 mount option to disable barriers.  To explicitly enable barriers, use barrier=1.
For XFS, use the nobarrier mount option to disable barriers.  To explicitly enable barriers, use barrier. As of version 4.10 of the mainline Linux kernel, the design of XFS file system always ensures durability. Disabling barriers has no effect and the “nobarrier” option is deprecated. However, some Linux distributions may have backported the changes to a distribution release with an earlier kernel version, check with your distribution vendor for the status in the distribution and version you are running.
Disk striping
When a high scale VM is attached with several premium storage persistent disks, the disks can be striped together to aggregate their IOPs, bandwidth, and storage capacity.
On Windows, you can use Storage Spaces to stripe disks together. You must configure one column for each disk in a pool. Otherwise, the overall performance of striped volume can be lower than expected, due to uneven distribution of traffic across the disks.
Important: Using Server Manager UI, you can set the total number of columns up to 8 for a striped volume. When attaching more than eight disks, use PowerShell to create the volume. Using PowerShell, you can set the number of columns equal to the number of disks. For example, if there are 16 disks in a single stripe set; specify 16 columns in the NumberOfColumns parameter of the New-VirtualDisk PowerShell cmdlet.
On Linux, use the MDADM utility to stripe disks together. For detailed steps on striping disks on Linux refer to Configure Software RAID on Linux.
Stripe Size
An important configuration in disk striping is the stripe size. The stripe size or block size is the smallest chunk of data that application can address on a striped volume. The stripe size you configure depends on the type of application and its request pattern. If you choose the wrong stripe size, it could lead to IO misalignment, which leads to degraded performance of your application.
For example, if an IO request generated by your application is bigger than the disk stripe size, the storage system writes it across stripe unit boundaries on more than one disk. When it is time to access that data, it will have to seek across more than one stripe units to complete the request. The cumulative effect of such behavior can lead to substantial performance degradation. On the other hand, if the IO request size is smaller than stripe size, and if it is random in nature, the IO requests may add up on the same disk causing a bottleneck and ultimately degrading the IO performance.
Depending on the type of workload your application is running, choose an appropriate stripe size. For random small IO requests, use a smaller stripe size. Whereas for large sequential IO requests use a larger stripe size. Find out the stripe size recommendations for the application you will be running on Premium Storage. For SQL Server, configure stripe size of 64 KB for OLTP workloads and 256 KB for data warehousing workloads. See Performance best practices for SQL Server on Azure VMs to learn more.
Note
You can stripe together a maximum of 32 premium storage disks on a DS series VM and 64 premium storage disks on a GS series VM.
Multi-threading
Azure has designed Premium Storage platform to be massively parallel. Therefore, a multi-threaded application achieves much higher performance than a single-threaded application. A multi-threaded application splits up its tasks across multiple threads and increases efficiency of its execution by utilizing the VM and disk resources to the maximum.
For example, if your application is running on a single core VM using two threads, the CPU can switch between the two threads to achieve efficiency. While one thread is waiting on a disk IO to complete, the CPU can switch to the other thread. In this way, two threads can accomplish more than a single thread would. If the VM has more than one core, it further decreases running time since each core can execute tasks in parallel.
You may not be able to change the way an off-the-shelf application implements single threading or multi-threading. For example, SQL Server is capable of handling multi-CPU and multi-core. However, SQL Server decides under what conditions it will leverage one or more threads to process a query. It can run queries and build indexes using multi-threading. For a query that involves joining large tables and sorting data before returning to the user, SQL Server will likely use multiple threads. However, a user cannot control whether SQL Server executes a query using a single thread or multiple threads.
There are configuration settings that you can alter to influence this multi-threading or parallel processing of an application. For example, in case of SQL Server it is the maximum Degree of Parallelism configuration. This setting called MAXDOP, allows you to configure the maximum number of processors SQL Server can use when parallel processing. You can configure MAXDOP for individual queries or index operations. This is beneficial when you want to balance resources of your system for a performance critical application.
For example, say your application using SQL Server is executing a large query and an index operation at the same time. Let us assume that you wanted the index operation to be more performant compared to the large query. In such a case, you can set MAXDOP value of the index operation to be higher than the MAXDOP value for the query. This way, SQL Server has more number of processors that it can leverage for the index operation compared to the number of processors it can dedicate to the large query. Remember, you do not control the number of threads SQL Server will use for each operation. You can control the maximum number of processors being dedicated for multi-threading.
Learn more about Degrees of Parallelism in SQL Server. Find out such settings that influence multi-threading in your application and their configurations to optimize performance.
Queue depth
The queue depth or queue length or queue size is the number of pending IO requests in the system. The value of queue depth determines how many IO operations your application can line up, which the storage disks will be processing. It affects all the three application performance indicators that we discussed in this article viz., IOPS, throughput, and latency.
Queue Depth and multi-threading are closely related. The Queue Depth value indicates how much multi-threading can be achieved by the application. If the Queue Depth is large, application can execute more operations concurrently, in other words, more multi-threading. If the Queue Depth is small, even though application is multi-threaded, it will not have enough requests lined up for concurrent execution.
Typically, off the shelf applications do not allow you to change the queue depth, because if set incorrectly it will do more harm than good. Applications will set the right value of queue depth to get the optimal performance. However, it is important to understand this concept so that you can troubleshoot performance issues with your application. You can also observe the effects of queue depth by running benchmarking tools on your system.
Some applications provide settings to influence the Queue Depth. For example, the MAXDOP (maximum degree of parallelism) setting in SQL Server explained in previous section. MAXDOP is a way to influence Queue Depth and multi-threading, although it does not directly change the Queue Depth value of SQL Server.
High queue depth
A high queue depth lines up more operations on the disk. The disk knows the next request in its queue ahead of time. Consequently, the disk can schedule operations ahead of time and process them in an optimal sequence. Since the application is sending more requests to the disk, the disk can process more parallel IOs. Ultimately, the application will be able to achieve higher IOPS. Since application is processing more requests, the total Throughput of the application also increases.
Typically, an application can achieve maximum Throughput with 8-16+ outstanding IOs per attached disk. If a queue depth is one, application is not pushing enough IOs to the system, and it will process less amount of in a given period. In other words, less Throughput.
For example, in SQL Server, setting the MAXDOP value for a query to "4" informs SQL Server that it can use up to four cores to execute the query. SQL Server will determine what is best queue depth value and the number of cores for the query execution.
Optimal queue depth
Very high queue depth value also has its drawbacks. If queue depth value is too high, the application will try to drive very high IOPS. Unless application has persistent disks with sufficient provisioned IOPS, this can negatively affect application latencies. Following formula shows the relationship between IOPS, latency, and queue depth.
You should not configure Queue Depth to any high value, but to an optimal value, which can deliver enough IOPS for the application without affecting latencies. For example, if the application latency needs to be 1 millisecond, the Queue Depth required to achieve 5,000 IOPS is, QD = 5000 x 0.001 = 5.
Queue Depth for Striped Volume
For a striped volume, maintain a high enough queue depth such that, every disk has a peak queue depth individually. For example, consider an application that pushes a queue depth of 2 and there are four disks in the stripe. The two IO requests will go to two disks and remaining two disks will be idle. Therefore, configure the queue depth such that all the disks can be busy. Formula below shows how to determine the queue depth of striped volumes.
Throttling
Azure Premium Storage provisions specified number of IOPS and Throughput depending on the VM sizes and disk sizes you choose. Anytime your application tries to drive IOPS or Throughput above these limits of what the VM or disk can handle, Premium Storage will throttle it. This manifests in the form of degraded performance in your application. This can mean higher latency, lower Throughput, or lower IOPS. If Premium Storage does not throttle, your application could completely fail by exceeding what its resources are capable of achieving. So, to avoid performance issues due to throttling, always provision sufficient resources for your application. Take into consideration what we discussed in the VM sizes and Disk sizes sections above. Benchmarking is the best way to figure out what resources you will need to host your application.
Next steps
If you are looking to benchmark your disk, see our articles on benchmarking a disk:
For Linux: Benchmark your application on Azure Disk Storage
For Windows: Benchmarking a disk.
Learn more about the available disk types:
For Linux: Select a disk type
For Windows: Select a disk type
For SQL Server users, read articles on Performance Best Practices for SQL Server:
Performance Best Practices for SQL Server in Azure Virtual Machines
Azure Premium Storage provides highest performance for SQL Server in Azure VM
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

10450
Examples of disk bursting metrics
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-metrics 

>>>
Disk metrics - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Disk performance metrics

Article
03/03/2023

																	7 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Azure offers metrics in the Azure portal that provide insight on how your virtual machines (VM) and disks perform. The metrics can also be retrieved through an API call. This article is broken into 3 subsections:
Disk IO, throughput and queue depth metrics - These metrics allow you to see the storage performance from the perspective of a disk and a virtual machine.
Disk bursting metrics - These are the metrics provide observability into our bursting feature on our premium disks.
Storage IO utilization metrics - These metrics help diagnose bottlenecks in your storage performance with disks.
All metrics are emitted every minute, except for the bursting credit percentage metric, which is emitted every 5 minutes.
Disk IO, throughput and queue depth metrics
The following metrics are available to get insight on VM and Disk IO, throughput, and queue depth performance:
OS Disk Queue Depth: The number of current outstanding IO requests that are waiting to be read from or written to the OS disk.
OS Disk Read Bytes/Sec: The number of bytes that are read in a second from the OS disk.
OS Disk Read Operations/Sec: The number of input operations that are read in a second from the OS disk.
OS Disk Write Bytes/Sec: The number of bytes that are written in a second from the OS disk.
OS Disk Write Operations/Sec: The number of output operations that are written in a second from the OS disk.
Data Disk Queue Depth: The number of current outstanding IO requests that are waiting to be read from or written to the data disk(s).
Data Disk Read Bytes/Sec: The number of bytes that are read in a second from the data disk(s).
Data Disk Read Operations/Sec: The number of input operations that are read in a second from data disk(s).
Data Disk Write Bytes/Sec: The number of bytes that are written in a second from the data disk(s).
Data Disk Write Operations/Sec: The number of output operations that are written in a second from data disk(s).
Disk Read Bytes/Sec: The number of total bytes that are read in a second from all disks attached to a VM.
Disk Read Operations/Sec: The number of input operations that are read in a second from all disks attached to a VM.
Disk Write Bytes/Sec: The number of bytes that are written in a second from all disks attached to a VM.
Disk Write Operations/Sec: The number of output operations that are written in a second from all disks attached to a VM.
Bursting metrics
The following metrics help with observability into our bursting feature on our premium disks:
Data Disk Max Burst Bandwidth: The throughput limit that the data disk(s) can burst up to.
OS Disk Max Burst Bandwidth: The throughput limit that the OS disk can burst up to.
Data Disk Max Burst IOPS: the IOPS limit that the data disk(s) can burst up to.
OS Disk Max Burst IOPS: The IOPS limit that the OS disk can burst up to.
Data Disk Target Bandwidth: The throughput limit that the data(s) disk can achieve without bursting.
OS Disk Target Bandwidth: The throughput limit that the OS disk can achieve without bursting.
Data Disk Target IOPS: The IOPS limit that the data disk(s) can achieve without bursting.
OS Disk Target IOPS: The IOPS limit that the data disk(s) can achieve without bursting.
Data Disk Used Burst BPS Credits Percentage: The accumulated percentage of the throughput burst used for the data disk(s). Emitted on a 5 minute interval.
OS Disk Used Burst BPS Credits Percentage: The accumulated percentage of the throughput burst used for the OS disk. Emitted on a 5 minute interval.
Data Disk Used Burst IO Credits Percentage: The accumulated percentage of the IOPS burst used for the data disk(s). Emitted on a 5 minute interval.
OS Disk Used Burst IO Credits Percentage: The accumulated percentage of the IOPS burst used for the OS disk. Emitted on a 5 minute interval.
VM Bursting metrics
The following metrics provide insight on VM-level bursting:
VM Uncached Used Burst IO Credits Percentage: The accumulated percentage of the VM’s uncached IOPS burst used. Emitted on a 5 minute interval.
VM Uncached Used Burst BPS Credits Percentage: The accumulated percentage of the VM’s uncached throughput burst used. Emitted on a 5 minute interval.
VM Cached Used Burst IO Credits Percentage: The accumulated percentage of the VM’s cached IOPS burst used. Emitted on a 5 minute interval.
VM Cached Used Burst BPS Credits Percentage: The accumulated percentage of the VM’s cached throughput burst used. Emitted on a 5 minute interval.
Storage IO utilization metrics
The following metrics help diagnose bottleneck in your Virtual Machine and Disk combination. These metrics are only available on VM series that support premium storage.
Metrics that help diagnose disk IO capping:
Data Disk IOPS Consumed Percentage: The percentage calculated by the data disk IOPS completed over the provisioned data disk IOPS. If this amount is at 100%, your application running is IO capped from your data disk's IOPS limit.
Data Disk Bandwidth Consumed Percentage: The percentage calculated by the data disk throughput completed over the provisioned data disk throughput. If this amount is at 100%, your application running is IO capped from your data disk's bandwidth limit.
OS Disk IOPS Consumed Percentage: The percentage calculated by the OS disk IOPS completed over the provisioned OS disk IOPS. If this amount is at 100%, your application running is IO capped from your OS disk's IOPS limit.
OS Disk Bandwidth Consumed Percentage: The percentage calculated by the OS disk throughput completed over the provisioned OS disk throughput. If this amount is at 100%, your application running is IO capped from your OS disk's bandwidth limit.
Metrics that help diagnose VM IO capping:
VM Cached IOPS Consumed Percentage: The percentage calculated by the total IOPS completed over the max cached virtual machine IOPS limit. If this amount is at 100%, your application running is IO capped from your VM's cached IOPS limit.
VM Cached Bandwidth Consumed Percentage: The percentage calculated by the total disk throughput completed over the max cached virtual machine throughput. If this amount is at 100%, your application running is IO capped from your VM's cached bandwidth limit.
VM uncached IOPS Consumed Percentage: The percentage calculated by the total IOPS on a virtual machine completed over the max uncached  virtual machine IOPS limit. If this amount is at 100%, your application running is IO capped from your VM's uncached IOPS limit.
VM Uncached Bandwidth Consumed Percentage: The percentage calculated by the total disk throughput on a virtual machine completed over the max provisioned virtual machine throughput. If this amount is at 100%, your application running is IO capped from your VM's uncached bandwidth limit.
Storage IO metrics example
Let's run through an example of how to use these new Storage IO utilization metrics to help us debug where a bottleneck is in our system. The system setup is the same as the previous example, except this time the attached OS disk is not cached.
Setup:
Standard_D8s_v3
Cached IOPS: 16,000
Uncached IOPS: 12,800
P30 OS disk
IOPS: 5,000
Host caching: Disabled
Two P30 data disks × 2
IOPS: 5,000
Host caching: Read/write
Two P30 data disks × 2
IOPS: 5,000
Host caching: Disabled
Let's run a benchmarking test on this virtual machine and disk combination that creates IO activity. To learn how to benchmark storage IO on Azure, see Benchmark your application on Azure Disk Storage. From the benchmarking tool, you can see that the VM and disk combination can achieve 22,800 IOPS:
The Standard_D8s_v3 can achieve a total of 28,600 IOPS. Using the metrics, let's investigate what's going on and identify our storage IO bottleneck. On the left pane, select Metrics:
Let's first take a look at our VM Cached IOPS Consumed Percentage metric:
This metric tells us that 61% of the 16,000 IOPS allotted to the cached IOPS on the VM is being used. This percentage means that the storage IO bottleneck isn't with the disks that are cached because it isn't at 100%. Now let's look at our VM Uncached IOPS Consumed Percentage metric:
This metric is at 100%. It tells us that all of the 12,800 IOPS allotted to the uncached IOPS on the VM are being used. One way we can remediate this issue is to change the size of our VM to a larger size that can handle the additional IO. But before we do that, let's look at the attached disk to find out how many IOPS they are seeing. Check the OS Disk by looking at the OS Disk IOPS Consumed Percentage:
This metric tells us that around 90% of the 5,000 IOPS provisioned for this P30 OS disk is being used. This percentage means there's no bottleneck at the OS disk. Now let's check the data disks that are attached to the VM by looking at the Data Disk IOPS Consumed Percentage:
This metric tells us that the average IOPS consumed percentage across all the disks attached is around 42%. This percentage is calculated based on the IOPS that are used by the disks, and aren't being served from the host cache. Let's drill deeper into this metric by applying splitting on these metrics and splitting by the LUN value:
This metric tells us the data disks attached on LUN 3 and 2 are using around 85% of their provisioned IOPS. Here is a diagram of what the IO looks like from the VM and disks architecture:
Next steps
Azure Monitor Metrics overview
Metrics aggregation explained
Create, view, and manage metric alerts using Azure Monitor
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

13651
Learn about disk bursting for Azure disks and Azure virtual machines.
https://learn.microsoft.com/en-us/azure/virtual-machines/disk-bursting 

>>>
Managed disk bursting - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Managed disk bursting

Article
05/02/2023

																	6 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Azure offers the ability to boost disk storage IOPS and MB/s performance, this is referred to as bursting for both virtual machines (VM) and disks. You can effectively use VM and disk bursting to achieve better bursting performance on both your VMs and disk.
Bursting for Azure VMs and disk resources aren't dependent on each other. You don't need to have a burst-capable VM for an attached burst-capable disk to burst. Similarly, you don't need to have a burst-capable disk attached to your burst-capable VM for the VM to burst.
Common scenarios
The following scenarios can benefit greatly from bursting:
Improve startup times  – With bursting, your instance will start up at a faster rate. For example, the default OS disk for premium enabled VMs is the P4 disk, which is a provisioned performance of up to 120 IOPS and 25 MB/s. With bursting, the P4 can go up to 3500 IOPS and 170 MB/s allowing for startup to accelerate by up to 6X.
Handle batch jobs – Some application workloads are cyclical in nature. They require a baseline performance most of the time, and higher performance for short periods of time. An example of this is an accounting program that processes daily transactions that require a small amount of disk traffic. At the end of the month this program would complete reconciling reports that need a much higher amount of disk traffic.
Traffic spikes – Web servers and their applications can experience traffic surges at any time. If your web server is backed by VMs or disks that use bursting, the servers would be better equipped to handle traffic spikes.
Disk-level bursting
Currently, there are two managed disk types that can burst, Premium SSD managed disks, and standard SSDs. Other disk types cannot currently burst. There are two models of bursting for disks:
An on-demand bursting model, where the disk bursts whenever its needs exceed its current capacity. This model incurs additional charges anytime the disk bursts. On-demand bursting is only available for Premium SSDs larger than 512 GiB.
A credit-based model, where the disk will burst only if it has burst credits accumulated in its credit bucket. This model does not incur additional charges when the disk bursts. Credit-based bursting is only available for Premium SSD managed disks 512 GiB and smaller, and standard SSDs 1024 GiB and smaller.
Azure Premium SSD managed disks can use either bursting model, but standard SSDs currently only offer credit-based bursting.
Additionally, the performance tier of managed disks can be changed, which could be ideal if your workload would otherwise be running in burst.
Credit-based bursting
On-demand bursting
Changing performance tier
Scenarios
Ideal for short-term scaling (30 minutes or less).
Ideal for short-term scaling(Not time restricted).
Ideal if your workload would otherwise continually be running in burst.
Cost
Free
Cost is variable, see the Billing section for details.
The cost of each performance tier is fixed, see Managed Disks pricing for details.
Availability
Only available for premium SSD managed disks 512 GiB and smaller, and standard SSDs 1024 GiB and smaller.
Only available for premium SSD managed disks larger than 512 GiB.
Available to all premium SSD sizes.
Enablement
Enabled by default on eligible disks.
Must be enabled by user.
User must manually change their tier.
On-demand bursting
Premium SSD managed disks using the on-demand bursting model of disk bursting can burst beyond original provisioned targets, as often as needed by their workload, up to the max burst target. For example, on a 1-TiB P30 disk, the provisioned IOPS is 5000 IOPS. When disk bursting is enabled on this disk, your workloads can issue IOs to this disk up to the max burst performance of 30,000 IOPS and 1,000 MBps. For the max burst targets on each supported disk, see Scalability and performance targets for VM disks.
If you expect your workloads to frequently run beyond the provisioned perf target, disk bursting won't be cost-effective. In this case, we recommend that you change your disk's performance tier to a higher tier instead, for better baseline performance. Review your billing details and assess that against the traffic pattern of your workloads.
Before you enable on-demand bursting, understand the following:
On-demand bursting cannot be enabled on a premium SSD that has less than or equal to 512 GiB. Premium SSDs less than or equal to 512 GiB will always use credit-based bursting.
On-demand bursting is only supported on premium SSDs. If a premium SSD with on-demand bursting enabled is switched to another disk type, then disk bursting is disabled.
On-demand bursting doesn't automatically disable itself when the performance tier is changed. If you want to change your performance tier but do not want to keep disk bursting, you must disable it.
On-demand bursting can only be enabled when the disk is detached from a VM or when the VM is stopped. On-demand bursting can be disabled 12 hours after it has been enabled.
Regional availability
Currently, the on-demand model for disk bursting is available in all public Azure regions.
Billing
Premium SSD managed disks using the on-demand bursting model are charged an hourly burst enablement flat fee and transaction costs apply to any burst transactions beyond the provisioned target. Transaction costs are charged using the pay-as-you go model, based on uncached disk IOs, including both reads and writes that exceed provisioned targets. The following is an example of disk traffic patterns over a billing hour:
Disk configuration: Premium SSD – 1 TiB (P30), Disk bursting enabled.
00:00:00 – 00:10:00 Disk IOPS below provisioned target of 5,000 IOPS
00:10:01 – 00:10:10 Application issued a batch job causing the disk IOPS to burst at 6,000 IOPS for 10 seconds
00:10:11 – 00:59:00 Disk IOPS below provisioned target of 5,000 IOPS
00:59:01 – 01:00:00 Application issued another batch job causing the disk IOPS to burst at 7,000 IOPS for 60 seconds
In this billing hour, the cost of bursting consists of two charges:
The first charge is the burst enablement flat fee of $X (determined by your region). This flat fee is always charged on the disk disregard of the attach status until it is disabled.
Second is the burst transaction cost. Disk bursting occurred in two time slots. From 00:10:01 – 00:10:10, the accumulated burst transaction is (6,000 – 5,000) X 10 = 10,000. From 00:59:01 – 01:00:00, the accumulated burst transaction is (7,000 – 5,000) X 60 = 120,000. The total burst transactions are 10,000 + 120,000 = 130,000. Burst transaction cost will be charged at $Y based on 13 units of 10,000 transactions (based on regional pricing).
With that, the total cost on disk bursting of this billing hour equals to $X + $Y. The same calculation would apply for bursting over provisioned target of MBps. We translate the overage of MB to transactions with IO size of 256KB. If your disk traffic exceed both provisioned IOPS and MBps target, you can refer to the example below to calculate the burst transactions.
Disk configuration: Premium SSD – 1 TB (P30), Disk bursting enabled.
00:00:01 – 00:00:05 Application issued a batch job causing the disk IOPS to burst at 10,000 IOPS and 300 MBps for five seconds.
00:00:06 – 00:00:10 Application issued a recovery job causing the disk IOPS to burst at 6,000 IOPS and 600 MBps for five seconds.
The burst transaction is accounted as the max number of transactions from either IOPS or MBps bursting. From 00:00:01 – 00:00:05, the accumulated burst transaction is Max((10,000 – 5,000), (300 - 200) * 1024 / 256)) * 5 = 25,000 transactions. From 00:00:06 – 00:00:10, the accumulated burst transaction is Max((6,000 – 5,000), (600 - 200) * 1024 / 256)) * 5 = 8,000 transactions. On top of that, you include the burst enablement flat fee to get the total cost for enabling on-demand based disk bursting.
You can refer to the Managed Disks pricing page for details on pricing and use Azure Pricing Calculator to make the assessment for your workload.
To enable on-demand bursting, see Enable on-demand bursting.
Credit-based bursting
For Premium SSD managed disks, credit-based bursting is available for disk sizes P20 and smaller. For standard SSDs, credit-based bursting is available for disk sizes E30 and smaller. For both standard and Premium SSD managed disks, credit-based bursting is available in all regions in Azure Public, Government, and China Clouds. By default, disk bursting is enabled on all new and existing deployments of supported disk sizes. VM-level bursting only uses credit-based bursting.
Virtual machine-level bursting
VM-level bursting only uses the credit-based model for bursting, it is enabled by default for most Premium Storage supported VMs.
Bursting flow
The bursting credit system applies in the same manner at both the VM level and disk level. Your resource, either a VM or disk, will start with fully stocked credits in its own burst bucket. These credits allow you to burst for up to 30 minutes at the maximum burst rate. You accumulate credits whenever the resource's IOPS or MB/s are being utilized below the resource's performance target. If your resource has accrued bursting credits and your workload needs the extra performance, your resource can use those credits to go above its performance limits and increase its performance to meet the workload demands.
How you spend your available credits is up to you. You can use your 30 minutes of burst credits consecutively or sporadically throughout the day. When resources are deployed they come with a full allocation of credits. When those deplete, it takes less than a day to restock. Credits can be spent at your discretion, the burst bucket does not need to be full in order for resources to burst. Burst accumulation varies depending on each resource, since it is based on unused IOPS and MB/s below their performance targets. Higher baseline performance resources can accrue their bursting credits faster than lower baseline performing resources. For example, a P1 disk idling will accrue 120 IOPS per second, whereas an idling P20 disk would accrue 2,300 IOPS per second.
Bursting states
There are three states your resource can be in with bursting enabled:
Accruing – The resource’s IO traffic is using less than the performance target. Accumulating bursting credits for IOPS and MB/s are done separate from one another. Your resource can be accruing IOPS credits and spending MB/s credits or vice versa.
Bursting – The resource’s traffic is using more than the performance target. The burst traffic will independently consume credits from IOPS or bandwidth.
Constant – The resource’s traffic is exactly at the performance target.
Bursting examples
The following examples show how bursting works with various VM and disk combinations. To make the examples easy to follow, we will focus on MB/s, but the same logic is applied independently to IOPS.
Burstable virtual machine with non-burstable disks
VM and disk combination:
Standard_L8s_v2
Uncached MB/s: 160
Max burst MB/s: 1,280
P50 OS Disk
Provisioned MB/s: 250
On-Demand Bursting: not enabled
2 P50 Data Disks
Provisioned MB/s: 250
On-Demand Bursting: not enabled
After the initial boot up, an application is run on the VM and has a non-critical workload. This workload requires 30 MB/s that gets spread evenly across all the disks.
Then the application needs to process a batched job that requires 600 MB/s. The Standard_L8s_v2 bursts to meet this demand and then requests to the disks get evenly spread out to P50 disks.
Burstable virtual machine with burstable disks
VM and disk combination:
Standard_L8s_v2
Uncached MB/s: 160
Max burst MB/s: 1,280
P4 OS Disk
Provisioned MB/s: 25
Max burst MB/s: 170
2 P4 Data Disks
Provisioned MB/s: 25
Max burst MB/s: 170
When the VM starts, it will burst to request its burst limit of 1,280 MB/s from the OS disk and the OS disk will respond with its burst performance of 170 MB/s.
After startup, you start an application that has a non-critical workload. This application requires 15 MB/s that gets spread evenly across all the disks.
Then the application needs to process a batched job that requires 360 MB/s. The Standard_L8s_v2 bursts to meet this demand and then requests. Only 20 MB/s are needed by the OS disk. The remaining 340 MB/s are handled by the bursting P4 data disks.
Next steps
To enable on-demand bursting, see Enable on-demand bursting.
To learn how to gain insight into your bursting resources, see Disk bursting metrics.
To see exactly how much each applicable disk size can burst, see Scalability and performance targets for VM disks.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

6980
Enable on-demand disk bursting on your managed disk.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-enable-bursting 

>>>
Enable on-demand disk bursting - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Enable on-demand bursting

Article
05/03/2023

																	3 contributors
Feedback
In this article
Premium solid-state drives (SSD) have two available bursting models; credit-based bursting and on-demand bursting. This article covers how to switch to on-demand bursting. Disks that use the on-demand model can burst beyond their original provisioned targets. On-demand bursting occurs as often as needed by the workload, up to the maximum burst target. On-demand bursting incurs additional charges.
For details on disk bursting, see Managed disk bursting.
For the max burst targets on each supported disk, see Scalability and performance targets for VM disks.
Important
You don't need to follow the steps in this article to use credit-based bursting. By default, credit-based bursting is enabled on all eligible disks.
Before you enable on-demand bursting, understand the following:
On-demand bursting cannot be enabled on a premium SSD that has less than or equal to 512 GiB. Premium SSDs less than or equal to 512 GiB will always use credit-based bursting.
On-demand bursting is only supported on premium SSDs. If a premium SSD with on-demand bursting enabled is switched to another disk type, then disk bursting is disabled.
On-demand bursting doesn't automatically disable itself when the performance tier is changed. If you want to change your performance tier but do not want to keep disk bursting, you must disable it.
On-demand bursting can only be enabled when the disk is detached from a VM or when the VM is stopped. On-demand bursting can be disabled 12 hours after it has been enabled.
Regional availability
Currently, the on-demand model for disk bursting is available in all public Azure regions.
Get started
On-demand bursting can be enabled with either the Azure portal, the Azure PowerShell module, the Azure CLI, or Azure Resource Manager templates. The following examples cover how to create a new disk with on-demand bursting enabled and enabling on-demand bursting on existing disks.
Portal
PowerShell
Azure CLI
Azure Resource Manager
A managed disk must be larger than 512 GiB to enable on-demand bursting.
To enable on-demand bursting for an existing disk:
Sign in to the Azure portal and navigate to your disk.
Select Configuration and select Enable on-demand bursting.
Select Save.
On-demand bursting cmdlets are available in version 5.5.0 and newer of the Az module. Alternatively, you may use the Azure Cloud Shell.
Create an empty data disk with on-demand bursting
A managed disk must be larger than 512 GiB to enable on-demand bursting. Replace the <myResourceGroupDisk> and <myDataDisk> parameters then run the following script to create a premium SSD with on-demand bursting:
Set-AzContext -SubscriptionName <yourSubscriptionName>
$diskConfig = New-AzDiskConfig -Location 'WestCentralUS' -CreateOption Empty -DiskSizeGB 1024 -SkuName Premium_LRS -BurstingEnabled $true
$dataDisk = New-AzDisk -ResourceGroupName <myResourceGroupDisk> -DiskName <myDataDisk> -Disk $diskConfig
Enable on-demand bursting on an existing disk
A managed disk must be larger than 512 GiB to enable on-demand bursting. Replace the <myResourceGroupDisk>, <myDataDisk> parameters and run this command to enable on-demand bursting on an existing disk:
New-AzDiskUpdateConfig -BurstingEnabled $true | Update-AzDisk -ResourceGroupName <myResourceGroupDisk> -DiskName <myDataDisk> //Set the flag to $false to disable on-demand bursting
On-demand bursting cmdlets are available in version 2.19.0 and newer of the Azure CLI module. Alternatively, you may use the Azure Cloud Shell.
Create and attach a on-demand bursting data disk
A managed disk must be larger than 512 GiB to enable on-demand bursting. Replace the <yourDiskName>, <yourResourceGroup>, and <yourVMName> parameters, then run the following commands to create a premium SSD with on-demand bursting:
az disk create -g <yourResourceGroup> -n <yourDiskName> --size-gb 1024 --sku Premium_LRS -l westcentralus --enable-bursting true
az vm disk attach --vm-name <yourVMName> --name <yourDiskName> --resource-group <yourResourceGroup>
Enable on-demand bursting on an existing disk - CLI
A managed disk must be larger than 512 GiB to enable on-demand bursting. Replace the <myResourceGroupDisk> and <yourDiskName> parameters and run this command to enable on-demand bursting on an existing disk:
az disk update --name <yourDiskName> --resource-group <yourResourceGroup> --enable-bursting true //Set the flag to false to disable on-demand bursting
With the 2020-09-30 disk API, you can enable on-demand bursting on newly-created or existing premium SSDs larger than 512 GiB. The 2020-09-30 API introduced a new property, burstingEnabled. By default, this property is set to false. The following sample template creates a 1TiB premium SSD in West Central US, with disk bursting enabled:
{
  "$schema": "http://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "diskSkuName": {
        "type": "string",
        "defaultValue": "Premium_LRS" //Supported on premium SSDs only
},
    "dataDiskSizeInGb": {
      "type": "string",
      "defaultValue": "1024" //Supported on disk size > 512 GiB
},
    "location": {
      "type": "string",
      "defaultValue": "westcentralus" //Preview regions: West Central US
},
"diskApiVersion": {
      "type": "string",
      "defaultValue": "2020-09-30" //Preview supported version: 2020-09-30 or above
    }
  },
  "resources": [
    {
      "apiVersion": "[parameters('diskApiVersion')]",
      "type": "Microsoft.Compute/disks",
      "name": "[parameters('diskName')]",
      "location": "[parameters(location)]",
      "properties": {
        "creationData": {
          "createOption": "Empty"
        },
        "diskSizeGB": "[parameters('dataDiskSizeInGb')]",
        "burstingEnabled": "true" //Feature flag to enable disk bursting on disks > 512 GiB
      },
      "sku": {
        "name": "[parameters('diskSkuName')]"
      }
    ]
}
Next steps
To learn how to gain insight into your bursting resources, see Disk bursting metrics.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4448
Learn about performance tiers for managed disks.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-change-performance 

>>>
Performance tiers for Azure managed disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Performance tiers for managed disks

Article
05/23/2023

																	2 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
The performance of your Azure managed disk is set when you create your disk, in the form of its performance tier. When you set the provisioned size of your disk, a performance tier is automatically selected. The performance tier determines the IOPS and throughput your managed disk has. The performance tier can be changed at deployment or afterwards, without changing the size of the disk and without downtime.
Changing the performance tier allows you to prepare for and meet higher demand without using your disk's bursting capability. It can be more cost-effective to change your performance tier rather than rely on bursting, depending on how long the additional performance is necessary. This is ideal for events that temporarily require a consistently higher level of performance, like holiday shopping, performance testing, or running a training environment. To handle these events, you can switch a disk to a higher performance tier without downtime, for as long as you need the additional performance. You can then return to the original tier without downtime when the additional performance is no longer necessary.
To learn more about how the performance of a disk works with the performance of a virtual machine, see Virtual machine and disk performance.
Restrictions
This feature is currently supported only for premium SSD managed disks.
This feature isn't currently supported with shared disks.
The P60, P70, and P80 performance tiers can only be used by disks that are larger than 4,096 GiB.
A disk's performance tier can be downgraded only once every 12 hours.
The system does not return Performance Tier for disks created before June 2020. You can take advantage of Performance Tier for an older disk by updating it with the baseline Tier.
How it works
When you first deploy or provision a disk, the baseline performance tier for that disk is set based on the provisioned disk size. You can use a performance tier higher than the original baseline to meet higher demand. When you no longer need that performance level, you can return to the initial baseline performance tier.
Billing impact
Your billing changes as your performance tier changes. For example, if you provision a P10 disk (128 GiB), your baseline performance tier is set as P10 (500 IOPS and 100 MBps). You'll be billed at the P10 rate. You can upgrade the tier to match the performance of P50 (7,500 IOPS and 250 MBps) without increasing the disk size. During the time of the upgrade, you'll be billed at the P50 rate. When you no longer need the higher performance, you can return to the P10 tier. The disk will once again be billed at the P10 rate.
For billing information, see Managed disk pricing.
What tiers can be changed
The following table depicts which tiers each baseline performance tier can upgrade to.
Disk size
Baseline performance tier
Can be upgraded to
4 GiB
P1
P2, P3, P4, P6, P10, P15, P20, P30, P40, P50
8 GiB
P2
P3, P4, P6, P10, P15, P20, P30, P40, P50
16 GiB
P3
P4, P6, P10, P15, P20, P30, P40, P50
32 GiB
P4
P6, P10, P15, P20, P30, P40, P50
64 GiB
P6
P10, P15, P20, P30, P40, P50
128 GiB
P10
P15, P20, P30, P40, P50
256 GiB
P15
P20, P30, P40, P50
512 GiB
P20
P30, P40, P50
1 TiB
P30
P40, P50
2 TiB
P40
P50
4 TiB
P50
None
8 TiB
P60
P70, P80
16 TiB
P70
P80
32 TiB
P80
None
Next steps
To learn how to change your performance tier, see portal or PowerShell/CLI articles.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4859
Learn how to change performance tiers for existing managed disks using either the Azure PowerShell module or the Azure CLI.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-performance-tiers 

>>>
Change the performance of Azure managed disks - CLI/PowerShell - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Change your performance tier without downtime using the Azure PowerShell module or the Azure CLI

Article
05/23/2023

																	5 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets
The performance of your Azure managed disk is set when you create your disk, in the form of its performance tier. The performance tier determines the IOPS and throughput your managed disk has. When you set the provisioned size of your disk, a performance tier is automatically selected. The performance tier can be changed at deployment or afterwards, without changing the size of the disk and without downtime. To learn more about performance tiers, see Performance tiers for managed disks.
Changing your performance tier has billing implications. See Billing impact for details.
Restrictions
This feature is currently supported only for premium SSD managed disks.
This feature isn't currently supported with shared disks.
The P60, P70, and P80 performance tiers can only be used by disks that are larger than 4,096 GiB.
A disk's performance tier can be downgraded only once every 12 hours.
The system does not return Performance Tier for disks created before June 2020. You can take advantage of Performance Tier for an older disk by updating it with the baseline Tier.
Prerequisites
Azure CLI
PowerShell
Install the latest Azure CLI and sign in to an Azure account with az login.
Install the latest Azure PowerShell version, and sign in to an Azure account in with Connect-AzAccount.
Create an empty data disk with a tier higher than the baseline tier
Azure CLI
PowerShell
subscriptionId=<yourSubscriptionIDHere>
resourceGroupName=<yourResourceGroupNameHere>
diskName=<yourDiskNameHere>
diskSize=<yourDiskSizeHere>
performanceTier=<yourDesiredPerformanceTier>
region=westcentralus
az account set --subscription $subscriptionId
az disk create -n $diskName -g $resourceGroupName -l $region --sku Premium_LRS --size-gb $diskSize --tier $performanceTier
Create an OS disk with a tier higher than the baseline tier from an Azure Marketplace image
resourceGroupName=<yourResourceGroupNameHere>
diskName=<yourDiskNameHere>
performanceTier=<yourDesiredPerformanceTier>
region=westcentralus
image=Canonical:UbuntuServer:18.04-LTS:18.04.202002180
az disk create -n $diskName -g $resourceGroupName -l $region --image-reference $image --sku Premium_LRS --tier $performanceTier
$subscriptionId='yourSubscriptionID'
$resourceGroupName='yourResourceGroupName'
$diskName='yourDiskName'
$diskSizeInGiB=4
$performanceTier='P50'
$sku='Premium_LRS'
$region='westcentralus'
Connect-AzAccount
Set-AzContext -Subscription $subscriptionId
$diskConfig = New-AzDiskConfig -SkuName $sku -Location $region -CreateOption Empty -DiskSizeGB $diskSizeInGiB -Tier $performanceTier
New-AzDisk -DiskName $diskName -Disk $diskConfig -ResourceGroupName $resourceGroupName
Update the tier of a disk without downtime
Azure CLI
PowerShell
Update the tier of a disk even when it is attached to a running VM
resourceGroupName=<yourResourceGroupNameHere>
diskName=<yourDiskNameHere>
performanceTier=<yourDesiredPerformanceTier>
az disk update -n $diskName -g $resourceGroupName --set tier=$performanceTier
Update the tier of a disk even when it is attached to a running VM
$resourceGroupName='yourResourceGroupName'
$diskName='yourDiskName'
$performanceTier='P1'
$diskUpdateConfig = New-AzDiskUpdateConfig -Tier $performanceTier
Update-AzDisk -ResourceGroupName $resourceGroupName -DiskName $diskName -DiskUpdate $diskUpdateConfig
Show the tier of a disk
Azure CLI
PowerShell
az disk show -n $diskName -g $resourceGroupName --query [tier] -o tsv
$disk = Get-AzDisk -ResourceGroupName $resourceGroupName -DiskName $diskName
$disk.Tier
Next steps
If you need to resize a disk to take advantage of the higher performance tiers, see these articles:
Expand virtual hard disks on a Linux VM with the Azure CLI
Expand a managed disk attached to a Windows virtual machine
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3261
Learn how to change performance tiers for new and existing managed disks using the Azure portal.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-performance-tiers-portal 

>>>
Change the performance of Azure managed disks using the Azure portal - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Change your performance tier using the Azure portal

Article
08/30/2022

																	3 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
The performance of your Azure managed disk is set when you create your disk, in the form of its performance tier. The performance tier determines the IOPS and throughput your managed disk has. When you set the provisioned size of your disk, a performance tier is automatically selected. The performance tier can be changed at deployment or afterwards, without changing the size of the disk and without downtime. To learn more about performance tiers, see Performance tiers for managed disks.
Changing your performance tier has billing implications. See Billing impact for details.
Restrictions
This feature is currently supported only for premium SSD managed disks.
This feature isn't currently supported with shared disks.
The P60, P70, and P80 performance tiers can only be used by disks that are larger than 4,096 GiB.
A disk's performance tier can be downgraded only once every 12 hours.
The system does not return Performance Tier for disks created before June 2020. You can take advantage of Performance Tier for an older disk by updating it with the baseline Tier.
Getting started
New disks
The following steps show how to change the performance tier of your disk when you first create the disk:
Sign in to the Azure portal.
Navigate to the VM you'd like to create a new disk for.
When selecting the new disk, first choose the size, of disk you need.
Once you've selected a size, then select a different performance tier, to change its performance.
Select OK to create the disk.
Change the performance tier of an existing disk
A disk's performance tier can be changed without downtime, so you don't have to deallocate your VM or detach your disk to change the tier.
Change performance tier
Navigate to the VM containing the disk you'd like to change.
Select your disk
Select Size + Performance.
In the Performance tier dropdown, select a tier other than the disk's current performance tier.
Select Resize.
Next steps
If you need to resize a disk to take advantage of the higher performance tiers, see these articles:
Expand virtual hard disks on a Linux VM with the Azure CLI
Expand a managed disk attached to a Windows virtual machine
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

16989
Documentation on how to enable and use Write Accelerator
https://learn.microsoft.com/en-us/azure/virtual-machines/how-to-enable-write-accelerator 

>>>
Azure Write Accelerator - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Enable Write Accelerator

Article
04/12/2023

																	14 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Write Accelerator is a disk capability for M-Series Virtual Machines (VMs) on Premium Storage with Azure Managed Disks exclusively. As the name states, the purpose of the functionality is to improve the I/O latency of writes against Azure Premium Storage. Write Accelerator is ideally suited where log file updates are required to persist to disk in a highly performant manner for modern databases.
Write Accelerator is generally available for M-series VMs in the Public Cloud.
Planning for using Write Accelerator
Write Accelerator should be used for the volumes that contain the transaction log or redo logs of a DBMS. It is not recommended to use Write Accelerator for the data volumes of a DBMS as the feature has been optimized to be used against log disks.
Write Accelerator only works in conjunction with Azure managed disks.
Important
Enabling Write Accelerator for the operating system disk of the VM will reboot the VM.
To enable Write Accelerator to an existing Azure disk that is NOT part of a volume build out of multiple disks with Windows disk or volume managers, Windows Storage Spaces, Windows Scale-out file server (SOFS), Linux LVM, or MDADM, the workload accessing the Azure disk needs to be shut down. Database applications using the Azure disk MUST be shut down.
If you want to enable or disable Write Accelerator for an existing volume that is built out of multiple Azure Premium Storage disks and striped using Windows disk or volume managers, Windows Storage Spaces, Windows Scale-out file server (SOFS), Linux LVM or MDADM, all disks building the volume must be enabled or disabled for Write Accelerator in separate steps. Before enabling or disabling Write Accelerator in such a configuration, shut down the Azure VM.
Enabling Write Accelerator for OS disks should not be necessary for SAP-related VM configurations.
Restrictions when using Write Accelerator
When using Write Accelerator for an Azure disk/VHD, these restrictions apply:
The Premium disk caching must be set to 'None' or 'Read Only'. All other caching modes are not supported.
Snapshots are currently supported for only Write Accelerator-enabled data disks, and not the OS disk. During backup, the Azure Backup service automatically backs up and protects Write Accelerator-enabled data disks attached to the VM.
Only smaller I/O sizes (<=64 KiB) are taking the accelerated path. In workload situations where data is getting bulk loaded or where the transaction log buffers of the different DBMS are filled to a larger degree before getting persisted to the storage, chances are that the I/O written to disk is not taking the accelerated path.
There are limits of Azure Premium Storage VHDs per VM that can be supported by Write Accelerator. The current limits are:
VM SKU
Number of Write Accelerator disks
Write Accelerator Disk IOPS per VM
M416ms_v2, M416s_v2
16
20000
M208ms_v2, M208s_v2
8
10000
M192ids_v2, M192idms_v2, M192is_v2, M192ims_v2,
16
20000
M128ms, M128s, M128ds_v2, M128dms_v2, M128s_v2, M128ms_v2
16
20000
M64ms, M64ls, M64s, M64ds_v2, M64dms_v2, M64s_v2, M64ms_v2
8
10000
M32ms, M32ls, M32ts, M32s, M32dms_v2, M32ms_v2
4
5000
M16ms, M16s
2
2500
M8ms, M8s
1
1250
The IOPS limits are per VM and not per disk. All Write Accelerator disks share the same IOPS limit per VM. Attached disks cannot exceed the write accelerator IOPS limit for a VM. For an example, even though the attached disks can do 30,000 IOPS, the system does not allow the disks to go above 20,000 IOPS for M416ms_v2.
Enabling Write Accelerator on a specific disk
The next few sections will describe how Write Accelerator can be enabled on Azure Premium Storage VHDs.
Prerequisites
The following prerequisites apply to the usage of Write Accelerator at this point in time:
The disks you want to apply Azure Write Accelerator against need to be Azure managed disks on Premium Storage.
You must be using an M-series VM
Enabling Azure Write Accelerator using Azure PowerShell
The Azure Power Shell module from version 5.5.0 include the changes to the relevant cmdlets to enable or disable Write Accelerator for specific Azure Premium Storage disks.
In order to enable or deploy disks supported by Write Accelerator, the following Power Shell commands got changed, and extended to accept a parameter for Write Accelerator.
A new switch parameter, -WriteAccelerator has been added to the following cmdlets:
Set-AzVMOsDisk
Add-AzVMDataDisk
Set-AzVMDataDisk
Add-AzVmssDataDisk
Not giving the parameter sets the property to false and will deploy disks that have no support by Write Accelerator.
A new switch parameter, -OsDiskWriteAccelerator was added to the following cmdlets:
Set-AzVmssStorageProfile
Not specifying the parameter sets the property to false by default, returning disks that don't leverage Write Accelerator.
A new optional Boolean (non-nullable) parameter, -OsDiskWriteAccelerator was added to the following cmdlets:
Update-AzVM
Update-AzVmss
Specify either $true or $false to control support of Azure Write Accelerator with the disks.
Examples of commands could look like:
New-AzVMConfig | Set-AzVMOsDisk | Add-AzVMDataDisk -Name "datadisk1" | Add-AzVMDataDisk -Name "logdisk1" -WriteAccelerator | New-AzVM
Get-AzVM | Update-AzVM -OsDiskWriteAccelerator $true
New-AzVmssConfig | Set-AzVmssStorageProfile -OsDiskWriteAccelerator | Add-AzVmssDataDisk -Name "datadisk1" -WriteAccelerator:$false | Add-AzVmssDataDisk -Name "logdisk1" -WriteAccelerator | New-AzVmss
Get-AzVmss | Update-AzVmss -OsDiskWriteAccelerator:$false
Two main scenarios can be scripted as shown in the following sections.
Adding a new disk supported by Write Accelerator using PowerShell
You can use this script to add a new disk to your VM. The disk created with this script uses Write Accelerator.
Replace myVM, myWAVMs, log001, size of the disk, and LunID of the disk with values appropriate for your specific deployment.
# Specify your VM Name
$vmName="myVM"
#Specify your Resource Group
$rgName = "myWAVMs"
#data disk name
$datadiskname = "log001"
#LUN Id
$lunid=8
#size
$size=1023
#Pulls the VM info for later
$vm=Get-AzVM -ResourceGroupName $rgname -Name $vmname
#add a new VM data disk
Add-AzVMDataDisk -CreateOption empty -DiskSizeInGB $size -Name $vmname-$datadiskname -VM $vm -Caching None -WriteAccelerator:$true -lun $lunid
#Updates the VM with the disk config - does not require a reboot
Update-AzVM -ResourceGroupName $rgname -VM $vm
Enabling Write Accelerator on an existing Azure disk using PowerShell
You can use this script to enable Write Accelerator on an existing disk. Replace myVM, myWAVMs, and test-log001 with values appropriate for your specific deployment. The script adds Write Accelerator to an existing disk where the value for $newstatus is set to '$true'. Using the value '$false' will disable Write Accelerator on a given disk.
#Specify your VM Name
$vmName="myVM"
#Specify your Resource Group
$rgName = "myWAVMs"
#data disk name
$datadiskname = "test-log001"
#new Write Accelerator status ($true for enabled, $false for disabled)
$newstatus = $true
#Pulls the VM info for later
$vm=Get-AzVM -ResourceGroupName $rgname -Name $vmname
#add a new VM data disk
Set-AzVMDataDisk -VM $vm -Name $datadiskname -Caching None -WriteAccelerator:$newstatus
#Updates the VM with the disk config - does not require a reboot
Update-AzVM -ResourceGroupName $rgname -VM $vm
Note
Executing the script above will detach the disk specified, enable Write Accelerator against the disk, and then attach the disk again
Enabling Write Accelerator using the Azure portal
You can enable Write Accelerator via the portal where you specify your disk caching settings:
Enabling Write Accelerator using the Azure CLI
You can use the Azure CLI to enable Write Accelerator.
To enable Write Accelerator on an existing disk, use az vm update, you may use the following examples if you replace the diskName, VMName, and ResourceGroup with your own values: az vm update -g group1 -n vm1 -write-accelerator 1=true
To attach a disk with Write Accelerator enabled use az vm disk attach, you may use the following example if you substitute in your own values: az vm disk attach -g group1 -vm-name vm1 -disk d1 --enable-write-accelerator
To disable Write Accelerator, use az vm update, setting the properties to false: az vm update -g group1 -n vm1 -write-accelerator 0=false 1=false
Enabling Write Accelerator using REST APIs
To deploy through Azure REST API, you need to install the Azure armclient.
Install armclient
To run armclient, you need to install it through Chocolatey. You can install it through cmd.exe or PowerShell. Use elevated rights for these commands (“Run as Administrator”).
Using cmd.exe, run the following command: @"%SystemRoot%\System32\WindowsPowerShell\v1.0\powershell.exe" -NoProfile -InputFormat None -ExecutionPolicy Bypass -Command "iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))" && SET "PATH=%PATH%;%ALLUSERSPROFILE%\chocolatey\bin"
Using Power Shell, run the following command: Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString('https://chocolatey.org/install.ps1'))
Now you can install the armclient by using the following command in either cmd.exe or PowerShell choco install armclient
Getting your current VM configuration
To change the attributes of your disk configuration, you first need to get the current configuration in a JSON file. You can get the current configuration by executing the following command: armclient GET /subscriptions/<<subscription-ID<</resourceGroups/<<ResourceGroup>>/providers/Microsoft.Compute/virtualMachines/<<virtualmachinename>>?api-version=2017-12-01 > <<filename.json>>
Replace the terms within '<<   >>' with your data, including the file name the JSON file should have.
The output could look like:
{
  "properties": {
    "vmId": "2444c93e-f8bb-4a20-af2d-1658d9dbbbcb",
    "hardwareProfile": {
      "vmSize": "Standard_M64s"
    },
    "storageProfile": {
      "imageReference": {
        "publisher": "SUSE",
        "offer": "SLES-SAP",
        "sku": "12-SP3",
        "version": "latest"
      },
      "osDisk": {
        "osType": "Linux",
        "name": "mylittlesap_OsDisk_1_754a1b8bb390468e9b4c429b81cc5f5a",
        "createOption": "FromImage",
        "caching": "ReadWrite",
        "managedDisk": {
          "storageAccountType": "Premium_LRS",
          "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Compute/disks/mylittlesap_OsDisk_1_754a1b8bb390468e9b4c429b81cc5f5a"
        },
        "diskSizeGB": 30
      },
      "dataDisks": [
        {
          "lun": 0,
          "name": "data1",
          "createOption": "Attach",
          "caching": "None",
          "managedDisk": {
            "storageAccountType": "Premium_LRS",
            "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Compute/disks/data1"
          },
          "diskSizeGB": 1023
        },
        {
          "lun": 1,
          "name": "log1",
          "createOption": "Attach",
          "caching": "None",
          "managedDisk": {
            "storageAccountType": "Premium_LRS",
            "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Compute/disks/data2"
          },
          "diskSizeGB": 1023
        }
      ]
    },
    "osProfile": {
      "computerName": "mylittlesapVM",
      "adminUsername": "pl",
      "linuxConfiguration": {
        "disablePasswordAuthentication": false
      },
      "secrets": []
    },
    "networkProfile": {
      "networkInterfaces": [
        {
          "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Network/networkInterfaces/mylittlesap518"
        }
      ]
    },
    "diagnosticsProfile": {
      "bootDiagnostics": {
        "enabled": true,
        "storageUri": "https://mylittlesapdiag895.blob.core.windows.net/"
      }
    },
    "provisioningState": "Succeeded"
  },
  "type": "Microsoft.Compute/virtualMachines",
  "location": "westeurope",
  "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Compute/virtualMachines/mylittlesapVM",
  "name": "mylittlesapVM"
Next, update the JSON file and to enable Write Accelerator on the disk called 'log1'. This can be accomplished by adding this attribute into the JSON file after the cache entry of the disk.
        {
          "lun": 1,
          "name": "log1",
          "createOption": "Attach",
          "caching": "None",
          "writeAcceleratorEnabled": true,
          "managedDisk": {
            "storageAccountType": "Premium_LRS",
            "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Compute/disks/data2"
          },
          "diskSizeGB": 1023
        }
Then update the existing deployment with this command: armclient PUT /subscriptions/<<subscription-ID<</resourceGroups/<<ResourceGroup>>/providers/Microsoft.Compute/virtualMachines/<<virtualmachinename>>?api-version=2017-12-01 @<<filename.json>>
The output should look like the one below. You can see that Write Accelerator enabled for one disk.
{
  "properties": {
    "vmId": "2444c93e-f8bb-4a20-af2d-1658d9dbbbcb",
    "hardwareProfile": {
      "vmSize": "Standard_M64s"
    },
    "storageProfile": {
      "imageReference": {
        "publisher": "SUSE",
        "offer": "SLES-SAP",
        "sku": "12-SP3",
        "version": "latest"
      },
      "osDisk": {
        "osType": "Linux",
        "name": "mylittlesap_OsDisk_1_754a1b8bb390468e9b4c429b81cc5f5a",
        "createOption": "FromImage",
        "caching": "ReadWrite",
        "managedDisk": {
          "storageAccountType": "Premium_LRS",
          "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Compute/disks/mylittlesap_OsDisk_1_754a1b8bb390468e9b4c429b81cc5f5a"
        },
        "diskSizeGB": 30
      },
      "dataDisks": [
        {
          "lun": 0,
          "name": "data1",
          "createOption": "Attach",
          "caching": "None",
          "managedDisk": {
            "storageAccountType": "Premium_LRS",
            "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Compute/disks/data1"
          },
          "diskSizeGB": 1023
        },
        {
          "lun": 1,
          "name": "log1",
          "createOption": "Attach",
          "caching": "None",
          "writeAcceleratorEnabled": true,
          "managedDisk": {
            "storageAccountType": "Premium_LRS",
            "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Compute/disks/data2"
          },
          "diskSizeGB": 1023
        }
      ]
    },
    "osProfile": {
      "computerName": "mylittlesapVM",
      "adminUsername": "pl",
      "linuxConfiguration": {
        "disablePasswordAuthentication": false
      },
      "secrets": []
    },
    "networkProfile": {
      "networkInterfaces": [
        {
          "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Network/networkInterfaces/mylittlesap518"
        }
      ]
    },
    "diagnosticsProfile": {
      "bootDiagnostics": {
        "enabled": true,
        "storageUri": "https://mylittlesapdiag895.blob.core.windows.net/"
      }
    },
    "provisioningState": "Succeeded"
  },
  "type": "Microsoft.Compute/virtualMachines",
  "location": "westeurope",
  "id": "/subscriptions/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX/resourceGroups/mylittlesap/providers/Microsoft.Compute/virtualMachines/mylittlesapVM",
  "name": "mylittlesapVM"
Once you've made this change, the drive should be supported by Write Accelerator.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

10189
Learn about the process of benchmarking your application on Azure.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-benchmarks 

>>>
Benchmark your application on Azure Disk Storage - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Benchmark a disk

Article
02/08/2023

																	4 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Benchmarking is the process of simulating different workloads on your application and measuring the application performance for each workload. Using the steps described in the designing for high performance article, you have gathered the application performance requirements. By running benchmarking tools on the VMs hosting the application, you can determine the performance levels that your application can achieve with premium SSDs. In this article, we provide you examples of benchmarking a Standard_D8ds_v4 VM provisioned with Azure premium SSDs.
We have used common benchmarking tools DiskSpd and FIO, for Windows and Linux respectively. These tools spawn multiple threads simulating a production like workload, and measure the system performance. Using the tools you can also configure parameters like block size and queue depth, which you normally cannot change for an application. This gives you more flexibility to drive the maximum performance on a high scale VM provisioned with premium SSDs for different types of application workloads. To learn more about each benchmarking tool visit DiskSpd and FIO.
To follow the examples below, create a Standard_D8ds_v4 and attach four premium SSDs to the VM. Of the four disks, configure three with host caching as "None" and stripe them into a volume called NoCacheWrites. Configure host caching as "ReadOnly" on the remaining disk and create a volume called CacheReads with this disk. Using this setup, you are able to see the maximum Read and Write performance from a Standard_D8ds_v4 VM. For detailed steps about creating a Standard_D8ds_v4 with premium SSDs, see Designing for high performance.
Warm up the Cache
The disk with ReadOnly host caching is able to give higher IOPS than the disk limit. To get this maximum read performance from the host cache, first you must warm up the cache of this disk. This ensures that the Read IOs that the benchmarking tool will drive on CacheReads volume, actually hits the cache, and not the disk directly. The cache hits result in more IOPS from the single cache enabled disk.
Important
You must warm up the cache before running benchmarks every time VM is rebooted.
DISKSPD
Download the DISKSP tool on the VM. DISKSPD is a tool that you can customize to create your own synthetic workloads. We will use the same setup described above to run benchmarking tests. You can change the specifications to test different workloads.
In this example, we use the following set of baseline parameters:
-c200G: Creates (or recreates) the sample file used in the test. It can be set in bytes, KiB, MiB, GiB, or blocks. In this case, a large file of 200-GiB target file is used to minimize memory caching.
-w100: Specifies the percentage of operations that are write requests (-w0 is equivalent to 100% read).
-b4K: Indicates the block size in bytes, KiB, MiB, or GiB. In this case, 4K block size is used to simulate a random I/O test.
-F4: Sets a total of four threads.
-r: Indicates the random I/O test (overrides the -s parameter).
-o128: Indicates the number of outstanding I/O requests per target per thread. This is also known as the queue depth. In this case, 128 is used to stress the CPU.
-W7200: Specifies the duration of the warm-up time before measurements start.
-d30: Specifies the duration of the test, not including warm-up.
-Sh: Disable software and hardware write caching (equivalent to -Suw).
For a complete list of parameters, see the GitHub repository.
Maximum write IOPS
We use a high queue depth of 128, a small block size of 8 KB, and four worker threads for driving Write operations. The write workers are driving traffic on the “NoCacheWrites” volume, which has three disks with cache set to “None”.
Run the following command for 30 seconds of warm-up and 30 seconds of measurement:
diskspd -c200G -w100 -b8K -F4 -r -o128 -W30 -d30 -Sh testfile.dat
Results show that the Standard_D8ds_v4 VM is delivering its maximum write IOPS limit of 12,800.
Maximum read IOPS
We use a high queue depth of 128, a small block size of four KB, and four worker threads for driving Read operations. The read workers are driving traffic on the “CacheReads” volume, which has one disk with cache set to “ReadOnly”.
Run the following command for two hours of warm-up and 30 seconds of measurement:
diskspd -c200G -b4K -F4 -r -o128 -W7200 -d30 -Sh testfile.dat
Results show that the Standard_D8ds_v4 VM is delivering its maximum read IOPS limit of 77,000.
Maximum throughput
To get the maximum read and write throughput, you can change to a larger block size of 64 KB.
FIO
FIO is a popular tool to benchmark storage on the Linux VMs. It has the flexibility to select different IO sizes, sequential or random reads and writes. It spawns worker threads or processes to perform the specified I/O operations. You can specify the type of I/O operations each worker thread must perform using job files. We created one job file per scenario illustrated in the examples below. You can change the specifications in these job files to benchmark different workloads running on Premium Storage. In the examples, we are using a Standard_D8ds_v4 running Ubuntu. Use the same setup described in the beginning of the benchmark section and warm up the cache before running the benchmark tests.
Before you begin, download FIO and install it on your virtual machine.
Run the following command for Ubuntu,
apt-get install fio
We use four worker threads for driving Write operations and four worker threads for driving Read operations on the disks. The write workers are driving traffic on the "nocache" volume, which has three disks with cache set to "None". The read workers are driving traffic on the "readcache" volume, which has one disk with cache set to "ReadOnly".
Maximum write IOPS
Create the job file with following specifications to get maximum Write IOPS. Name it "fiowrite.ini".
[global]
size=30g
direct=1
iodepth=256
ioengine=libaio
bs=4k
numjobs=4
[writer1]
rw=randwrite
directory=/mnt/nocache
Note the follow key things that are in line with the design guidelines discussed in previous sections. These specifications are essential to drive maximum IOPS,
A high queue depth of 256.
A small block size of 4 KB.
Multiple threads performing random writes.
Run the following command to kick off the FIO test for 30 seconds,
sudo fio --runtime 30 fiowrite.ini
While the test runs, you are able to see the number of write IOPS the VM and Premium disks are delivering. As shown in the sample below, the Standard_D8ds_v4 VM is delivering its maximum write IOPS limit of 12,800 IOPS.
Maximum read IOPS
Create the job file with following specifications to get maximum Read IOPS. Name it "fioread.ini".
[global]
size=30g
direct=1
iodepth=256
ioengine=libaio
bs=4k
numjobs=4
[reader1]
rw=randread
directory=/mnt/readcache
Note the follow key things that are in line with the design guidelines discussed in previous sections. These specifications are essential to drive maximum IOPS,
A high queue depth of 256.
A small block size of 4 KB.
Multiple threads performing random writes.
Run the following command to kick off the FIO test for 30 seconds,
sudo fio --runtime 30 fioread.ini
While the test runs, you are able to see the number of read IOPS the VM and Premium disks are delivering. As shown in the sample below, the Standard_D8ds_v4 VM is delivering more than 77,000 Read IOPS. This is a combination of the disk and the cache performance.
Maximum read and write IOPS
Create the job file with following specifications to get maximum combined Read and Write IOPS. Name it "fioreadwrite.ini".
[global]
size=30g
direct=1
iodepth=128
ioengine=libaio
bs=4k
numjobs=4
[reader1]
rw=randread
directory=/mnt/readcache
[writer1]
rw=randwrite
directory=/mnt/nocache
rate_iops=3200
Note the follow key things that are in line with the design guidelines discussed in previous sections. These specifications are essential to drive maximum IOPS,
A high queue depth of 128.
A small block size of 4 KB.
Multiple threads performing random reads and writes.
Run the following command to kick off the FIO test for 30 seconds,
sudo fio --runtime 30 fioreadwrite.ini
While the test runs, you are able to see the number of combined read and write IOPS the VM and Premium disks are delivering. As shown in the sample below, the Standard_D8ds_v4 VM is delivering more than 90,000 combined Read and Write IOPS. This is a combination of the disk and the cache performance.
Maximum combined throughput
To get the maximum combined Read and Write Throughput, use a larger block size and large queue depth with multiple threads performing reads and writes. You can use a block size of 64 KB and queue depth of 128.
Next steps
Proceed to our article on designing for high performance.
In that article, you create a checklist similar to your existing application for the prototype. Using Benchmarking tools you can simulate the workloads and measure performance on the prototype application. By doing so, you can determine which disk offering can match or surpass your application performance requirements. Then you can implement the same guidelines for your production application.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

8349
Learn about scalability and performance targets for virtual machine disks attached to VMs.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-scalability-targets 

>>>
Scalability and performance targets for VM disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Scalability and performance targets for VM disks

Article
05/23/2023

																	5 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
You can attach a number of data disks to an Azure virtual machine (VM). Based on the scalability and performance targets for a VM's data disks, you can determine the number and type of disk that you need to meet your performance and capacity requirements.
Important
For optimal performance, limit the number of highly utilized disks attached to the virtual machine to avoid possible throttling. If all attached disks aren't highly utilized at the same time, the virtual machine can support a larger number of disks. Additionally, when creating a managed disk from an existing managed disk, only 49 disks can be created concurrently. More disks can be created after some of the initial 49 have been created.
For Azure managed disks:
The following table illustrates the default and maximum limits of the number of resources per region per subscription. The limits remain the same irrespective of disks encrypted with either platform-managed keys or customer-managed keys. There is no limit for the number of Managed Disks, snapshots and images per resource group.
Resource
Limit
Standard managed disks
50,000
Standard SSD managed disks
50,000
Premium SSD managed disks
50,000
Premium SSD v2 managed disks
1,000
Premium SSD v2 managed disks capacity2
32,768
Ultra disks
1,000
Ultra disk capacity2
32,768
Standard_LRS snapshots1
75,000
Standard_ZRS snapshots1
75,000
Managed image
50,000
1An individual disk can have 500 incremental snapshots.
2This is the default max but higher capacities are supported by request. To request an increase in capacity, request a quota increase or contact Azure Support.
For standard storage accounts:
A Standard storage account has a maximum total request rate of 20,000 IOPS. The total IOPS across all of your virtual machine disks in a Standard storage account should not exceed this limit.
For unmanaged disks, you can roughly calculate the number of highly utilized disks supported by a single standard storage account based on the request rate limit. For example, for a Basic tier VM, the maximum number of highly utilized disks is about 66, which is 20,000/300 IOPS per disk. The maximum number of highly utilized disks for a Standard tier VM is about 40, which is 20,000/500 IOPS per disk.
For premium storage accounts:
A premium storage account has a maximum total throughput rate of 50 Gbps. The total throughput across all of your VM disks should not exceed this limit.
See VM sizes for more details.
Managed virtual machine disks
Standard HDD managed disks
Standard Disk Type
S4
S6
S10
S15
S20
S30
S40
S50
S60
S70
S80
Disk size in GiB
32
64
128
256
512
1,024
2,048
4,096
8,192
16,384
32,767
Base IOPS per disk
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 1,300
Up to 2,000
Up to 2,000
*Expanded IOPS per disk
N/A
N/A
N/A
N/A
N/A
Up to 1,500
Up to 3,000
Up to 3,000
Up to 3,000
Up to 3,000
Up to 3,000
Base throughput per disk
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 300 MB/s
Up to 500 MB/s
Up to 500 MB/s
*Expanded throughput per disk
N/A
N/A
N/A
N/A
N/A
Up to 150 MB/s
Up to 300 MB/s
Up to 500 MB/s
Up to 500 MB/s
Up to 500 MB/s
Up to 500 MB/s
* Only applies to disks with performance plus (preview) enabled.
Standard SSD managed disks
Standard SSD sizes
E1
E2
E3
E4
E6
E10
E15
E20
E30
E40
E50
E60
E70
E80
Disk size in GiB
4
8
16
32
64
128
256
512
1,024
2,048
4,096
8,192
16,384
32,767
Base IOPS per disk
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 500
Up to 2,000
Up to 4,000
Up to 6,000
*Expanded IOPS per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
Up to 1,500
Up to 3,000
Up to 6,000
Up to 6,000
Up to 6,000
Up to 6,000
Base throughput per disk
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 60 MB/s
Up to 400 MB/s
Up to 600 MB/s
Up to 750 MB/s
*Expanded throughput per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
Up to 150 MB/s
Up to 300 MB/s
Up to 600 MB/s
Up to 750 MB/s
Up to 750 MB/s
Up to 750 MB/s
Max burst IOPS per disk
600
600
600
600
600
600
600
600
1000
Max burst throughput per disk
150 MB/s
150 MB/s
150 MB/s
150 MB/s
150 MB/s
150 MB/s
150 MB/s
150 MB/s
250 MB/s
Max burst duration
30 min
30 min
30 min
30 min
30 min
30 min
30 min
30 min
30 min
* Only applies to disks with performance plus (preview) enabled.
Premium SSD managed disks: Per-disk limits
Premium SSD sizes 
P1
P2
P3
P4
P6
P10
P15
P20
P30
P40
P50
P60
P70
P80
Disk size in GiB
4
8
16
32
64
128
256
512
1,024
2,048
4,096
8,192
16,384
32,767
Base provisioned IOPS per disk
120
120
120
120
240
500
1,100
2,300
5,000
7,500
7,500
16,000
18,000
20,000
**Expanded provisioned IOPS per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
8,000
16,000
20,000
20,000
20,000
20,000
Base provisioned Throughput per disk
25 MB/s
25 MB/s
25 MB/s
25 MB/s
50 MB/s
100 MB/s
125 MB/s
150 MB/s
200 MB/s
250 MB/s
250 MB/s
500 MB/s
750 MB/s
900 MB/s
**Expanded provisioned Throughput per disk
N/A
N/A
N/A
N/A
N/A
N/A
N/A
N/A
300 MB/s
600 MB/s
900 MB/s
900 MB/s
900 MB/s
900 MB/s
Max burst IOPS per disk
3,500
3,500
3,500
3,500
3,500
3,500
3,500
3,500
30,000*
30,000*
30,000*
30,000*
30,000*
30,000*
Max burst throughput per disk
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
170 MB/s
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
1,000 MB/s*
Max burst duration
30 min
30 min
30 min
30 min
30 min
30 min
30 min
30 min
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Unlimited*
Eligible for reservation
No
No
No
No
No
No
No
No
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
Yes, up to one year
*Applies only to disks with on-demand bursting enabled.
** Only applies to disks with performance plus (preview) enabled.
Premium SSD managed disks: Per-VM limits
Resource
Limit
Maximum IOPS Per VM
80,000 IOPS with GS5 VM
Maximum throughput per VM
2,000 MB/s with GS5 VM
Unmanaged virtual machine disks
Standard unmanaged virtual machine disks: Per-disk limits
VM tier
Basic tier VM
Standard tier VM
Disk size
4,095 GB
4,095 GB
Maximum 8-KB IOPS per persistent disk
300
500
Maximum number of disks that perform the maximum IOPS
66
40
Premium unmanaged virtual machine disks: Per-account limits
Resource
Limit
Total disk capacity per account
35 TB
Total snapshot capacity per account
10 TB
Maximum bandwidth per account (ingress + egress)1
<=50 Gbps
1Ingress refers to all data from requests that are sent to a storage account. Egress refers to all data from responses that are received from a storage account.
Premium unmanaged virtual machine disks: Per-disk limits
Premium storage disk type
P10
P20
P30
P40
P50
Disk size
128 GiB
512 GiB
1,024 GiB (1 TB)
2,048 GiB (2 TB)
4,095 GiB (4 TB)
Maximum IOPS per disk
500
2,300
5,000
7,500
7,500
Maximum throughput per disk
100 MB/sec
150 MB/sec
200 MB/sec
250 MB/sec
250 MB/sec
Maximum number of disks per storage account
280
70
35
17
8
Premium unmanaged virtual machine disks: Per-VM limits
Resource
Limit
Maximum IOPS per VM
80,000 IOPS with GS5 VM
Maximum throughput per VM
2,000 MB/sec with GS5 VM
See also
Azure subscription and service limits, quotas, and constraints
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

18064
Learn about incremental snapshots for managed disks, including how to create them using the Azure portal, Azure PowerShell module, and Azure Resource Manager.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-incremental-snapshots 

>>>
Create an incremental snapshot - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Create an incremental snapshot for managed disks

Article
06/07/2023

																	7 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Incremental snapshots are point-in-time backups for managed disks that, when taken, consist only of the changes since the last snapshot. The first incremental snapshot is a full copy of the disk. The subsequent incremental snapshots occupy only delta changes to disks since the last snapshot. When you restore a disk from an incremental snapshot, the system reconstructs the full disk that represents the point in time backup of the disk when the incremental snapshot was taken. This capability for managed disk snapshots potentially allows them to be more cost-effective, since, unless you choose to, you don't have to store the entire disk with each individual snapshot. Just like full snapshots, incremental snapshots can be used to either create a full managed disk or a full snapshot. Both full snapshots and incremental snapshots can be used immediately after being taken. In other words, once you take either snapshot, you can immediately read the underlying data and use it to restore disks.
There are a few differences between an incremental snapshot and a full snapshot. Incremental snapshots will always use standard HDD storage, irrespective of the storage type of the disk, whereas full snapshots can use premium SSDs. If you're using full snapshots on Premium Storage to scale up VM deployments, we recommend you use custom images on standard storage in the Azure Compute Gallery. It will help you achieve a more massive scale with lower cost. Additionally, incremental snapshots potentially offer better reliability with zone-redundant storage (ZRS). If ZRS is available in the selected region, an incremental snapshot will use ZRS automatically. If ZRS isn't available in the region, then the snapshot will default to locally-redundant storage (LRS). You can override this behavior and select one manually but, we don't recommend that.
Incremental snapshots are billed for the used size only. You can find the used size of your snapshots by looking at the Azure usage report. For example, if the used data size of a snapshot is 10 GiB, the daily usage report will show 10 GiB/(31 days) = 0.3226 as the consumed quantity.
Restrictions
Incremental snapshots currently can't be moved between subscriptions.
You can currently only generate SAS URIs of up to five snapshots of a particular snapshot family at any given time.
You can't create an incremental snapshot for a particular disk outside of that disk's subscription.
Incremental snapshots can't be moved to another resource group. But, they can be copied to another resource group or region.
Up to seven incremental snapshots per disk can be created every five minutes.
A total of 500 incremental snapshots can be created for a single disk.
You can't get the changes between snapshots taken before and after you changed the size of the parent disk across 4 TB boundary. For example, You took an incremental snapshot snapshot-a when the size of a disk was 2 TB. Now you increased the size of the disk to 6 TB and then took another incremental snapshot snapshot-b. You can't get the changes between snapshot-a and snapshot-b. You have to download the full copy of snapshot-b created after the resize. Subsequently, you can get the changes between snapshot-b and snapshots created after snapshot-b.
Incremental snapshots of Premium SSD v2 and Ultra Disks
Incremental snapshots of Premium SSD v2 and Ultra Disks have the following extra restrictions:
You must request and receive access to the feature from this link.
Snapshots with a 512 logical sector size are stored as VHD, and can be used to create any disk type. Snapshots with a 4096 logical sector size are stored as VHDX and can only be used to create Ultra Disks and Premium SSD v2 disks, they can't be used to create other disk types. To determine which sector size your snapshot is, see check sector size.
Up to five disks may be simultaneously created from a snapshot of a Premium SSD v2 or an Ultra Disk.
When an incremental snapshot of either a Premium SSD v2 or an Ultra Disk is created, a background copy process for that disk is started. While a background copy is ongoing, you can have up to three total snapshots pending. The process must complete before any more snapshots of that disk can be created.
Incremental snapshots of a Premium SSD v2 or an Ultra disk can't be used immediately after they're created. The background copy must complete before you can create a disk from the snapshot. See Check status of snapshots or disks for details.
Disks created from an incremental snapshot of a Premium SSD v2 or an Ultra Disk can't be immediately attached to a VM once it's created. The background copy must complete before it can be attached. See Check disk creation status for details.
Note
Normally, when you take an incremental snapshot, and there aren't any changes, the size of that snapshot is 0 MiB. Currently, empty snapshots of disks with a 4096 logical sector size instead have a size of 6 MiB, when they'd normally be 0 MiB.
Regional availability
Incremental snapshots of Premium SSD v2 and Ultra Disks are currently available in the following regions:
Incremental snapshots of Ultra Disks are currently only available in North Europe, West Europe, Sweden Central, East US, East US 2, South Central US, West US, and West US 2.
Incremental snapshots of Premium SSD v2 disks are currently only available in North Europe, West Europe, East US, East US 2, West US 2.
Azure CLI
Azure PowerShell
Portal
Resource Manager Template
You can use the Azure CLI to create an incremental snapshot. You'll need the latest version of the Azure CLI. See the following articles to learn how to either install or update the Azure CLI.
The following script will create an incremental snapshot of a particular disk:
# Declare variables
diskName="yourDiskNameHere"
resourceGroupName="yourResourceGroupNameHere"
snapshotName="desiredSnapshotNameHere"
# Get the disk you need to backup
yourDiskID=$(az disk show -n $diskName -g $resourceGroupName --query "id" --output tsv)
# Create the snapshot
az snapshot create -g $resourceGroupName -n $snapshotName --source $yourDiskID --incremental true
Important
After taking a snapshot of an Ultra Disk, you must wait for the snapshot to complete before you can use it. See the Check status of snapshots or disks section for details.
You can identify incremental snapshots from the same disk with the SourceResourceId property of snapshots. SourceResourceId is the Azure Resource Manager resource ID of the parent disk.
You can use SourceResourceId to create a list of all snapshots associated with a particular disk. Replace yourResourceGroupNameHere with your value and then you can use the following example to list your existing incremental snapshots:
# Declare variables and create snapshot list
subscriptionId="yourSubscriptionId"
resourceGroupName="yourResourceGroupNameHere"
diskName="yourDiskNameHere"
az account set --subscription $subscriptionId
diskId=$(az disk show -n $diskName -g $resourceGroupName --query [id] -o tsv)
az snapshot list --query "[?creationData.sourceResourceId=='$diskId' && incremental]" -g $resourceGroupName --output table
You can use the Azure PowerShell module to create an incremental snapshot. You'll need the latest version of the Azure PowerShell module. The following command will either install it or update your existing installation to latest:
Install-Module -Name Az -AllowClobber -Scope CurrentUser
Once that is installed, sign in to your PowerShell session with Connect-AzAccount.
To create an incremental snapshot with Azure PowerShell, set the configuration with New-AzSnapShotConfig with the -Incremental parameter and then pass that as a variable to New-AzSnapshot through the -Snapshot parameter.
$diskName = "yourDiskNameHere"
$resourceGroupName = "yourResourceGroupNameHere"
$snapshotName = "yourDesiredSnapshotNameHere"
# Get the disk that you need to backup by creating an incremental snapshot
$yourDisk = Get-AzDisk -DiskName $diskName -ResourceGroupName $resourceGroupName
# Create an incremental snapshot by setting the SourceUri property with the value of the Id property of the disk
$snapshotConfig=New-AzSnapshotConfig -SourceUri $yourDisk.Id -Location $yourDisk.Location -CreateOption Copy -Incremental
New-AzSnapshot -ResourceGroupName $resourceGroupName -SnapshotName $snapshotName -Snapshot $snapshotConfig
Important
After taking a snapshot of a Premium SSD v2 or an Ultra Disk, you must wait for the snapshot to complete before you can use it.  See the Check status of snapshots or disks section for details.
You can identify incremental snapshots from the same disk with the SourceResourceId and the SourceUniqueId properties of snapshots. SourceResourceId is the Azure Resource Manager resource ID of the parent disk. SourceUniqueId is the value inherited from the UniqueId property of the disk. If you delete a disk and then create a new disk with the same name, the value of the UniqueId property changes.
You can use SourceResourceId and SourceUniqueId to create a list of all snapshots associated with a particular disk. Replace yourResourceGroupNameHere with your value and then you can use the following example to list your existing incremental snapshots:
$resourceGroupName = "yourResourceGroupNameHere"
$snapshots = Get-AzSnapshot -ResourceGroupName $resourceGroupName
$incrementalSnapshots = New-Object System.Collections.ArrayList
foreach ($snapshot in $snapshots)
{
    if($snapshot.Incremental -and $snapshot.CreationData.SourceResourceId -eq $yourDisk.Id -and $snapshot.CreationData.SourceUniqueId -eq $yourDisk.UniqueId){
        $incrementalSnapshots.Add($snapshot)
    }
}
$incrementalSnapshots
Sign into the Azure portal and navigate to the disk you'd like to snapshot.
On your disk, select Create a Snapshot
Select the resource group you'd like to use and enter a name.
Select Incremental and select Review + Create
Select Create
Important
After taking a snapshot of a Premium SSD v2 or an Ultra Disk, you must wait for the snapshot to complete before you can use it.  See the Check status of snapshots or disks section for details.
You can also use Azure Resource Manager templates to create an incremental snapshot. You'll need to make sure the apiVersion is set to 2022-03-22 and that the incremental property is also set to true. The following snippet is an example of how to create an incremental snapshot with Resource Manager templates:
{
  "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "diskName": {
      "type": "string",
      "defaultValue": "contosodisk1"
    },
  "diskResourceId": {
    "defaultValue": "<your_managed_disk_resource_ID>",
    "type": "String"
  }
  },
  "resources": [
  {
    "type": "Microsoft.Compute/snapshots",
    "name": "[concat( parameters('diskName'),'_snapshot1')]",
    "location": "[resourceGroup().location]",
    "apiVersion": "2022-03-22",
    "properties": {
      "creationData": {
        "createOption": "Copy",
        "sourceResourceId": "[parameters('diskResourceId')]"
      },
      "incremental": true
    }
  }
  ]
}
Important
After taking a snapshot of a Premium SSD v2 or an Ultra Disk, you must wait for the snapshot to complete before you can use it.  See the Check status of snapshots or disks section for details.
Check status of snapshots or disks
Incremental snapshots of Premium SSD v2 or Ultra Disks can't be used to create new disks until the background process copying the data into the snapshot has completed. Similarly, Premium SSD v2 or Ultra Disks created from incremental snapshots can't be attached to a VM until the background process copying the data into the disk has completed.
You can use either the CLI or PowerShell sections to check the status of the background copy from a disk to a snapshot and you can use the Check disk creation status section to check the status of a background copy from a snapshot to a disk.
CLI
You have two options for getting the status of snapshots. You can either get a list of all incremental snapshots associated with a specific disk, and their respective status, or you can get the status of an individual snapshot.
CLI - List incremental snapshots
The following script returns a list of all snapshots associated with a particular disk. The value of the CompletionPercent property of any snapshot must be 100 before it can be used. Replace yourResourceGroupNameHere, yourSubscriptionId, and yourDiskNameHere with your values then run the script:
# Declare variables and create snapshot list
subscriptionId="yourSubscriptionId"
resourceGroupName="yourResourceGroupNameHere"
diskName="yourDiskNameHere"
az account set --subscription $subscriptionId
diskId=$(az disk show -n $diskName -g $resourceGroupName --query [id] -o tsv)
az snapshot list --query "[?creationData.sourceResourceId=='$diskId' && incremental]" -g $resourceGroupName --output table
CLI - Individual snapshot
You can also check the status of an individual snapshot by checking the CompletionPercent property. Replace $sourceSnapshotName with the name of your snapshot then run the following command. The value of the property must be 100 before you can use the snapshot for restoring disk or generate a SAS URI for downloading the underlying data.
az snapshot show -n $sourceSnapshotName -g $resourceGroupName --query [completionPercent] -o tsv
PowerShell
You have two options for getting the status of snapshots. You can either get a list of all incremental snapshots associated with a particular disk and their respective status, or you can get the status of an individual snapshot.
PowerShell - List incremental snapshots
The following script returns a list of all incremental snapshots associated with a particular disk that haven't completed their background copy. Replace yourResourceGroupNameHere and yourDiskNameHere, then run the script.
$resourceGroupName = "yourResourceGroupNameHere"
$snapshots = Get-AzSnapshot -ResourceGroupName $resourceGroupName
$diskName = "yourDiskNameHere"
$yourDisk = Get-AzDisk -DiskName $diskName -ResourceGroupName $resourceGroupName
$incrementalSnapshots = New-Object System.Collections.ArrayList
foreach ($snapshot in $snapshots)
{
    if($snapshot.Incremental -and $snapshot.CreationData.SourceResourceId -eq $yourDisk.Id -and $snapshot.CreationData.SourceUniqueId -eq $yourDisk.UniqueId)
    {
    $targetSnapshot=Get-AzSnapshot -ResourceGroupName $resourceGroupName -SnapshotName $snapshotName
        {
        if($targetSnapshot.CompletionPercent -lt 100)
            {
            $incrementalSnapshots.Add($targetSnapshot)
            }
        }
    }
}
$incrementalSnapshots
PowerShell - individual snapshots
You can check the CompletionPercent property of an individual snapshot to get its status. Replace yourResourceGroupNameHere and yourSnapshotName then run the script. The value of the property must be 100 before you can use the snapshot for restoring disk or generate a SAS URI for downloading the underlying data.
$resourceGroupName = "yourResourceGroupNameHere"
$snapshotName = "yourSnapshotName"
$targetSnapshot=Get-AzSnapshot -ResourceGroupName $resourceGroupName -SnapshotName $snapshotName
$targetSnapshot.CompletionPercent
Check disk creation status
When creating a disk from either a Premium SSD v2 or an Ultra Disk snapshot, you must wait for the background copy process to complete before you can attach it. Currently, you must use the Azure CLI to check the progress of the copy process.
The following script gives you the status of an individual disk's copy process. The value of completionPercent must be 100 before the disk can be attached.
subscriptionId=yourSubscriptionID
resourceGroupName=yourResourceGroupName
diskName=yourDiskName
az account set --subscription $subscriptionId
az disk show -n $diskName -g $resourceGroupName --query [completionPercent] -o tsv
Check sector size
Snapshots with a 4096 logical sector size can only be used to create Premium SSD v2 or Ultra Disks. They can't be used to create other disk types. Snapshots of disks with 4096 logical sector size are stored as VHDX, whereas snapshots of disks with 512 logical sector size are stored as VHD. Snapshots inherit the logical sector size from the parent disk.
To determine whether or your Premium SSD v2 or Ultra Disk snapshot is a VHDX or a VHD, get the LogicalSectorSize property of the snapshot.
The following command displays the logical sector size of a snapshot:
az snapshot show -g resourcegroupname -n snapshotname --query [creationData.logicalSectorSize] -o tsv
Next steps
See Copy an incremental snapshot to a new region to learn how to copy an incremental snapshot across regions.
If you have additional questions on snapshots, see the snapshots section of the FAQ.
If you'd like to see sample code demonstrating the differential capability of incremental snapshots, using .NET, see Copy Azure Managed Disks backups to another region with differential capability of incremental snapshots.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

8625
Learn how to copy an incremental snapshot of a managed disk to a different region.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-copy-incremental-snapshot-across-regions 

>>>
Copy a snapshot to a new region - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Copy an incremental snapshot to a new region

Article
04/23/2023

																	2 contributors
Feedback
In this article
There are two options for copying an incremental snapshot across regions. The first option, a managed process (recommended), that will perform the copy for you. This process is handled by Azure and removes the maintenance overhead of managing the copy process by staging a storage account in the target region. Azure ensures that only changes since the last snapshot in the target region are copied to the target region to reduce the data footprint, reducing the recovery point objective. You can check the process of a copy so you know when a target snapshot is ready to restore disks. For this managed process, you're only billed for the bandwidth cost of the data transfer across the region, and the read transactions on the source snapshot. Don't delete your source snapshot while the target snapshot is being copied.
The second option is a manual copy, where you get the changes between two incremental snapshots, down to the block level, and manually copy it from one region to another. Most users should use the managed process but, if you're interested in improving the copy speed, the second option allows you to use your compute resources to make the copy faster.
This article covers copying an incremental snapshot from one region to another. See Create an incremental snapshot for managed disks for conceptual details on incremental snapshots.
Restrictions
You can copy 100 incremental snapshots in parallel at the same time per subscription per region.
If you use the REST API, you must use version 2020-12-01 or newer of the Azure Compute REST API.
You can only copy one incremental snapshot of a particular disk at a time.
Snapshots must be copied in the order they were created.
Managed copy
Azure CLI
Azure PowerShell
Portal
Resource Manager Template
You can use the Azure CLI to copy an incremental snapshot. You need the latest version of the Azure CLI. See the following articles to learn how to either install or update the Azure CLI.
The following script copies an incremental snapshot from one region to another:
subscriptionId=<yourSubscriptionID>
resourceGroupName=<yourResourceGroupName>
targetSnapshotName=<name>
sourceSnapshotResourceId=<sourceSnapshotResourceId>
targetRegion=<validRegion>
sourceSnapshotId=$(az snapshot show -n $sourceSnapshotName -g $resourceGroupName --query [id] -o tsv)
az snapshot create -g $resourceGroupName -n $targetSnapshotName -l $targetRegion --source $sourceSnapshotId --incremental --copy-start
Check copy status
You can check the status of an individual snapshot by checking the CompletionPercent property. Replace $sourceSnapshotName with the name of your snapshot then run the following command. The value of the property must be 100 before you can use the snapshot for restoring disk or generate a SAS URI for downloading the underlying data.
az snapshot show -n $sourceSnapshotName -g $resourceGroupName --query [completionPercent] -o tsv
You can use the Azure PowerShell module to copy an incremental snapshot. You'll need the latest version of the Azure PowerShell module. The following command will either install it or update your existing installation to latest:
Install-Module -Name Az -AllowClobber -Scope CurrentUser
Once that is installed, sign in to your PowerShell session with Connect-AzAccount.
The following script will copy an incremental snapshot from one region to another.
$subscriptionId="yourSubscriptionIdHere"
$resourceGroupName="yourResourceGroupNameHere"
$sourceSnapshotName="yourSourceSnapshotNameHere"
$targetSnapshotName="yourTargetSnapshotNameHere"
$targetRegion="desiredRegion"
Set-AzContext -Subscription $subscriptionId
$sourceSnapshot=Get-AzSnapshot -ResourceGroupName $resourceGroupName -SnapshotName $sourceSnapshotName
$snapshotconfig = New-AzSnapshotConfig -Location $targetRegion -CreateOption CopyStart -Incremental -SourceResourceId $sourceSnapshot.Id
New-AzSnapshot -ResourceGroupName $resourceGroupName -SnapshotName $targetSnapshotName -Snapshot $snapshotconfig
Check copy status
You can check the CompletionPercent property of an individual snapshot to get its status. Replace yourResourceGroupNameHere and yourSnapshotName then run the script. The value of the property must be 100 before you can use the snapshot for restoring disk or generate a SAS URI for downloading the underlying data.
$resourceGroupName = "yourResourceGroupNameHere"
$snapshotName = "yourSnapshotName"
$targetSnapshot=Get-AzSnapshot -ResourceGroupName $resourceGroupName -SnapshotName $snapshotName
$targetSnapshot.CompletionPercent
You can also copy an incremental snapshot across regions in the Azure portal. However, you must use this specific link to access the portal, for now: https://aka.ms/incrementalsnapshot
Sign in to the Azure portal and navigate to the incremental snapshot you'd like to migrate.
Select Copy snapshot.
For Snapshot type under Instance details select Incremental.
Change the Region to the region you'd like to copy the snapshot to.
Select Review + Create and then Create.
You can also use Azure Resource Manager templates to copy an incremental snapshot. You must use version 2020-12-01 or newer of the Azure Compute REST API. The following snippet is an example of how to copy an incremental snapshot across regions with Resource Manager templates:
{
    "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#",
    "contentVersion": "1.0.0.0",
    "parameters": {
        "name": {
            "defaultValue": "isnapshot1",
            "type": "String"
        },
        "sourceSnapshotResourceId": {
            "defaultValue": "<your_incremental_snapshot_resource_ID>",
            "type": "String"
        },
        "skuName": {
            "defaultValue": "Standard_LRS",
            "type": "String"
        },
        "targetRegion": {
            "defaultValue": "desired_region",
            "type": "String"
        }
    },
    "variables": {},
    "resources": [
        {
            "type": "Microsoft.Compute/snapshots",
            "sku": {
                "name": "[parameters('skuName')]",
                "tier": "Standard"
            },
            "name": "[parameters('name')]",
            "apiVersion": "2020-12-01",
            "location": "[parameters('targetRegion')]",
            "scale": null,
            "properties": {
                "creationData": {
                    "createOption": "CopyStart",
                    "sourceResourceId": "[parameters('sourceSnapshotResourceId')]"
                },
                "incremental": true
            },
            "dependsOn": []
        }
    ]
}
Manual copy
Incremental snapshots offer a differential capability. They enable you to get the changes between two incremental snapshots of the same managed disk, down to the block level. You can use this to reduce your data footprint when copying snapshots across regions.  For example, you can download the first incremental snapshot as a base blob in another region. For the subsequent incremental snapshots, you can copy only the changes since the last snapshot to the base blob. After copying the changes, you can take snapshots on the base blob that represent your point in time backup of the disk in another region. You can restore your disk either from the base blob or from a snapshot on the base blob in another region.
Next steps
If you'd like to see sample code demonstrating the differential capability of incremental snapshots, using .NET, see Copy Azure Managed Disks backups to another region with differential capability of incremental snapshots.
If you have additional questions on snapshots, see the snapshots section of the FAQ.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

10046
Learn about the Azure Disk backup solution.
https://learn.microsoft.com/en-us/azure/backup/disk-backup-overview?toc=/azure/virtual-machines/toc.json 

>>>
Overview of Azure Disk Backup - Azure Backup | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Overview of Azure Disk Backup

Article
02/02/2023

																	7 contributors
Feedback
In this article
Azure Disk Backup is a native, cloud-based backup solution that protects your data in managed disks. It's a simple, secure, and cost-effective solution that enables you to configure protection for managed disks in a few steps. It assures that you can recover your data in a disaster scenario.
Azure Disk Backup offers a turnkey solution that provides snapshot lifecycle management for managed disks by automating periodic creation of snapshots and retaining it for configured duration using backup policy. You can manage the disk snapshots with zero infrastructure cost and without the need for custom scripting or any management overhead. This is a crash-consistent backup solution that takes point-in-time backup of a managed disk using incremental snapshots with support for multiple backups per day. It's also an agent-less solution and doesn't impact production application performance. It supports backup and restore of both OS and data disks (including shared disks), whether or not they're currently attached to a running Azure virtual machine.
If you require application-consistent backup of virtual machine including the data disks, or an option to restore an entire virtual machine from backup, restore a file or folder, or restore to a secondary region, then use the Azure VM backup solution. Azure Backup offers side-by-side support for backup of managed disks using Disk Backup in addition to Azure VM backup solutions. This is useful when you need once-a-day application consistent backups of virtual machines and also more frequent backups of OS disks or a specific data disk that are crash consistent, and don't impact the production application performance.
Azure Disk Backup is integrated into Backup Center, which provides a single unified management experience in Azure for enterprises to govern, monitor, operate, and analyze backups at scale.
Key benefits of Disk Backup
Azure Disk backup is an agentless and crash consistent solution that uses incremental snapshots and offers the following advantages:
More frequent and quick backups without interrupting the virtual machine.
Doesn't affect the performance of the production application.
No security concerns since it doesn't require running custom scripts or installing agents.
A cost-effective solution to back up specific disks when compared to backing up entire virtual machine.
Azure Disk backup solution is useful in the following scenarios:
Need for frequent backups per day without application being quiescent.
Apps running in a  cluster scenario: both Windows Server Failover Cluster and Linux clusters are writing to shared disks.
Specific need for agentless backup because of security or performance concerns on the application.
Application consistent backup of VM isn't feasible since line-of-business apps don't support Volume Shadow Copy Service (VSS).
Consider Azure Disk Backup in scenarios where:
A mission-critical application is running on an Azure Virtual machine that demands multiple backups per day to meet the recovery point objective, but without impacting the production environment or application performance.
Your organization or industry regulation restricts installing agents because of security concerns.
Executing custom pre or post scripts and invoking freeze and thaw on Linux virtual machines to get application-consistent backup puts undue overhead on production workload availability.
Containerized applications running on Azure Kubernetes Service (AKS cluster) are using managed disks as persistent storage. Today, you must back up the managed disk via automation scripts that are hard to manage.
A managed disk is holding critical business data, used as a file-share, or contains database backup files, and you want to optimize backup cost by not investing in Azure VM backup.
You have many Linux and Windows single-disk virtual machines (that is, a virtual machine with just an OS disk and no data disks attached) that host web server, state-less machines, or serves as a staging environment with application configuration settings, and you need a cost efficient backup solution to protect the OS disk. For example, to trigger a quick on-demand backup before upgrading or patching the virtual machine.
A virtual machine is running an OS configuration that is unsupported by Azure VM backup solution (for example, Windows 2008 32-bit Server).
How the backup and restore process works
The first step in configuring backup for Azure Managed Disks is creating a Backup vault. The vault gives you a consolidated view of the backups configured across different workloads. Azure Disk backup supports only Operational Tier backup. Copying of backups to the vault storage tier is not supported. So, the Backup vault storage redundancy setting (LRS/GRS) doesn't apply to the backups stored in Operational Tier.
Then create a Backup policy that allows you to configure backup frequency and retention duration.
To configure backup, go to the Backup vault, assign a backup policy, select the managed disk that needs to be backed up and provide a resource group where the snapshots are to be stored and managed. Azure Backup automatically triggers scheduled backup jobs that create an incremental snapshot of the disk according to the backup frequency. Older snapshots are deleted according to the retention duration specified by the backup policy.
Azure Backup uses incremental snapshots of the managed disk. Incremental snapshots are a cost-effective, point-in-time backup of managed disks that are billed for the delta changes to the disk since the last snapshot. These are always stored on the most cost-effective storage, standard HDD storage regardless of the storage type of the parent disks. The first snapshot of the disk will occupy the used size of the disk, and consecutive incremental snapshots store delta changes to the disk since the last snapshot. Azure Backup automatically assigns tag to the snapshots it creates to uniquely identify them.
Once you configure the backup of a managed disk, a backup instance will be created within the backup vault. Using the backup instance, you can find health of backup operations, trigger on-demand backups, and perform restore operations. You can also view health of backups across multiple vaults and backup instances using Backup Center, which provides a single pane of glass view.
To restore, just select the recovery point from which you want to restore the disk. Provide the resource group where the restored disk is to be created from the snapshot. Azure Backup provides an instant restore experience since the snapshots are stored locally in your subscription.
Backup Vault uses Managed Identity to access other Azure resources. To configure backup of a managed disk and to restore from past backup, Backup Vault’s managed identity requires a set of permissions on the source disk, the snapshot resource group where snapshots are created and managed, and the target resource group where you want to restore the backup. You can grant permissions to the managed identity by using Azure role-based access control (Azure RBAC). Managed identity is a service principal of a special type that may only be used with Azure resources. Learn more about Managed Identities.
Currently Azure Disk Backup supports operational backup of managed disks and doesn't copy the backups to Backup Vault storage. Refer to the support matrix for a detailed list of supported and unsupported scenarios, and region availability.
Pricing
Azure Backup uses incremental snapshots of the managed disk. Incremental snapshots are charged per GiB of the storage occupied by the delta changes since the last snapshot. For example, if you're using a managed disk with a provisioned size of 128 GiB, with 100 GiB used, the first incremental snapshot is billed only for the used size of 100 GiB. 20 GiB of data is added on the disk before you create the second snapshot. Now, the second incremental snapshot is billed for only 20 GiB.
Incremental snapshots are always stored on standard storage, irrespective of the storage type of parent-managed disks, and are charged based on  the pricing of standard storage. For example, incremental snapshots of a Premium SSD-Managed Disk are stored on standard storage. By default, they are stored on ZRS  in regions that support ZRS. Otherwise, they are stored on locally redundant storage (LRS). The per GiB pricing of both the options, LRS and ZRS, is the same.
The snapshots created by Azure Backup are stored in the resource group within your Azure subscription and incur Snapshot Storage charges. For more details about the snapshot pricing, see Managed Disk Pricing. Because the snapshots aren't copied to the Backup Vault, Azure Backup doesn't charge a Protected Instance fee and Backup Storage cost doesn't apply.
The number of recovery points is determined by the Backup policy used to configure backups of the disk backup instances. Older block blobs are deleted according to the garbage collection process as the corresponding older recovery points are pruned.
Next steps
Azure Disk Backup support matrix
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

13324
Learn how to back up Azure Managed Disks from the Azure portal.
https://learn.microsoft.com/en-us/azure/backup/backup-managed-disks?toc=/azure/virtual-machines/toc.json 

>>>
Back up Azure Managed Disks - Azure Backup | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Back up Azure Managed Disks

Article
02/02/2023

																	5 contributors
Feedback
In this article
This article explains how to back up Azure Managed Disk from the Azure portal.
In this article, you'll learn how to:
Create a Backup vault
Create a backup policy
Configure a backup of an Azure Disk
Run an on-demand backup job
For information on the Azure Disk backup region availability, supported scenarios and limitations, see the support matrix.
Create a Backup vault
A Backup vault is a storage entity in Azure that holds backup data for various newer workloads that Azure Backup supports, such as Azure Database for PostgreSQL servers and Azure Disks. Backup vaults make it easy to organize your backup data, while minimizing management overhead. Backup vaults are based on the Azure Resource Manager model of Azure, which provides enhanced capabilities to help secure backup data.
Sign in to the Azure portal at https://portal.azure.com.
Type Backup center in the search box.
Under Services, select Backup center.
In the Backup center page, select Vault.
In the Initiate: Create Vault screen, select Backup vault, and Proceed.
In the Basics tab, provide subscription, resource group, backup vault name, region, and backup storage redundancy. Continue by selecting Review + create. Learn more about creating a Backup vault.
Create Backup policy
In the DemoVault Backup vault created in the previous step, go to Backup policies and select Add.
In the Basics tab, provide policy name, select Datasource type as Azure Disk. The vault is already prepopulated and the selected vault properties are presented.
Note
Although the selected vault may have the global-redundancy setting, currently Azure Disk Backup supports snapshot datastore only. All backups are stored in a resource group in your subscription and aren't copied to backup vault storage.
In the Backup policy tab, select the backup schedule frequency.
Azure Disk Backup offers multiple backups per day. If you require more frequent backups, choose the Hourly backup frequency with the ability to take backups with intervals of every 1, 2, 4, 6, 8, or 12 hours. The backups are scheduled based on the Time interval selected. For example, if you select Every 4 hours, then the backups are taken at approximately in the interval of every 4 hours so the backups are distributed equally across the day. If a once a day backup is sufficient, then choose the Daily backup frequency. In the daily backup frequency, you can specify the time of the day when your backups are taken. It's important to note that the time of the day indicates the backup start time and not the time when the backup completes. The time required for completing the backup operation is dependent on various factors including size of the disk, and churn rate between consecutive backups. However, Azure Disk backup is an agentless backup that uses incremental snapshots, which doesn't impact the production application performance.
In the Backup policy tab, select retention settings that meet the recovery point objective (RPO) requirement.
The default retention rule applies if no other retention rule is specified. The default retention rule can be modified to change the retention duration, but it cannot be deleted. You can add a new retention rule by selecting Add retention rule.
You can pick first successful backup taken daily or weekly, and provide the retention duration that the specific backups are to be retained before they're deleted. This option is useful to retain specific backups of the day or week for a longer duration of time. All other frequent backups can be retained for a shorter duration.
Note
Azure Backup for Managed Disks uses incremental snapshots which are limited to 500 snapshots per disk. To allow you to take on-demand backups aside from scheduled backups, backup policy limits the total backups to 450. Learn more about incremental snapshots for managed disk.
Complete the backup policy creation by selecting Review + create.
Configure backup
Azure Disk backup supports only the operational tier backup. Copying of backups to the vault storage tier is currently not supported. The Backup vault storage redundancy setting (LRS/GRS) doesn’t apply to the backups stored in the operational tier.                       Incremental snapshots are stored in a Standard HDD storage, irrespective of the selected storage type of the parent disk. For additional reliability, incremental snapshots are stored on Zone Redundant Storage (ZRS) by default in ZRS supported regions.
Azure Disk backup supports cross-subscription (backup vault in one subscription and the source disk in another) backup and restore. Currently, cross-region backup and restore aren't supported by Azure Disk backup, that is, the backup vault and disk to back up are in different regions.              So, to use Azure Disk backup, ensure that the backup vault and disk to back up are in the same region.
Once you configure the disk backup, you can’t change the Snapshot Resource Group that’s assigned to a backup instance.
To configure disk backup, follow these steps:
Go to Backup center -> Overview and click + Backup to start configuring backup of the disk.
Select Azure Disks in the Datasource type drop-down list, and then click Continue.
Select a Backup vault and click Next to proceed.
Note
Ensure that both the backup vault and the disk to be backed up are in same location.
Azure Backup uses incremental snapshots of managed disks, which store only the delta changes to the disk as the last snapshot on Standard HDD storage, regardless of the storage type of the parent disk. For additional reliability, incremental snapshots are stored on Zone Redundant Storage (ZRS) by default in the ZRS supported regions. Currently, Azure Disk Backup supports operational backup of managed disks that doesn't copy backups to the Backup vault storage. So, the backup storage redundancy setting of the Backup vault doesn’t apply to the recovery points.
On the Backup Policy tab, choose a Backup policy.
On the Datasources tab, click + Add/Edit to choose one or more Azure Managed Disks for which you want to configure backup.
Note
While the portal allows you to select multiple disks and configure backup, each disk is an individual backup instance. Currently, Azure Disk Backup only supports backup of individual disks. Point-in-time backup of multiple disks attached to a virtual machine isn't supported.
In the Azure  portal, you can only select disks within the same subscription. If you have several disks to be backed up or if the disks reside in different subscriptions, you can use scripts (PowerShell/CLI) to automate.
See the support matrix for more information on the Azure Disk backup region availability, supported scenarios, and limitations.
Select Snapshot resource group and click Validate to initiate prerequisites checks.
Choosing resource group for storing and managing snapshots:
Don't select the same resource group as that of the source disk.
As a guideline, it's recommended to create a dedicated resource group as a snapshot datastore to be used by the Azure Backup service. Having a dedicated resource group allows restricting access permissions on the resource group, providing safety and ease of management of the backup data.
You can use this resource group for storing snapshots across multiple disks that are being (or planned to be) backed up.
You can't create an incremental snapshot for a particular disk outside of that disk's subscription. So, choose the resource group within the same subscription where the disk needs to be backed up. Learn more about incremental snapshot for managed disks.
Once you configure the backup of a disk, you can’t change the Snapshot Resource Group that’s assigned to a backup instance.
Once the validation is complete, check if there are any errors reported in the Backup readiness column.
Note
Validation might take few minutes to complete. Validation may fail if:
A disk is unsupported. See the support matrix for unsupported scenarios.
The Backup vault managed identity does not have valid role assignments on the disk to be backed up or on the snapshot resource group where incremental snapshots are stored.
If the Role assignment not done error message displays in the Backup readiness column, the Backup vault managed identity needs role permissions on the selected disk(s) and/or   on the Snapshot resource group.
To configure backup of managed disks, the following prerequisites are required:
Note
Backup vault uses managed identity to access other Azure resources. To configure a backup of managed disks, Backup Vault’s managed identity requires a set of permissions on the source disks and resource groups where snapshots are created and managed.
A system-assigned managed identity is restricted to one per resource and is tied to the lifecycle of this resource. To grant permissions to the managed identity, use Azure role-based access control (Azure RBAC). Managed identity is a service principal of a special type that may only be used with Azure resources. Learn more about managed identities.
Assign the Disk Backup Reader role to Backup Vault’s managed identity on the Source disk that needs to be backed up.
Assign the Disk Snapshot Contributor role to the Backup vault’s managed identity on the Resource group where backups are created and managed by the Azure Backup service. The disk snapshots are stored in a resource group within your subscription. To allow Azure Backup service to create, store, and manage snapshots, you need to provide permissions to the backup vault.
Note
The Configure Backup flow using Azure portal helps you in granting required role permissions to the above resources.
Select the checkbox next to each row with the Role assignment not done error message status in the Backup readiness column and click Add missing roles to automatically grant required role permissions for the Backup vault managed identity on selected resources.
Click Confirm to provide consent. Azure Backup will automatically propagate role assignment changes on your behalf and try to revalidate.
If you want to grand permission for the Backup vault managed identity to the selected disk(s) and snapshot resource group, select Resource in the Scope drop-down list.
Tip
If you plan to configure backup for other disks in the same resource group/subscription in future, you can choose to provide permission at the scope of resource group or subscription.
Note
In some cases, it can take up to 30 minutes for the role assignments to propagate, causing revalidation failure. In this scenario, retry after some time.
If the Add missing roles action fails  to assign permissions with the error ‘Insufficient permission for role assignment’ in Backup readiness column, it indicates that you don’t have the privilege to assign role permissions. Choose Download role assignment template to download role assignments as scripts and seek support from your IT Administrator to run the scripts to complete the prerequisites.
After a successful validation, click Next to move to the Review and configure tab, and then click Configure backup to configure backup of selected disks.
Run an on-demand backup
In the DemoVault Backup vault created in the previous step, go to Backup instances and select a backup instance.
In the Backup instances screen, you'll find:
essential information including source disk name, the snapshot resource group where incremental snapshots are stored, backup vault, and backup policy.
Job status showing summary of backup and restore operations and their status in the last seven days.
A list of restore points for the selected time period.
Select Backup to initiate an on-demand backup.
Select one of the retention rules associated with the backup policy. This retention rule will determine the retention duration of this on-demand  backup. Select Backup now to start the backup.
Track a backup operation
The Azure Backup service creates a job for scheduled backups or if you trigger on-demand backup operation for tracking. To view the backup job status:
Go to the Backup instance screen. It shows the jobs dashboard with operation and status for the past seven days.
To view the status of the backup operation, select View all to show ongoing and past jobs of this backup instance.
Review the list of backup and restore jobs and their status. Select a job from the list of jobs to view job details.
Next steps
Restore Azure Managed Disks
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

8068
Learn how to restore Azure Managed Disks from the Azure portal.
https://learn.microsoft.com/en-us/azure/backup/restore-managed-disks?toc=/azure/virtual-machines/toc.json 

>>>
Restore Azure Managed Disks - Azure Backup | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Restore Azure Managed Disks

Article
02/02/2023

																	4 contributors
Feedback
In this article
This article explains how to restore Azure Managed Disks from a restore point created by Azure Backup.
Currently, the Original-Location Recovery (OLR) option of restoring by replacing existing the source disk from where the backups were taken isn't supported. You can restore from a recovery point to create a new disk either in the same resource group as that of the source disk from where the backups were taken or in any other resource group. This is known as Alternate-Location Recovery (ALR) and this helps to keep both the source disk and the restored (new) disk.
In this article, you'll learn how to:
Restore to create a new disk
Track the restore operation status
Restore to create a new disk
Backup Vault uses Managed Identity to access other Azure resources. To restore from backup, Backup vault’s managed identity requires a set of permissions on the resource group where the disk is to be restored.
Backup vault uses a system assigned managed identity, which is restricted to one per resource and is tied to the lifecycle of this resource. You can grant permissions to the managed identity by using Azure role-based access control (Azure RBAC). Managed identity is a service principal of a special type that may only be used with Azure resources. Learn more about Managed Identities.
The following pre-requisites are required to perform a restore operation:
Assign the Disk Restore Operator role to the Backup Vault’s managed identity on the Resource group where the disk will be restored by the Azure Backup service.
Note
You can choose the same resource group as that of the source disk from where backups are taken or to any other resource group within the same or a different subscription.
Go to the resource group where the disk is to be restored to. For example, the resource group is TargetRG.
Go to Access control (IAM) and select Add role assignments
On the right context pane, select Disk Restore Operator in the Role dropdown list. Select the backup vault’s managed identity and Save.
Tip
Type the backup vault's name to select the vault’s managed identity.
Verify that the backup vault's managed identity has the right set of role assignments on the resource group where the disk will be restored.
Go to Backup vault - > Identity and select Azure role assignments
Verify that the role, resource name, and resource type appear correctly.
Note
While the role assignments are reflected correctly on the portal, it may take approximately 15 minutes for the permission to be applied on the backup vault’s managed identity.
During scheduled backups or an on-demand backup operation, Azure Backup stores the disk incremental snapshots in the Snapshot Resource Group provided during configuring backup of the disk. Azure Backup uses these incremental snapshots during the restore operation. If the snapshots are deleted or moved from the Snapshot Resource Group or if the Backup vault role assignments are revoked on the Snapshot Resource Group, the restore operation will fail.
If the disk to be restored is encrypted with customer-managed keys (CMK) or using double encryption using platform-managed keys and customer-managed keys, then assign the Reader role permission to the Backup Vault’s managed identity on the Disk Encryption Set resource.
Once the prerequisites are met, follow these steps to perform the restore operation.
In the Azure portal, go to Backup center. Select Backup instances under the Manage section. From the list of backup instances, select the disk backup instance for which you want to perform the restore operation.
Alternately, you can perform this operation from the Backup vault you used to configure backup for the disk.
In the Backup instance screen, select the restore point that you want to use to perform the restore operation and select Restore.
In the Restore workflow, review the Basics and Select recovery point tab information, and select Next: Restore parameters.
In the Restore parameters tab, select the Target subscription and Target resource group where you want to restore the backup to. Provide the name of the disk to be restored. Select Next: Review + restore.
Tip
Disks being backed up by Azure Backup using the Disk Backup solution can also be backed up by Azure Backup using the Azure VM backup solution with the Recovery Services vault. If you have configured protection of the Azure VM to which this disk is attached, you can also use the Azure VM restore operation. You can choose to restore the VM, or disks and files or folders from the recovery point of the corresponding Azure VM backup instance. For more information, see Azure VM backup.
Once the validation is successful, select Restore to start the restore operation.
Note
Validation might take few minutes to complete before you can trigger restore operation. Validation may fail if:
a disk with the same name  provided in Restored disk name already exists in the Target resource group
the Backup vault's managed identity doesn't have valid role assignments on the Target resource group
the Backup vault's managed identity role assignments are revoked on the Snapshot resource group where incremental snapshots are stored
If incremental snapshots are deleted or moved from the snapshot resource group
Restore will create a new disk from the selected recovery point in the target resource group that was provided during the restore operation. To use the restored disk on an existing virtual machine, you'll need to perform more steps:
If the restored disk is a data disk, you can attach an existing disk to a virtual machine. If the restored disk is OS disk, you can swap the OS disk of a virtual machine from the Azure portal under the Virtual machine pane - > Disks menu in the Settings section.
For Windows virtual machines, if the restored disk is a data disk, follow the instructions to detach the original data disk from the virtual machine. Then attach the restored disk to the virtual machine. Follow the instructions to swap the OS disk of the virtual machine with the restored disk.
For Linux virtual machines, if the restored disk is a data disk, follow the instructions to detach the original data disk from the virtual machine. Then attach the restored disk to the virtual machine. Follow the instructions to swap the OS disk of  the virtual machine with the restored disk.
It's recommended that you revoke the Disk Restore Operator role assignment from the Backup vault's managed identity on the Target resource group after the successful completion of restore operation.
Track a restore operation
After you trigger the restore operation, the backup service creates a job for tracking. Azure Backup displays notifications about the job in the portal. To view the restore job progress:
Go to the Backup instance screen. It shows the jobs dashboard with operation and status for the past seven days.
To view the status of the restore operation, select View all to show ongoing and past jobs of this backup instance.
Review the list of backup and restore jobs and their status. Select a job from the list of jobs to view job details.
Next steps
Azure Disk Backup FAQ
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

16065
This article explains how to plan for backup and disaster recovery of IaaS virtual machines and managed disks in Azure.
https://learn.microsoft.com/en-us/azure/virtual-machines/backup-and-disaster-recovery-for-azure-iaas-disks 

>>>
Backup and disaster recovery for managed disks on Azure VMs - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Backup and disaster recovery for Azure managed disks

Article
06/14/2022

																	5 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets
This article explains how to plan for backup and disaster recovery for Azure managed disks.
First, we cover the built-in fault tolerance capabilities in the Azure platform that guard against local failures. We then discuss the disaster scenarios not fully covered by the built-in capabilities. We also show several examples of workload scenarios where different backup and disaster recovery considerations can apply. We also cover some disaster recovery solutions for managed disks.
Introduction
Azure uses various methods for redundancy and fault tolerance to protect customers from localized hardware failures. Local failures can include problems with an Azure Storage server machine that stores part of the data for a virtual disk or failures of solid-state drives (SSDs) or hard disk drives (HDDs) on that server. Isolated hardware component failures can happen during normal operations.
Azure is designed to be resilient to these failures. Major disasters can result in failures or the inaccessibility of many storage servers or even a whole data center. Although your virtual machines (VMs) and disks are normally protected from localized failures, additional steps are necessary to protect your workload from region-wide catastrophic failures, such as a major disaster, that can affect your VMs and disks.
In addition to the possibility of platform failures, problems with a customer application or data can occur. For example, a new version of your application might inadvertently make a change to the data that causes it to break. In that case, you might want to revert the application and the data to a prior version that contains the last known good state. This requires maintaining regular backups.
For regional disaster recovery, you must back up your infrastructure as a service (IaaS) VM disks to a different region.
Before we look at backup and disaster recovery options, let’s recap a few methods available for handling localized failures.
Azure IaaS resiliency
Resiliency refers to the tolerance for normal failures that occur in hardware components. Resiliency is the ability to recover from failures and continue to function. It's not about avoiding failures, but responding to failures in a way that avoids downtime or data loss. The goal of resiliency is to return the application to a fully functioning state following a failure. Azure VMs and managed disks are designed to be resilient to common hardware faults. Let's look at how the Azure IaaS platform provides this resiliency.
A VM consists mainly of two parts: a compute server and the persistent disks. Both affect the fault tolerance of a VM.
If the Azure compute host server that houses your VM experiences a hardware failure, which is rare, Azure is designed to automatically restore the VM on another server. In this scenario, your computer reboots, and the VM comes back up after some time. Azure automatically detects such hardware failures and begins recovery to help ensure the customer VM is available as soon as possible.
Regarding your managed disk, the durability of data is critical for a persistent storage platform. Azure customers have important business applications running on IaaS, and they depend on the persistence of the data. Azure designs protection for these IaaS disks, with three redundant copies of the data that is stored locally. These copies provide for high durability against local failures. If one of the hardware components that holds your disk fails, your VM is not affected, because there are two additional copies to support disk requests. It works fine, even if two different hardware components that support a disk fail at the same time (which is rare).
To ensure that you always maintain three replicas, Azure automatically creates a new copy of the data in the background if one of the three copies becomes unavailable. Therefore, it should not be necessary to use RAID with Azure disks for fault tolerance. A simple RAID 0 configuration should be sufficient for striping the disks, if necessary, to create larger volumes.
Because of this architecture, Azure has consistently delivered enterprise-grade durability for IaaS disks, with an industry-leading zero percent annualized failure rate.
Localized hardware faults on the compute host or in the storage platform can sometimes result in of the temporary unavailability of the VM that is covered by the Azure SLA for VM availability. Azure also provides an industry-leading SLA for single VM instances that use Azure premium SSDs.
To safeguard application workloads from downtime due to the temporary unavailability of a disk or VM, customers can use availability sets. Two or more virtual machines in an availability set provide redundancy for the application. Azure then creates these VMs and disks in separate fault domains with different power, network, and server components.
Because of these separate fault domains, localized hardware failures typically don't affect multiple VMs in the set at the same time. Having separate fault domains provides high availability for your application. It's considered a good practice to use availability sets when high availability is required.
Backup and disaster recovery
Disaster recovery is the ability to recover from rare, but major, incidents. These incidents include non-transient, wide-scale failures, such as a service disruption that affects an entire region. Disaster recovery includes data backup and archiving, and might include manual intervention, such as restoring a database from a backup.
The Azure platform’s built-in protection against localized failures might not fully protect the VMs/disks if a major disaster causes large-scale outages. These large-scale outages include catastrophic events, such as if a data center is hit by a hurricane, earthquake, fire, or if there is a large-scale hardware unit failure. In addition, you might encounter failures due to application or data issues.
To help protect your IaaS workloads from outages, you should plan for redundancy and have backups to enable recovery. For disaster recovery, you should back up in a different geographic location away from the primary site. This approach helps ensure your backup is not affected by the same event that originally affected the VM or disks. For more information, see Disaster recovery for Azure applications.
Your disaster recovery considerations might include the following aspects:
High availability: The ability of the application to continue running in a healthy state, without significant downtime. By healthy state, this state means that the application is responsive, and users can connect to the application and interact with it. Certain mission-critical applications and databases might be required to always be available, even when there are failures in the platform. For these workloads, you might need to plan redundancy for the application, as well as the data.
Data durability: In some cases, the main consideration is ensuring that the data is preserved if a disaster happens. Therefore, you might need a backup of your data in a different site. For such workloads, you might not need full redundancy for the application, but only a regular backup of the disks.
Backup and disaster recovery scenarios
Let’s look at a few typical examples of application workload scenarios and the considerations for planning for disaster recovery.
Scenario 1: Major database solutions
Consider a production database server, like SQL Server or Oracle, that can support high availability. Critical production applications and users depend on this database. The disaster recovery plan for this system might need to support the following requirements:
The data must be protected and recoverable.
The server must be available for use.
The disaster recovery plan might require maintaining a replica of the database in a different region as a backup. Depending on the requirements for server availability and data recovery, the solution might range from an active-active or active-passive replica site to periodic offline backups of the data. Relational databases, such as SQL Server and Oracle, provide various options for replication. For SQL Server, use SQL Server Always On Availability Groups for high availability.
NoSQL databases, like MongoDB, also support replicas for redundancy. The replicas for high availability are used.
Scenario 2: A cluster of redundant VMs
Consider a workload handled by a cluster of VMs that provide redundancy and load balancing. One example is a Cassandra cluster deployed in a region. This type of architecture already provides a high level of redundancy within that region. However, to protect the workload from a regional-level failure, you should consider spreading the cluster across two regions or making periodic backups to another region.
Scenario 3: IaaS application workload
Let's look at the IaaS application workload. For example, this application might be a typical production workload running on an Azure VM. It might be a web server or file server holding the content and other resources of a site. It might also be a custom-built business application running on a VM that stored its data, resources, and application state on the VM disks. In this case, it's important to make sure you take backups on a regular basis. Backup frequency should be based on the nature of the VM workload. For example, if the application runs every day and modifies data, then the backup should be taken every hour.
Another example is a reporting server that pulls data from other sources and generates aggregated reports. The loss of this VM or disks might lead to the loss of the reports. However, it might be possible to rerun the reporting process and regenerate the output. In that case, you don’t really have a loss of data, even if the reporting server is hit with a disaster. As a result, you might have a higher level of tolerance for losing part of the data on the reporting server. In that case, less frequent backups are an option to reduce costs.
Scenario 4: IaaS application data issues
IaaS application data issues are another possibility. Consider an application that computes, maintains, and serves critical commercial data, such as pricing information. A new version of your application had a software bug that incorrectly computed the pricing and corrupted the existing commerce data served by the platform. Here, the best course of action is to revert to the earlier version of the application and the data. To enable this, take periodic backups of your system.
Disaster recovery solution: Azure Disk Backup
Azure Disk Backup is a native, cloud-based backup solution that protects your data in managed disks. It's a simple, secure, and cost-effective solution that enables you to configure protection for managed disks in a few steps. It assures that you can recover your data in a disaster scenario.
Azure Disk Backup offers a turnkey solution that provides snapshot lifecycle management for managed disks by automating periodic creation of snapshots and retaining it for configured duration using backup policy. You can manage the disk snapshots with zero infrastructure cost and without the need for custom scripting or any management overhead. This is a crash-consistent backup solution that takes point-in-time backup of a managed disk using incremental snapshots with support for multiple backups per day. It's also an agent-less solution and doesn't impact production application performance. It supports backup and restore of both OS and data disks (including shared disks), whether or not they're currently attached to a running Azure VM.
For more details on Azure Disk Backup, see Overview of Azure Disk Backup.
Alternative solution: Consistent snapshots
If you are unable to use Azure Backup, you can implement your own backup mechanism by using snapshots. Creating consistent snapshots for all the disks used by a VM and then replicating those snapshots to another region is complicated. For this reason, Azure considers using the Backup service as a better option than building a custom solution.
If you use locally redundant storage for disks, you need to replicate the data yourself.
A snapshot is a representation of an object at a specific point in time. A snapshot incurs billing for the incremental size of the data it holds. For more information, see Create an incremental snapshot for managed disks.
Create snapshots while the VM is running
Although you can take a snapshot at any time, if the VM is running, there is still data being streamed to the disks. The snapshots might contain partial operations that were in flight. Also, if there are several disks involved, the snapshots of different disks might have occurred at different times. These scenarios may cause to the snapshots to be uncoordinated. This lack of coordination is especially problematic for striped volumes whose files might be corrupted if changes were being made during backup.
To avoid this situation, the backup process must implement the following steps:
Freeze all the disks.
Flush all the pending writes.
Create an incremental snapshot for managed disks for all the disks.
Some Windows applications, like SQL Server, provide a coordinated backup mechanism via a volume shadow service to create application-consistent backups. On Linux, you can use a tool like fsfreeze for coordinating the disks. This tool provides file-consistent backups, but not application-consistent snapshots. This process is complex, so you should consider using Azure Disk Backup or a third-party backup solution that already implements this procedure.
The previous process results in a collection of coordinated snapshots for all of the VM disks, representing a specific point-in-time view of the VM. This is a backup restore point for the VM. You can repeat the process at scheduled intervals to create periodic backups. See Copy the backups to another region for steps to copy the snapshots to another region for disaster recovery.
Create snapshots while the VM is offline
Another option to create consistent backups is to shut down the VM and take snapshots of each disk. Taking offline snapshots is easier than coordinating snapshots of a running VM, but it requires a few minutes of downtime.
Copy the snapshots to another region
Creation of the snapshots alone might not be sufficient for disaster recovery. You must also copy the snapshots to another region. See Copy an incremental snapshot to a new region.
Other options
SQL Server
SQL Server running in a VM has its own built-in capabilities to back up your SQL Server database to Azure Blob storage or a file share. For more information, see Back up and restore for SQL Server in Azure virtual machines. In addition to back up and restore, SQL Server Always On availability groups can maintain secondary replicas of databases. This ability greatly reduces the disaster recovery time.
Next steps
See Back up Azure unmanaged Virtual Machine disks with incremental snapshots.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

6394
Learn how to create a copy of an Azure VM to use as a backup or for troubleshooting issues using the portal, PowerShell, or CLI.
https://learn.microsoft.com/en-us/azure/virtual-machines/snapshot-copy-managed-disk 

>>>
Create an Azure snapshot of a virtual hard disk - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Create a snapshot of a virtual hard disk

Article
04/22/2022

																	5 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets
A snapshot is a full, read-only copy of a virtual hard disk (VHD). You can use a snapshot as a point-in-time backup, or to help troubleshoot virtual machine (VM) issues. You can take a snapshot of both operating system (OS) or data disk VHDs.
Create a snapshot of a VHD
If you want to use a snapshot to create a new VM, ensure that you first cleanly shut down the VM. This action clears any processes that are in progress.
Portal
PowerShell
Azure CLI
To create a snapshot using the Azure portal, complete these steps.
In the Azure portal, select Create a resource.
Search for and select Snapshot.
In the Snapshot window, select Create. The Create snapshot window appears.
For Resource group, select an existing resource group or enter the name of a new one.
Enter a Name, then select a Region and Snapshot type for the new snapshot. If you would like to store your snapshot in zone-resilient storage, you need to select a region that supports availability zones. For a list of supporting regions, see Azure regions with availability zones.
For Source subscription, select the subscription that contains the managed disk to be backed up.
For Source disk, select the managed disk to snapshot.
For Storage type, select Standard HDD, unless you require zone-redundant storage or high-performance storage for your snapshot.
If needed, configure settings on the Encryption, Networking, and Tags tabs. Otherwise, default settings are used for your snapshot.
Select Review + create.
This example requires that you use Cloud Shell or have the Azure CLI installed.
Follow these steps to take a snapshot with the New-AzSnapshotConfig and New-AzSnapshot cmdlets. This example assumes that you have a VM called myVM in the myResourceGroup resource group. The code sample provided creates a snapshot in the same resource group and within the same region as your source VM.
First, you'll use the New-AzSnapshotConfig cmdlet to create a configurable snapshot object. You can then use the New-AzSnapshot cmdlet to take a snapshot of the disk.
Set the required parameters. Update the values to reflect your environment.
$resourceGroupName = 'myResourceGroup'
$location = 'eastus'
$vmName = 'myVM'
$snapshotName = 'mySnapshot'
Use the Get-AzVM cmdlet to get the VM containing the VHD you want to copy.
$vm = Get-AzVM `
    -ResourceGroupName $resourceGroupName `
    -Name $vmName
Create the snapshot configuration. In the example, the snapshot is of the OS disk. By default, the snapshot uses locally redundant standard storage. We recommend that you store your snapshots in standard storage instead of premium storage whatever the storage type of the parent disk or target disk. Premium snapshots incur additional cost.
$snapshot =  New-AzSnapshotConfig `
    -SourceUri $vm.StorageProfile.OsDisk.ManagedDisk.Id `
    -Location $location `
    -CreateOption copy
If you want to store your snapshot in zone-resilient storage, you must create the snapshot in a region that supports [availability zones](../availability-zones/az-overview.md and include the -SkuName Standard_ZRS parameter. For a list of regions that support availability zones, see Azure regions with availability zones.
Take the snapshot.
New-AzSnapshot `
    -Snapshot $snapshot `
    -SnapshotName $snapshotName `
    -ResourceGroupName $resourceGroupName
Use the Get-AzSnapshot cmdlet to verify that your snapshot exists.
Get-AzSnapshot `
    -ResourceGroupName $resourceGroupName
This example requires that you use Cloud Shell or have the Azure CLI installed.
Follow these steps to take a snapshot with the az snapshot create command and the --source-disk parameter. This example assumes that you have a VM called myVM in the myResourceGroup resource group. The code sample provided creates a snapshot in the same resource group and within the same region as your source VM.
Get the disk ID with az vm show.
osDiskId=$(az vm show \
   -g myResourceGroup \
   -n myVM \
   --query "storageProfile.osDisk.managedDisk.id" \
   -o tsv)
Take a snapshot named osDisk-backup using az snapshot create. In the example, the snapshot is of the OS disk. By default, the snapshot uses locally redundant standard storage. We recommend that you store your snapshots in standard storage instead of premium storage whatever the storage type of the parent disk or target disk. Premium snapshots incur additional cost.
az snapshot create \
    -g myResourceGroup \
	--source "$osDiskId" \
	--name osDisk-backup
If you would like to store your snapshot in zone-resilient storage, you need to create it in a region that supports availability zones and include the optional --sku Standard_ZRS parameter. A list of availability zones can be found here.
Use az snapshot list to verify that your snapshot exists.
az snapshot list \
   -g myResourceGroup \
   -o table
Next steps
To recover using a snapshot, you must create a new disk from the snapshot, then either deploy a new VM, and use the managed disk as the OS disk, or attach the disk as a data disk to an existing VM.
Portal
PowerShell
Azure CLI
For more information, see the example in Create a VM from a VHD by using the Azure portal.
For more information, see the example in Create a Windows VM from a specialized disk by using PowerShell.
For more information, see the example in Create a complete Linux virtual machine with the Azure CLI.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

10246
Create a custom solution for backup and recovery of your Azure virtual machine disks using incremental snapshots.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/incremental-snapshots 

>>>
Use incremental snapshots for backup and recovery of unmanaged disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Back up Azure unmanaged Virtual Machine disks with incremental snapshots

Article
08/23/2021

																	8 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs
Overview
Azure Storage provides the capability to take snapshots of blobs. Snapshots capture the blob state at that point in time. In this article, we describe a scenario in which you can maintain backups of virtual machine disks using snapshots. You can use this methodology when you choose not to use Azure Backup and Recovery Service, and wish to create a custom backup strategy for your virtual machine disks. For virtual machines running business or mission critical workloads, it's recommended to use Azure Backup as part of the backup strategy.
Azure virtual machine disks are stored as page blobs in Azure Storage. Since we are describing a backup strategy for virtual machine disks in this article, we refer to snapshots in the context of page blobs. To learn more about snapshots, refer to Creating a Snapshot of a Blob.
What is a snapshot?
A blob snapshot is a read-only version of a blob that is captured at a point in time. Once a snapshot has been created, it can be read, copied, or deleted, but not modified. Snapshots provide a way to back up a blob as it appears at a moment in time. Until REST version 2015-04-05, you had the ability to copy full snapshots. With the REST version 2015-07-08 and above, you can also copy incremental snapshots.
Full snapshot copy
Snapshots can be copied to another storage account as a blob to keep backups of the base blob. You can also copy a snapshot over its base blob, which is like restoring the blob to an earlier version. When a snapshot is copied from one storage account to another, it occupies the same space as the base page blob. Therefore, copying whole snapshots from one storage account to another is slow and consumes much space in the target storage account.
Note
If you copy the base blob to another destination, the snapshots of the blob are not copied along with it. Similarly, if you overwrite a base blob with a copy, snapshots associated with the base blob are not affected and stay intact under the base blob name.
Back up disks using snapshots
As a backup strategy for your virtual machine disks, you can take periodic snapshots of the disk or page blob, and copy them to another storage account using tools like Copy Blob operation or AzCopy. You can copy a snapshot to a destination page blob with a different name. The resulting destination page blob is a writeable page blob and not a snapshot. Later in this article, we describe steps to take backups of virtual machine disks using snapshots.
Restore disks using snapshots
When it is time to restore your disk to a stable version that was previously captured in one of the backup snapshots, you can copy a snapshot over the base page blob. After the snapshot is promoted to the base page blob, the snapshot remains, but its source is overwritten with a copy that can be both read and written. Later in this article we describe steps to restore a previous version of your disk from its snapshot.
Implementing full snapshot copy
You can implement a full snapshot copy by doing the following,
First, take a snapshot of the base blob using the Snapshot Blob operation.
Then, copy the snapshot to a target storage account using Copy Blob.
Repeat this process to maintain backup copies of your base blob.
Incremental snapshot copy
The new feature in the GetPageRanges API provides a much better way to back up the snapshots of your page blobs or disks. The API returns the list of changes between the base blob and the snapshots, which reduces the amount of storage space used on the backup account. The API supports page blobs on Premium Storage as well as Standard Storage. Using this API, you can build faster and more efficient backup solutions for Azure VMs. This API will be available with the REST version 2015-07-08 and higher.
Incremental Snapshot Copy allows you to copy from one storage account to another the difference between,
Base blob and its Snapshot OR
Any two snapshots of the base blob
Provided the following conditions are met,
The blob was created on Jan-1-2016 or later.
The blob was not overwritten with PutPage or Copy Blob between two snapshots.
Note
This feature is available for Premium and Standard Azure Page Blobs.
When you have a custom backup strategy using snapshots, copying the snapshots from one storage account to another can be slow and can consume much storage space. Instead of copying the entire snapshot to a backup storage account, you can write the difference between consecutive snapshots to a backup page blob. This way, the time to copy and the space to store backups is substantially reduced.
Implementing Incremental Snapshot Copy
You can implement incremental snapshot copy by doing the following,
Take a snapshot of the base blob using Snapshot Blob.
Copy the snapshot to the target backup storage account in same or any other Azure region using Copy Blob. This is the backup page blob. Take a snapshot of the backup page blob and store it in the backup account.
Take another snapshot of the base blob using Snapshot Blob.
Get the difference between the first and second snapshots of the base blob using GetPageRanges. Use the new parameter prevsnapshot, to specify the DateTime value of the snapshot you want to get the difference with. When this parameter is present, the REST response includes only the pages that were changed between target snapshot and previous snapshot including clear pages.
Use PutPage to apply these changes to the backup page blob.
Finally, take a snapshot of the backup page blob and store it in the backup storage account.
In the next section, we will describe in more detail how you can maintain backups of disks using Incremental Snapshot Copy
Scenario
In this section, we describe a scenario that involves a custom backup strategy for virtual machine disks using snapshots.
Consider a DS-series Azure VM with a premium storage P30 disk attached. The P30 disk called mypremiumdisk is stored in a premium storage account called mypremiumaccount. A standard storage account called mybackupstdaccount is used for storing the backup of mypremiumdisk. We would like to keep a snapshot of mypremiumdisk every 12 hours.
To learn about creating a storage account, see Create a storage account.
To learn about backing up Azure VMs, refer to Plan Azure VM backups.
Steps to maintain backups of a disk using incremental snapshots
The following steps describe how to take snapshots of mypremiumdisk and maintain the backups in mybackupstdaccount. The backup is a standard page blob called mybackupstdpageblob. The backup page blob always reflects the same state as the last snapshot of mypremiumdisk.
Create the backup page blob for your premium storage disk, by taking a snapshot of mypremiumdisk called mypremiumdisk_ss1.
Copy this snapshot to mybackupstdaccount as a page blob called mybackupstdpageblob.
Take a snapshot of mybackupstdpageblob called mybackupstdpageblob_ss1, using Snapshot Blob and store it in mybackupstdaccount.
During the backup window, create another snapshot of mypremiumdisk, say mypremiumdisk_ss2, and store it in mypremiumaccount.
Get the incremental changes between the two snapshots, mypremiumdisk_ss2 and mypremiumdisk_ss1, using GetPageRanges on mypremiumdisk_ss2 with the prevsnapshot parameter set to the timestamp of mypremiumdisk_ss1. Write these incremental changes to the backup page blob mybackupstdpageblob in mybackupstdaccount. If there are deleted ranges in the incremental changes, they must be cleared from the backup page blob. Use PutPage to write incremental changes to the backup page blob.
Take a snapshot of the backup page blob mybackupstdpageblob, called mybackupstdpageblob_ss2. Delete the previous snapshot mypremiumdisk_ss1 from premium storage account.
Repeat steps 4-6 every backup window. In this way, you can maintain backups of mypremiumdisk in a standard storage account.
Steps to restore a disk from snapshots
The following steps, describe how to restore the premium disk, mypremiumdisk to an earlier snapshot from the backup storage account mybackupstdaccount.
Identify the point in time that you wish to restore the premium disk to. Let's say that it is snapshot mybackupstdpageblob_ss2, which is stored in the backup storage account mybackupstdaccount.
In mybackupstdaccount, promote the snapshot mybackupstdpageblob_ss2 as the new backup base page blob mybackupstdpageblobrestored.
Take a snapshot of this restored backup page blob, called mybackupstdpageblobrestored_ss1.
Copy the restored page blob mybackupstdpageblobrestored from mybackupstdaccount to mypremiumaccount as the new premium disk mypremiumdiskrestored.
Take a snapshot of mypremiumdiskrestored, called mypremiumdiskrestored_ss1 for making future incremental backups.
Point the DS series VM to the restored disk mypremiumdiskrestored and detach the old mypremiumdisk from the VM.
Begin the Backup process described in previous section for the restored disk mypremiumdiskrestored, using the mybackupstdpageblobrestored as the backup page blob.
Next Steps
Use the following links to learn more about creating snapshots of a blob and planning your VM backup infrastructure.
Creating a Snapshot of a Blob
Plan your VM Backup Infrastructure
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

27907
This article explains how to plan for backup and disaster recovery of IaaS virtual machines and disks in Azure. This document covers both unmanaged disks.
https://learn.microsoft.com/en-us/azure/virtual-machines/page-blobs-backup-and-disaster-recovery 

>>>
Backup and disaster recovery for unmanaged disks on Azure VMs - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Backup and disaster recovery for Azure unmanaged disks

Article
06/14/2022

																	3 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets
This article explains how to plan for backup and disaster recovery (DR) of IaaS virtual machines (VMs) and disks in Azure. This document covers unmanaged disks, or page blobs.
First, we cover the built-in fault tolerance capabilities in the Azure platform that helps guard against local failures. We then discuss the disaster scenarios not fully covered by the built-in capabilities. We also show several examples of workload scenarios where different backup and DR considerations can apply. We then review possible solutions for the DR of IaaS disks.
Introduction
The Azure platform uses various methods for redundancy and fault tolerance to help protect customers from localized hardware failures. Local failures can include problems with an Azure Storage server machine that stores part of the data for a virtual disk or failures of an SSD or HDD on that server. Such isolated hardware component failures can happen during normal operations.
The Azure platform is designed to be resilient to these failures. Major disasters can result in failures or the inaccessibility of many storage servers or even a whole datacenter. Although your VMs and disks are normally protected from localized failures, additional steps are necessary to protect your workload from region-wide catastrophic failures, such as a major disaster, that can affect your VM and disks.
In addition to the possibility of platform failures, problems with a customer application or data can occur. For example, a new version of your application might inadvertently make a change to the data that causes it to break. In that case, you might want to revert the application and the data to a prior version that contains the last known good state. This requires maintaining regular backups.
For regional disaster recovery, you must back up your IaaS VM disks to a different region.
Before we look at backup and DR options, let’s recap a few methods available for handling localized failures.
Azure IaaS resiliency
Resiliency refers to the tolerance for normal failures that occur in hardware components. Resiliency is the ability to recover from failures and continue to function. It's not about avoiding failures, but responding to failures in a way that avoids downtime or data loss. The goal of resiliency is to return the application to a fully functioning state following a failure. Azure virtual machines and disks are designed to be resilient to common hardware faults. Let's look at how the Azure IaaS platform provides this resiliency.
A virtual machine consists mainly of two parts: a compute server and the persistent disks. Both affect the fault tolerance of a virtual machine.
If the Azure compute host server that houses your VM experiences a hardware failure, which is rare, Azure is designed to automatically restore the VM on another server. If this scenario, your computer reboots, and the VM comes back up after some time. Azure automatically detects such hardware failures and executes recoveries to help ensure the customer VM is available as soon as possible.
Regarding IaaS disks, the durability of data is critical for a persistent storage platform. Azure customers have important business applications running on IaaS, and they depend on the persistence of the data. Azure designs protection for these IaaS disks, with three redundant copies of the data that is stored locally. These copies provide for high durability against local failures. If one of the hardware components that holds your disk fails, your VM is not affected, because there are two additional copies to support disk requests. It works fine, even if two different hardware components that support a disk fail at the same time (which is rare).
To ensure that you always maintain three replicas, Azure Storage automatically spawns a new copy of the data in the background if one of the three copies becomes unavailable. Therefore, it should not be necessary to use RAID with Azure disks for fault tolerance. A simple RAID 0 configuration should be sufficient for striping the disks, if necessary, to create larger volumes.
Because of this architecture, Azure has consistently delivered enterprise-grade durability for IaaS disks, with an industry-leading zero percent annualized failure rate.
Localized hardware faults on the compute host or in the Storage platform can sometimes result in of the temporary unavailability of the VM that is covered by the Azure SLA for VM availability. Azure also provides an industry-leading SLA for single VM instances that use Azure premium SSDs.
To safeguard application workloads from downtime due to the temporary unavailability of a disk or VM, customers can use availability sets. Two or more virtual machines in an availability set provide redundancy for the application. Azure then creates these VMs and disks in separate fault domains with different power, network, and server components.
Because of these separate fault domains, localized hardware failures typically do not affect multiple VMs in the set at the same time. Having separate fault domains provides high availability for your application. It's considered a good practice to use availability sets when high availability is required. The next section covers the disaster recovery aspect.
Backup and disaster recovery
Disaster recovery is the ability to recover from rare, but major, incidents. These incidents include non-transient, wide-scale failures, such as service disruption that affects an entire region. Disaster recovery includes data backup and archiving, and might include manual intervention, such as restoring a database from a backup.
The Azure platform’s built-in protection against localized failures might not fully protect the VMs/disks if a major disaster causes large-scale outages. These large-scale outages include catastrophic events, such as if a datacenter is hit by a hurricane, earthquake, fire, or if there is a large-scale hardware unit failure. In addition, you might encounter failures due to application or data issues.
To help protect your IaaS workloads from outages, you should plan for redundancy and have backups to enable recovery. For disaster recovery, you should back up in a different geographic location away from the primary site. This approach helps ensure your backup is not affected by the same event that originally affected the VM or disks. For more information, see Disaster recovery for Azure applications.
Your DR considerations might include the following aspects:
High availability: The ability of the application to continue running in a healthy state, without significant downtime. By healthy state, this state means that the application is responsive, and users can connect to the application and interact with it. Certain mission-critical applications and databases might be required to always be available, even when there are failures in the platform. For these workloads, you might need to plan redundancy for the application, as well as the data.
Data durability: In some cases, the main consideration is ensuring that the data is preserved if a disaster happens. Therefore, you might need a backup of your data in a different site. For such workloads, you might not need full redundancy for the application, but only a regular backup of the disks.
Backup and DR scenarios
Let’s look at a few typical examples of application workload scenarios and the considerations for planning for disaster recovery.
Scenario 1: Major database solutions
Consider a production database server, like SQL Server or Oracle, that can support high availability. Critical production applications and users depend on this database. The disaster recovery plan for this system might need to support the following requirements:
The data must be protected and recoverable.
The server must be available for use.
The disaster recovery plan might require maintaining a replica of the database in a different region as a backup. Depending on the requirements for server availability and data recovery, the solution might range from an active-active or active-passive replica site to periodic offline backups of the data. Relational databases, such as SQL Server and Oracle, provide various options for replication. For SQL Server, use SQL Server Always On Availability Groups for high availability.
NoSQL databases, like MongoDB, also support replicas for redundancy. The replicas for high availability are used.
Scenario 2: A cluster of redundant VMs
Consider a workload handled by a cluster of VMs that provide redundancy and load balancing. One example is a Cassandra cluster deployed in a region. This type of architecture already provides a high level of redundancy within that region. However, to protect the workload from a regional-level failure, you should consider spreading the cluster across two regions or making periodic backups to another region.
Scenario 3: IaaS application workload
Let's look at the IaaS application workload. For example, this application might be a typical production workload running on an Azure VM. It might be a web server or file server holding the content and other resources of a site. It might also be a custom-built business application running on a VM that stored its data, resources, and application state on the VM disks. In this case, it's important to make sure you take backups on a regular basis. Backup frequency should be based on the nature of the VM workload. For example, if the application runs every day and modifies data, then the backup should be taken every hour.
Another example is a reporting server that pulls data from other sources and generates aggregated reports. The loss of this VM or disks might lead to the loss of the reports. However, it might be possible to rerun the reporting process and regenerate the output. In that case, you don’t really have a loss of data, even if the reporting server is hit with a disaster. As a result, you might have a higher level of tolerance for losing part of the data on the reporting server. In that case, less frequent backups are an option to reduce costs.
Scenario 4: IaaS application data issues
IaaS application data issues are another possibility. Consider an application that computes, maintains, and serves critical commercial data, such as pricing information. A new version of your application had a software bug that incorrectly computed the pricing and corrupted the existing commerce data served by the platform. Here, the best course of action is to revert to the earlier version of the application and the data. To enable this, take periodic backups of your system.
Disaster recovery solution: Azure Backup
Azure Backup is used for backups and DR, and it works with managed disks as well as unmanaged disks. You can create a backup job with time-based backups, easy VM restoration, and backup retention policies.
If you use premium SSDs, managed disks, or other disk types with the locally redundant storage option, it's especially important to make periodic DR backups. Azure Backup stores the data in your recovery services vault for long-term retention. Choose the geo-redundant storage option for the backup recovery services vault. That option ensures that backups are replicated to a different Azure region for safeguarding from regional disasters.
For unmanaged disks, you can use the locally redundant storage type for IaaS disks, but ensure that Azure Backup is enabled with the geo-redundant storage option for the recovery services vault.
Note
If you use the geo-redundant storage or read-access geo-redundant storage  option for your unmanaged disks, you still need consistent snapshots for backup and DR. Use either Azure Backup or consistent snapshots.
The following table is a summary of the solutions available for DR.
Scenario
Automatic replication
DR solution
Premium SSD disks
Local (locally redundant storage)
Azure Backup
Managed disks
Local (locally redundant storage)
Azure Backup
Unmanaged locally redundant storage disks
Local (locally redundant storage)
Azure Backup
Unmanaged geo-redundant storage disks
Cross region (geo-redundant storage)
Azure BackupConsistent snapshots
Unmanaged read-access geo-redundant storage disks
Cross region (read-access geo-redundant storage)
Azure BackupConsistent snapshots
High availability is best met by using managed disks in an availability set along with Azure Backup. If you use unmanaged disks, you can still use Azure Backup for DR. If you are unable to use Azure Backup, then taking consistent snapshots, as described in a later section, is an alternative solution for backup and DR.
Your choices for high availability, backup, and DR at application or infrastructure levels can be represented as follows:
Level
High availability
Backup or DR
Application
SQL Server Always On
Azure Backup
Infrastructure
Availability set
Geo-redundant storage with consistent snapshots
Using Azure Backup
Azure Backup can back up your VMs running Windows or Linux to the Azure recovery services vault. Backing up and restoring business-critical data is complicated by the fact that business-critical data must be backed up while the applications that produce the data are running.
To address this issue, Azure Backup provides application-consistent backups for Microsoft workloads. It uses the volume shadow service to ensure that data is written correctly to storage. For Linux VMs, the default backup consistency mode is file-consistent backups, because Linux does not have functionality equivalent to the volume shadow service as in the case of Windows. For Linux machines, see Application-consistent backup of Azure Linux VMs.
When Azure Backup initiates a backup job at the scheduled time, it triggers the backup extension installed in the VM to take a point-in-time snapshot. A snapshot is taken in coordination with the volume shadow service to get a consistent snapshot of the disks in the virtual machine without having to shut it down. The backup extension in the VM flushes all writes before taking a consistent snapshot of all of the disks. After taking the snapshot, the data is transferred by Azure Backup to the backup vault. To make the backup process more efficient, the service identifies and transfers only the blocks of data that have changed after the last backup.
To restore, you can view the available backups through Azure Backup and then initiate a restore. You can create and restore Azure backups through the Azure portal, by using PowerShell, or by using the Azure CLI.
Steps to enable a backup
Use the following steps to enable backups of your VMs by using the Azure portal. There is some variation depending on your exact scenario. Refer to the Azure Backup documentation for full details. Azure Backup also supports VMs with managed disks.
Create a recovery services vault for a VM:
a. In the Azure portal, browse All resources and find Recovery Services vaults.
b. On the Recovery Services vaults menu, click Add and follow the steps to create a new vault in the same region as the VM. For example, if your VM is in the West US region, pick West US for the vault.
Verify the storage replication for the newly created vault. Access the vault under Recovery Services vaults and go to Properties > Backup Configuration > Update. Ensure the geo-redundant storage option is selected by default. This option ensures that your vault is automatically replicated to a secondary datacenter. For example, your vault in West US is automatically replicated to East US.
Configure the backup policy and select the VM from the same UI.
Make sure the Backup Agent is installed on the VM. If your VM is created by using an Azure gallery image, then the Backup Agent is already installed. Otherwise (that is, if you use a custom image), use the instructions to install the VM agent on a virtual machine.
After the previous steps are completed, the backup runs at regular intervals as specified in the backup policy. If necessary, you can trigger the first backup manually from the vault dashboard on the Azure portal.
For automating Azure Backup by using scripts, refer to PowerShell cmdlets for VM backup.
Steps for recovery
If you need to repair or rebuild a VM, you can restore the VM from any of the backup recovery points in the vault. There are a couple of different options for performing the recovery:
You can create a new VM as a point-in-time representation of your backed-up VM.
You can restore the disks, and then use the template for the VM to customize and rebuild the restored VM.
For more information, see the instructions to use the Azure portal to restore virtual machines. This document also explains the specific steps for restoring backed-up VMs to a paired datacenter by using your geo-redundant backup vault if there is a disaster at the primary datacenter. In that case, Azure Backup uses the Compute service from the secondary region to create the restored virtual machine.
You can also use PowerShell for creating a new VM from restored disks.
Alternative solution: Consistent snapshots
If you are unable to use Azure Backup, you can implement your own backup mechanism by using snapshots. Creating consistent snapshots for all the disks used by a VM and then replicating those snapshots to another region is complicated. For this reason, Azure considers using the Backup service as a better option than building a custom solution.
If you use read-access geo-redundant storage/geo-redundant storage for disks, snapshots are automatically replicated to a secondary datacenter. If you use locally redundant storage for disks, you need to replicate the data yourself. For more information, see Back up Azure-unmanaged VM disks with incremental snapshots.
A snapshot is a representation of an object at a specific point in time. A snapshot incurs billing for the incremental size of the data it holds. For more information, see Create a blob snapshot.
Create snapshots while the VM is running
Although you can take a snapshot at any time, if the VM is running, there is still data being streamed to the disks. The snapshots might contain partial operations that were in flight. Also, if there are several disks involved, the snapshots of different disks might have occurred at different times. These scenarios may cause to the snapshots to be uncoordinated. This lack of coordination is especially problematic for striped volumes whose files might be corrupted if changes were being made during backup.
To avoid this situation, the backup process must implement the following steps:
Freeze all the disks.
Flush all the pending writes.
Create a blob snapshot for all the disks.
Some Windows applications, like SQL Server, provide a coordinated backup mechanism via a volume shadow service to create application-consistent backups. On Linux, you can use a tool like fsfreeze for coordinating the disks. This tool provides file-consistent backups, but not application-consistent snapshots. This process is complex, so you should consider using Azure Backup or a third-party backup solution that already implements this procedure.
The previous process results in a collection of coordinated snapshots for all of the VM disks, representing a specific point-in-time view of the VM. This is a backup restore point for the VM. You can repeat the process at scheduled intervals to create periodic backups. See Copy the backups to another region for steps to copy the snapshots to another region for DR.
Create snapshots while the VM is offline
Another option to create consistent backups is to shut down the VM and take blob snapshots of each disk. Taking blob snapshots is easier than coordinating snapshots of a running VM, but it requires a few minutes of downtime.
Shut down the VM.
Create a snapshot of each virtual hard drive blob, which only takes a few seconds.
To create a snapshot, you can use PowerShell, the Azure Storage REST API, Azure CLI, or one of the Azure Storage client libraries, such as the Storage client library for .NET.
Start the VM, which ends the downtime. Typically, the entire process finishes within a few minutes.
This process yields a collection of consistent snapshots for all the disks, providing a backup restore point for the VM.
Copy the snapshots to another region
Creation of the snapshots alone might not be sufficient for DR. You must also replicate the snapshot backups to another region.
If you use geo-redundant storage or read-access geo-redundant storage for your disks, then the snapshots are replicated to the secondary region automatically. There can be a few minutes of lag before the replication. If the primary datacenter goes down before the snapshots finish replicating, you cannot access the snapshots from the secondary datacenter. The likelihood of this is small.
Note
Only having the disks in a geo-redundant storage or read-access geo-redundant storage account does not protect the VM from disasters. You must also create coordinated snapshots or use Azure Backup. This is required to recover a VM to a consistent state.
If you use locally redundant storage, you must copy the snapshots to a different storage account immediately after creating the snapshot. The copy target might be a locally redundant storage account in a different region, resulting in the copy being in a remote region. You can also copy the snapshot to a read-access geo-redundant storage account in the same region. In this case, the snapshot is lazily replicated to the remote secondary region. Your backup is protected from disasters at the primary site after the copying and replication is complete.
To copy your incremental snapshots for DR efficiently, review the instructions in Back up Azure unmanaged VM disks with incremental snapshots.
Recovery from snapshots
To retrieve a snapshot, copy it to make a new blob. If you are copying the snapshot from the primary account, you can copy the snapshot over to the base blob of the snapshot. This process reverts the disk to the snapshot. This process is known as promoting the snapshot. If you are copying the snapshot backup from a secondary account, in the case of a read-access geo-redundant storage account, you must copy it to a primary account. You can copy a snapshot by using PowerShell or by using the AzCopy utility. For more information, see Transfer data with the AzCopy command-line utility.
For VMs with multiple disks, you must copy all the snapshots that are part of the same coordinated restore point. After you copy the snapshots to writable VHD blobs, you can use the blobs to recreate your VM by using the template for the VM.
Other options
SQL Server
SQL Server running in a VM has its own built-in capabilities to back up your SQL Server database to Azure Blob storage or a file share. If the storage account is geo-redundant storage or read-access geo-redundant storage, you can access those backups in the storage account’s secondary datacenter in the event of a disaster, with the same restrictions as previously discussed. For more information, see Back up and restore for SQL Server in Azure virtual machines. In addition to back up and restore, SQL Server Always On availability groups can maintain secondary replicas of databases. This ability greatly reduces the disaster recovery time.
Other considerations
This article has discussed how to back up or take snapshots of your VMs and their disks to support disaster recovery and how to use those backups or snapshots to recover your data. With the Azure Resource Manager model, many people use templates to create their VMs and other infrastructures in Azure. You can use a template to create a VM that has the same configuration every time. If you use custom images for creating your VMs, you must also make sure that your images are protected by using a read-access geo-redundant storage account to store them.
Consequently, your backup process can be a combination of two things:
Back up the data (disks).
Back up the configuration (templates and custom images).
Depending on the backup option you choose, you might have to handle the backup of both the data and the configuration, or the backup service might handle all of that for you.
Appendix: Understanding the impact of data redundancy
For storage accounts in Azure, there are three types of data redundancy that you should consider regarding disaster recovery: locally redundant, geo-redundant, or geo-redundant with read access.
Locally redundant storage retains three copies of the data in the same datacenter. When the VM writes the data, all three copies are updated before success is returned to the caller, so you know they are identical. Your disk is protected from local failures, because it's unlikely that all three copies are affected at the same time. In the case of locally redundant storage, there is no geo-redundancy, so the disk is not protected from catastrophic failures that can affect an entire datacenter or storage unit.
With geo-redundant storage and read-access geo-redundant storage, three copies of your data are retained in the primary region that is selected by you. Three more copies of your data are retained in a corresponding secondary region that is set by Azure. For example, if you store data in West US, the data is replicated to East US. Copy retention is done asynchronously, and there is a small delay between updates to the primary and secondary sites. Replicas of the disks on the secondary site are consistent on a per-disk basis (with the delay), but replicas of multiple active disks might not be in sync with each other. To have consistent replicas across multiple disks, consistent snapshots are needed.
The main difference between geo-redundant storage and read-access geo-redundant storage is that with read-access geo-redundant storage, you can read the secondary copy at any time. If there is a problem that renders the data in the primary region inaccessible, the Azure team makes every effort to restore access. While the primary is down, if you have read-access geo-redundant storage enabled, you can access the data in the secondary datacenter. Therefore, if you plan to read from the replica while the primary is inaccessible, then read-access geo-redundant storage should be considered.
If it turns out to be a significant outage, the Azure team might trigger a geo-failover and change the primary DNS entries to point to secondary storage. At this point, if you have either geo-redundant storage or read-access geo-redundant storage enabled, you can access the data in the region that used to be the secondary. In other words, if your storage account is geo-redundant storage and there is a problem, you can access the secondary storage only if there is a geo-failover.
For more information, see What to do if an Azure Storage outage occurs.
Next steps
See Back up Azure unmanaged Virtual Machine disks with incremental snapshots.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

9194
Learn more about ephemeral OS disks for Azure VMs.
https://learn.microsoft.com/en-us/azure/virtual-machines/ephemeral-os-disks 

>>>
Ephemeral OS disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Ephemeral OS disks for Azure VMs

Article
03/10/2023

																	13 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Ephemeral OS disks are created on the local virtual machine (VM) storage and not saved to the remote Azure Storage. Ephemeral OS disks work well for stateless workloads, where applications are tolerant of individual VM failures but are more affected by VM deployment time or reimaging of individual VM instances. With Ephemeral OS disk, you get lower read/write latency to the OS disk and faster VM reimage.
The key features of ephemeral disks are:
Ideal for stateless applications.
Supported by  Marketplace, custom images, and by Azure Compute Gallery (formerly known as Shared Image Gallery).
Ability to fast reset or reimage VMs and scale set instances to the original boot state.
Lower latency, similar to a temporary disk.
Ephemeral OS disks are free, you incur no storage cost for OS disks.
Available in all Azure regions.
Key differences between persistent and ephemeral OS disks:
Persistent OS Disk
Ephemeral OS Disk
Size limit for OS disk
4* TiB
Cache size or temp size for the VM size or 2040 GiB, whichever is smaller. For the cache or temp size in GiB, see DS, ES, M, FS, and GS
VM sizes supported
All
VM sizes that support Premium storage such as DSv1, DSv2, DSv3, Esv3, Fs, FsV2, GS, M, Mdsv2, Bs, Dav4, Eav4
Disk type support
Managed and unmanaged OS disk
Managed OS disk only
Region support
All regions
All regions
Data persistence
OS disk data written to OS disk are stored in Azure Storage
Data written to OS disk is stored on local VM storage and isn't persisted to Azure Storage.
Stop-deallocated state
VMs and scale set instances can be stop-deallocated and restarted from the stop-deallocated state
Not Supported
Specialized OS disk support
Yes
No
OS disk resize
Supported during VM creation and after VM is stop-deallocated
Supported during VM creation only
Resizing to a new VM size
OS disk data is preserved
Data on the OS disk is deleted, OS is reprovisioned
Redeploy
OS disk data is preserved
Data on the OS disk is deleted, OS is reprovisioned
Stop/ Start of VM
OS disk data is preserved
Not Supported
Page file placement
For Windows, page file is stored on the resource disk
For Windows, page file is stored on the OS disk (for both OS cache placement and Temp disk placement).
Maintenance of VM/VMSS using healing
OS disk data is preserved
OS disk data is not preserved
Maintenance of VM/VMSS using Live Migration
OS disk data is preserved
OS disk data is preserved
* 4 TiB is the maximum supported OS disk size for managed (persistent) disks. However, many OS disks are partitioned with master boot record (MBR) by default and because of this are limited to 2 TiB. For details, see OS disk.
Placement options for Ephemeral OS disks
Ephemeral OS disk can be stored either on VM's OS cache disk or VM's temp/resource disk.
DiffDiskPlacement is the new property that can be used to specify where you want to place the Ephemeral OS disk. With this feature, when a Windows VM is provisioned, we configure the pagefile to be located on the OS Disk.
Size requirements
You can choose to deploy Ephemeral OS Disk on VM cache or VM temp disk.
The image OS disk’s size should be less than or equal to the temp/cache size of the VM size chosen.
For example, if you want to opt for OS cache placement: Standard Windows Server images from the marketplace are about 127 GiB, which means that you need a VM size that has a cache equal to or larger than 127 GiB. The Standard_DS3_v2 has a cache size of 127 GiB, which is large enough. In this case, the Standard_DS3_v2 is the smallest size in the DSv2 series that you can use with this image.
For example, if you want to opt for Temp disk placement: Standard Ubuntu server image from marketplace is about 30 GiB. To enable Ephemeral OS disk on temp, the temp disk size must be equal to or larger than 30 GiB. Standard_B4ms has a temp size of 32 GiB, which can fit the 30 GiB OS disk. Upon creation of the VM, the temp disk space would be 2 GiB.
Important
If opting for temp disk placement the Final Temp disk size = (Initial temp disk size - OS image size).
In the case of Temp disk placement, as Ephemeral OS disk is placed on temp disk it will share the IOPS with temp disk as per the VM size chosen by you.
Basic Linux and Windows Server images in the Marketplace that are denoted by [smallsize] tend to be around 30 GiB and can use most of the available VM sizes.
Ephemeral disks also require that the VM size supports Premium storage. The sizes usually (but not always) have an s in the name, like DSv2 and EsV3. For more information, see Azure VM sizes for details around which sizes support Premium storage.
Note
Ephemeral disk will not be accessible through the portal. You will receive a "Resource not Found" or "404" error when accessing the ephemeral disk which is expected.
Unsupported features
Capturing VM images
Disk snapshots
Azure Disk Encryption
Azure Backup
Azure Site Recovery
OS Disk Swap
Trusted Launch for Ephemeral OS disks
Ephemeral OS disks can be created with Trusted launch. All regions are supported for Trusted Launch; not all virtual machines sizes are supported. Check Virtual machines sizes supported for supported sizes.
VM guest state (VMGS) is specific to trusted launch VMs. It is a blob that is managed by Azure and contains the unified extensible firmware interface (UEFI) secure boot signature databases and other security information. When using trusted launch by default 1 GiB from the OS cache or temp storage based on the chosen placement option is reserved for VMGS.The lifecycle of the VMGS blob is tied to that of the OS Disk.
For example, If you try to create a Trusted launch Ephemeral OS disk VM using OS image of size 56 GiB with VM size Standard_DS4_v2 using temp disk placement you would get an error as
"OS disk of Ephemeral VM with size greater than 55 GB is not allowed for VM size Standard_DS4_v2 when the DiffDiskPlacement is ResourceDisk."
This is because the temp storage for Standard_DS4_v2 is 56 GiB, and 1 GiB is reserved for VMGS when using trusted launch.
For the same example above, if you create a standard Ephemeral OS disk VM you would not get any errors and it would be a successful operation.
Important
While using ephemeral disks for Trusted Launch VMs, keys and secrets generated or sealed by the vTPM after VM creation may not be persisted for operations like reimaging and platform events like service healing.
For more information on how to deploy a trusted launch VM
Confidential VMs using Ephemeral OS disks
AMD-based Confidential VMs cater to high security and confidentiality requirements of customers. These VMs provide a strong, hardware-enforced boundary to help meet your security needs. There are limitations to use Confidential VMs. Check the region, size and OS supported limitations for confidential VMs.
Virtual machine guest state (VMGS) blob contains the security information of the confidential VM.
Confidential VMs using Ephemeral OS disks by default 1 GiB from the OS cache or temp storage based on the chosen placement option is reserved for VMGS.The lifecycle of the VMGS blob is tied to that of the OS Disk.
Important
When choosing a confidential VM with full OS disk encryption before VM deployment that uses a customer-managed key (CMK). Updating a CMK key version or key rotation is not supported with Ephemeral OS disk. Confidential VMs using Ephemeral OS disks need to be deleted before updating or rotating the keys and can be re-created subsequently.
For more information on confidential VM
Customer Managed key
You can choose to use customer managed keys or platform managed keys when you enable end-to-end encryption for VMs using Ephemeral OS disk. Currently this option is available only via PowerShell, CLI and SDK in all regions.
Important
Updating a CMK key version or key rotation of customer managed key is not supported with Ephemeral OS disk. VMs using Ephemeral OS disks need to be deleted before updating or rotating the keys and can be re-created subsequently.
For more information on Encryption at host
Next steps
Create a VM with ephemeral OS disk using Azure Portal/CLI/PowerShell/ARM template.
Check out the frequently asked questions on ephemeral os disk.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

6739
Learn to deploy ephemeral OS disks for Azure VMs.
https://learn.microsoft.com/en-us/azure/virtual-machines/ephemeral-os-disks-deploy 

>>>
Deploy Ephemeral OS disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
How to deploy Ephemeral OS disks for Azure VMs

Article
03/10/2023

																	4 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
This article shows you how to create a virtual machine or virtual machine scale sets with Ephemeral OS disks through Portal, ARM template deployment, CLI and PowerShell.
Portal
In the Azure portal, you can choose to use ephemeral disks when deploying a virtual machine or virtual machine scale sets by opening the Advanced section of the Disks tab. For choosing placement of Ephemeral OS disk, select OS cache placement or Temp disk placement.
If the option for using an ephemeral disk or OS cache placement or Temp disk placement is greyed out, you might have selected a VM size that doesn't have a cache/temp size larger than the OS image or that doesn't support Premium storage. Go back to the Basics page and try choosing another VM size.
Scale set template deployment
The process to create a scale set that uses an ephemeral OS disk is to add the diffDiskSettings property to the
Microsoft.Compute/virtualMachineScaleSets/virtualMachineProfile resource type in the template. Also, the caching policy must be set to ReadOnly for the ephemeral OS disk. placement can be changed to CacheDisk for OS cache disk placement.
{
  "type": "Microsoft.Compute/virtualMachineScaleSets",
  "name": "myScaleSet",
  "location": "East US 2",
  "apiVersion": "2019-12-01",
  "sku": {
    "name": "Standard_DS2_v2",
    "capacity": "2"
  },
  "properties": {
    "upgradePolicy": {
      "mode": "Automatic"
    },
    "virtualMachineProfile": {
       "storageProfile": {
        "osDisk": {
          "diffDiskSettings": {
            "option": "Local" ,
            "placement": "ResourceDisk"
          },
          "caching": "ReadOnly",
          "createOption": "FromImage"
        },
        "imageReference":  {
          "publisher": "publisherName",
          "offer": "offerName",
          "sku": "skuName",
          "version": "imageVersion"
        }
      },
      "osProfile": {
        "computerNamePrefix": "myvmss",
        "adminUsername": "azureuser",
        "adminPassword": "P@ssw0rd!"
      }
    }
  }
}
Note
Replace all the other values accordingly.
VM template deployment
You can deploy a VM with an ephemeral OS disk using a template. The process to create a VM that uses ephemeral OS disks is to add the diffDiskSettings property to Microsoft.Compute/virtualMachines resource type in the template. Also, the caching policy must be set to ReadOnly for the ephemeral OS disk. placement option can be changed to CacheDisk for OS cache disk placement.
{
  "type": "Microsoft.Compute/virtualMachines",
  "name": "myVirtualMachine",
  "location": "East US 2",
  "apiVersion": "2019-12-01",
  "properties": {
       "storageProfile": {
            "osDisk": {
              "diffDiskSettings": {
                "option": "Local" ,
                "placement": "ResourceDisk"
              },
              "caching": "ReadOnly",
              "createOption": "FromImage"
            },
            "imageReference": {
                "publisher": "MicrosoftWindowsServer",
                "offer": "WindowsServer",
                "sku": "2016-Datacenter-smalldisk",
                "version": "latest"
            },
            "hardwareProfile": {
                 "vmSize": "Standard_DS2_v2"
             }
      },
      "osProfile": {
        "computerNamePrefix": "myvirtualmachine",
        "adminUsername": "azureuser",
        "adminPassword": "P@ssw0rd!"
      }
    }
 }
CLI
To use an ephemeral disk for a CLI VM deployment, set the --ephemeral-os-disk parameter in az vm create to true and the --ephemeral-os-disk-placement parameter to ResourceDisk for temp disk placement or CacheDisk for cache disk placement and the --os-disk-caching parameter to ReadOnly.
az vm create \
  --resource-group myResourceGroup \
  --name myVM \
  --image imageName \
  --ephemeral-os-disk true \
  --ephemeral-os-disk-placement ResourceDisk \
  --os-disk-caching ReadOnly \
  --admin-username azureuser \
  --generate-ssh-keys
Note
Replace myVM, myResourceGroup, imageName and azureuser accordingly.
For scale sets, you use the same --ephemeral-os-disk true parameter for az-vmss-create and set the --os-disk-caching parameter to ReadOnly and the --ephemeral-os-disk-placement parameter to ResourceDisk for temp disk placement or CacheDisk for cache disk placement.
Reimage a VM using REST
You can reimage a Virtual Machine instance with ephemeral OS disk using REST API as described below and via Azure portal by going to Overview pane of the VM. For scale sets, reimaging is already available through PowerShell, CLI, and the portal.
POST https://management.azure.com/subscriptions/{sub-
id}/resourceGroups/{rgName}/providers/Microsoft.Compute/VirtualMachines/{vmName}/reimage?api-version=2019-12-01"
PowerShell
To use an ephemeral disk for a PowerShell VM deployment, use Set-AzVMOSDisk in your VM configuration. Set the -DiffDiskSetting to Local and -Caching to ReadOnly and  -DiffDiskPlacement to ResourceDisk.
Set-AzVMOSDisk -DiffDiskSetting Local -DiffDiskPlacement ResourceDisk -Caching ReadOnly
To use an ephemeral disk on cache disk for a PowerShell VM deployment, use Set-AzVMOSDisk in your VM configuration. Set the -DiffDiskSetting to Local , -Caching to ReadOnly and  -DiffDiskPlacement to CacheDisk.
Set-AzVMOSDisk -DiffDiskSetting Local -DiffDiskPlacement CacheDisk -Caching ReadOnly
For scale set deployments, use the Set-AzVmssStorageProfile cmdlet in your configuration. Set the -DiffDiskSetting to Local , -Caching to ReadOnly and  -DiffDiskPlacement to ResourceDisk or CacheDisk.
Set-AzVmssStorageProfile -DiffDiskSetting Local -DiffDiskPlacement ResourceDisk -OsDiskCaching ReadOnly
Next steps
For more information on Ephemeral OS disk.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5077
Frequently asked questions on ephemeral OS disks for Azure VMs.
https://learn.microsoft.com/en-us/azure/virtual-machines/ephemeral-os-disks-faq 

>>>
FAQ Ephemeral OS disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Frequently asked questions about Ephemeral OS disks

Article
03/10/2023

																	2 contributors
Feedback
In this article
Q: What is the size of the local OS Disks?
A: We support platform, Shared Image Gallery, and custom images, up to the VM cache size with OS cache placement and up to Temp disk size with Temp disk placement, where all read/writes to the OS disk will be local on the same node as the Virtual Machine.
Q: Can the ephemeral OS disk be resized?
A: No, once the ephemeral OS disk is provisioned, the OS disk cannot be resized.
Q: Can the ephemeral OS disk placement be modified after creation of VM?
A: No, once the ephemeral OS disk is provisioned, the OS disk placement cannot be changed. But the VM can be recreated via ARM template deployment/PowerShell/CLI by updating the OS disk placement of choosing. This would result in the recreation of the VM with Data on the OS disk deleted and OS is reprovisioned.
Q: Is there any Temp disk created if image size equals to Temp disk size of VM size selected?
A: No, in that case, there won't be any Temp disk drive created.
Q: Are Ephemeral OS disks supported on low-priority VMs and Spot VMs?
A: Yes. There is no option of Stop-Deallocate for Ephemeral VMs, rather users need to Delete instead of deallocating them.
Q: Can I attach a Managed Disks to an Ephemeral VM?
A: Yes, you can attach a managed data disk to a VM that uses an ephemeral OS disk.
Q: Will all VM sizes be supported for ephemeral OS disks?
A: No, most Premium Storage VM sizes are supported (DS, ES, FS, GS, M, etc.). To know whether a particular VM size supports ephemeral OS disks for an OS image size you can use the below script. It takes the OS image size and location as inputs and provides a list of VM SKUs and corresponding placement supported. If both OS Cache and temp disk placement are marked as not supported then Ephemeral OS disk cannot be used for the given OS image size.
[CmdletBinding()]
param([Parameter(Mandatory=$true)]
      [ValidateNotNullOrEmpty()]
      [string]$Location,
      [Parameter(Mandatory=$true)]
      [long]$OSImageSizeInGB
      )
Function HasSupportEphemeralOSDisk([object[]] $capability)
{
    return $capability | where { $_.Name -eq "EphemeralOSDiskSupported" -and $_.Value -eq "True"}
}
Function Get-MaxTempDiskAndCacheSize([object[]] $capabilities)
{
    $MaxResourceVolumeGB = 0;
    $CachedDiskGB = 0;
    foreach($capability in $capabilities)
    {
        if ($capability.Name -eq "MaxResourceVolumeMB")
        { $MaxResourceVolumeGB = [int]($capability.Value / 1024) }
        if ($capability.Name -eq "CachedDiskBytes")
        { $CachedDiskGB = [int]($capability.Value / (1024 * 1024 * 1024)) }
    }
    return ($MaxResourceVolumeGB, $CachedDiskGB)
}
Function Get-EphemeralSupportedVMSku
{
    [CmdletBinding()]
    Param
    (
        [Parameter(Mandatory=$true)]
        [long]$OSImageSizeInGB,
        [Parameter(Mandatory=$true)]
        [string]$Location
    )
    $VmSkus = Get-AzComputeResourceSku $Location | Where-Object { $_.ResourceType -eq "virtualMachines" -and (HasSupportEphemeralOSDisk $_.Capabilities) -ne $null }
    $Response = @()
    foreach ($sku in $VmSkus)
    {
        ($MaxResourceVolumeGB, $CachedDiskGB) = Get-MaxTempDiskAndCacheSize $sku.Capabilities
        $Response += New-Object PSObject -Property @{
            ResourceSKU = $sku.Size
            TempDiskPlacement = @{ $true = "NOT SUPPORTED"; $false = "SUPPORTED"}[$MaxResourceVolumeGB -lt $OSImageSizeInGB]
            CacheDiskPlacement = @{ $true = "NOT SUPPORTED"; $false = "SUPPORTED"}[$CachedDiskGB -lt $OSImageSizeInGB]
        };
    }
    return $Response
}
Get-EphemeralSupportedVMSku -OSImageSizeInGB $OSImageSizeInGB -Location $Location | Format-Table
Q: Can the ephemeral OS disk be applied to existing VMs and scale sets?
A: No, ephemeral OS disk can only be used during VM and scale set creation.
Q: Can you mix ephemeral and normal OS disks in a scale set?
A: No, you can't have a mix of ephemeral and persistent OS disk instances within the same scale set.
Q: Can the ephemeral OS disk be created using PowerShell or CLI?
A: Yes, you can create VMs with Ephemeral OS Disk using REST, Templates, PowerShell, and CLI.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

6666
Enable Private Links for your managed disks with Azure CLI. Allowing you to securely export and import disks within only your virtual network.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/disks-export-import-private-links-cli 

>>>
Azure CLI - Restrict import/export access to managed disks with Private Links - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Azure CLI - Restrict import/export access for managed disks with Private Links

Article
03/31/2023

																	9 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
You can use private endpoints to restrict the export and import of managed disks and securely access data over a Private Link from clients on your Azure virtual network. The private endpoint uses an IP address from the virtual network address space for your managed disks service. Network traffic between clients on their virtual network and managed disks only traverses over the virtual network and a private link on the Microsoft backbone network, eliminating exposure from the public internet.
To use Private Links to export/import managed disks, first you create a disk access resource and link it to a virtual network in the same subscription by creating a private endpoint. Then, associate a disk or a snapshot with an instance of disk access. Finally, set the NetworkAccessPolicy property of the disk or the snapshot to AllowPrivate. This will limit access to your virtual network.
You can set the NetworkAccessPolicy property to DenyAll to prevent anybody from exporting data of a disk or a snapshot. The default value for the NetworkAccessPolicy property is AllowAll.
Limitations
Your virtual network must be in the same subscription as your disk access object to link them.
You can't import or export more than five disks or snapshots at the same time with the same disk access object.
You can't request manual approval to link a virtual network to a disk access object.
Log in into your subscription and set your variables
subscriptionId=yourSubscriptionId
resourceGroupName=yourResourceGroupName
region=northcentralus
diskAccessName=yourDiskAccessForPrivateLinks
vnetName=yourVNETForPrivateLinks
subnetName=yourSubnetForPrivateLinks
privateEndPointName=yourPrivateLinkForSecureMDExportImport
privateEndPointConnectionName=yourPrivateLinkConnection
#The name of an existing disk which is the source of the snapshot
sourceDiskName=yourSourceDiskForSnapshot
#The name of the new snapshot which will be secured via Private Links
snapshotNameSecuredWithPL=yourSnapshotNameSecuredWithPL
az login
az account set --subscription $subscriptionId
Create a disk access using Azure CLI
az disk-access create -n $diskAccessName -g $resourceGroupName -l $region
diskAccessId=$(az disk-access show -n $diskAccessName -g $resourceGroupName --query [id] -o tsv)
Create a Virtual Network
Network policies like network security groups (NSG) are not supported for private endpoints. In order to deploy a Private Endpoint on a given subnet, an explicit disable setting is required on that subnet.
az network vnet create --resource-group $resourceGroupName \
    --name $vnetName \
    --subnet-name $subnetName
Disable subnet private endpoint policies
Azure deploys resources to a subnet within a virtual network, so you need to update the subnet to disable private endpoint network policies.
az network vnet subnet update --resource-group $resourceGroupName \
    --name $subnetName  \
    --vnet-name $vnetName \
    --disable-private-endpoint-network-policies true
Create a private endpoint for the disk access object
az network private-endpoint create --resource-group $resourceGroupName \
    --name $privateEndPointName \
    --vnet-name $vnetName  \
    --subnet $subnetName \
    --private-connection-resource-id $diskAccessId \
    --group-ids disks \
    --connection-name $privateEndPointConnectionName
Configure the Private DNS Zone
Create a Private DNS Zone for Storage blob domain, create an association link with the Virtual Network
and create a DNS Zone Group to associate the private endpoint with the Private DNS Zone.
az network private-dns zone create --resource-group $resourceGroupName \
    --name "privatelink.blob.core.windows.net"
az network private-dns link vnet create --resource-group $resourceGroupName \
    --zone-name "privatelink.blob.core.windows.net" \
    --name yourDNSLink \
    --virtual-network $vnetName \
    --registration-enabled false
az network private-endpoint dns-zone-group create \
   --resource-group $resourceGroupName \
   --endpoint-name $privateEndPointName \
   --name yourZoneGroup \
   --private-dns-zone "privatelink.blob.core.windows.net" \
   --zone-name disks
Create a disk protected with Private Links
resourceGroupName=yourResourceGroupName
region=northcentralus
diskAccessName=yourDiskAccessName
diskName=yourDiskName
diskSkuName=Standard_LRS
diskSizeGB=128
diskAccessId=$(az resource show -n $diskAccessName -g $resourceGroupName --namespace Microsoft.Compute --resource-type diskAccesses --query [id] -o tsv)
az disk create -n $diskName \
-g $resourceGroupName \
-l $region \
--size-gb $diskSizeGB \
--sku $diskSkuName \
--network-access-policy AllowPrivate \
--disk-access $diskAccessId
Create a snapshot of a disk protected with Private Links
resourceGroupName=yourResourceGroupName
region=northcentralus
diskAccessName=yourDiskAccessName
sourceDiskName=yourSourceDiskForSnapshot
snapshotNameSecuredWithPL=yourSnapshotName
diskId=$(az disk show -n $sourceDiskName -g $resourceGroupName --query [id] -o tsv)
diskAccessId=$(az resource show -n $diskAccessName -g $resourceGroupName --namespace Microsoft.Compute --resource-type diskAccesses --query [id] -o tsv)
az snapshot create -n $snapshotNameSecuredWithPL \
-g $resourceGroupName \
-l $region \
--source $diskId \
--network-access-policy AllowPrivate \
--disk-access $diskAccessId
Next steps
Upload a VHD to Azure or copy a managed disk to another region - Azure CLI or Azure PowerShell module
Download a VHD - Windows or Linux
FAQ on Private Links
Export/Copy managed snapshots as VHD to a storage account in different region with CLI
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4408
Enable Private Link for your managed disks with Azure portal. This allows you to securely export and import disks within your virtual network.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-enable-private-links-for-import-export-portal 

>>>
Azure portal - Restrict import/export access to managed disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Restrict import/export access for managed disks using Azure Private Link

Article
04/23/2023

																	9 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
You can use private endpoints to restrict the export and import of managed disks and more securely access data over a private link from clients on your Azure virtual network. The private endpoint uses an IP address from the virtual network address space for your managed disks. Network traffic between clients on their virtual network and managed disks only traverses over the virtual network and a private link on the Microsoft backbone network, eliminating exposure from the public internet.
To use Private Link to export and import managed disks, first you create a disk access resource and link it to a virtual network in the same subscription by creating a private endpoint. Then, associate a disk or a snapshot with a disk access instance.
Limitations
Your virtual network must be in the same subscription as your disk access object to link them.
You can't import or export more than five disks or snapshots at the same time with the same disk access object.
You can't request manual approval to link a virtual network to a disk access object.
Create a disk access resource
Sign in to the Azure portal and navigate to Disk Accesses with this link.
Important
You must use the provided link to navigate to the Disk Accesses pane. It is not currently visible in the public portal without using the link.
Select + Create to create a new disk access resource.
On the Create a disk accesses pane, select your subscription and a resource group. Under Instance details, enter a name and select a region.
Select Review + create.
When your resource has been created, navigate directly to it.
Create a private endpoint
Next, you'll need to create a private endpoint and configure it for disk access.
From your disk access resource, under Settings, select Private endpoint connections.
Select + Private endpoint.
In the Create a private endpoint pane, select a resource group.
Provide a name and select the same region in which your disk access resource was created.
Select Next: Resource.
On the Resource pane, select Connect to an Azure resource in my directory.
For Resource type, select Microsoft.Compute/diskAccesses.
For Resource, select the disk access resource you created earlier.
Leave the Target sub-resource as disks.
Select Next : Configuration.
Select the virtual network to which you will limit disk import and export. This prevents the import and export of your disk to other virtual networks.
Note
If you have a network security group enabled for the selected subnet, it will be disabled for private endpoints on this subnet only. Other resources on this subnet will retain network security group enforcement.
Select the appropriate subnet.
Select Review + create.
Enable private endpoint on your disk
Navigate to the disk you'd like to configure.
Under Settings, select Networking.
Select Private endpoint (through disk access) and select the disk access you created earlier.
Select Save.
You've now configured a private link that you can use to import and export your managed disk.
Next steps
Upload a VHD to Azure or copy a managed disk to another region - Azure CLI or Azure PowerShell module
Download a VHD - Windows or Linux
FAQ for private links and managed disks
Export/Copy managed snapshots as VHD to a storage account in different region with PowerShell
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

12396
Learn how to upload a VHD to an Azure managed disk and copy a managed disk across regions, using Azure PowerShell, via direct upload.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/disks-upload-vhd-to-managed-disk-powershell 

>>>
Upload a VHD to Azure or copy a disk across regions - Azure PowerShell - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Upload a VHD to Azure or copy a managed disk to another region - Azure PowerShell

Article
03/31/2023

																	13 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs
This article explains how to either upload a VHD from your local machine to an Azure managed disk or copy a managed disk to another region, using the Azure PowerShell module. The process of uploading a managed disk, also known as direct upload, enables you to upload a VHD up to 32 TiB in size directly into a managed disk. Currently, direct upload is supported for standard HDD, standard SSD, and premium SSDs. It isn't supported for ultra disks, yet.
If you're providing a backup solution for IaaS VMs in Azure, you should use direct upload to restore customer backups to managed disks. When uploading a VHD from a source external to Azure, speeds depend on your local bandwidth. When uploading or copying from an Azure VM, your bandwidth would be the same as standard HDDs.
Secure uploads with Azure AD
If you're using Azure Active Directory (Azure AD) to control resource access, you can now use it to restrict uploading of Azure managed disks. This feature is available as a GA offering in all regions. When a user attempts to upload a disk, Azure validates the identity of the requesting user in Azure AD, and confirms that user has the required permissions. At a higher level, a system administrator could set a policy at the Azure account or subscription level to ensure that an Azure AD identity has the necessary permissions for uploading before allowing a disk or a disk snapshot to be uploaded. If you have any questions on securing uploads with Azure AD, reach out to this email: azuredisks@microsoft .com
Prerequisites
Install the latest Azure PowerShell module.
Restrictions
VHDs can't be uploaded to empty snapshots.
Azure Backup doesn't currently support disks secured with Azure AD.
Assign RBAC role
To access managed disks secured with Azure AD, the requesting user must have either the Data Operator for Managed Disks role, or a custom role with the following permissions:
Microsoft.Compute/disks/download/action
Microsoft.Compute/disks/upload/action
Microsoft.Compute/snapshots/download/action
Microsoft.Compute/snapshots/upload/action
For detailed steps on assigning a role, see Assign Azure roles using Azure PowerShell. To create or update a custom role, see Create or update Azure custom roles using Azure PowerShell.
Get started
There are two ways you can upload a VHD with the Azure PowerShell module: You can either use the Add-AzVHD command, which will automate most of the process for you, or you can perform the upload manually with AzCopy.
Generally, you should use Add-AzVHD. However, if you need to upload a VHD that is larger than 50 GiB, consider uploading the VHD manually with AzCopy. VHDs 50 GiB and larger upload faster using AzCopy.
For guidance on how to copy a managed disk from one region to another, see Copy a managed disk.
Use Add-AzVHD
Prerequisites
Install the Azure PowerShell module.
A VHD has been prepared for Azure, stored locally.
On Windows: You don't need to convert your VHD to VHDx, convert it a fixed size, or resize it to include the 512-byte offset. Add-AZVHD performs these functions for you.
Hyper-V must be enabled for Add-AzVHD to perform these functions.
On Linux: You must perform these actions manually. See Resizing VHDs for details.
Upload a VHD
(Optional) Grant access to the disk
If Azure AD is used to enforce upload restrictions on a subscription or at the account level, Add-AzVHD only succeeds if attempted by a user that has the appropriate RBAC role or necessary permissions. You'll need to assign RBAC permissions to grant access to the disk and generate a writeable SAS.
New-AzRoleAssignment -SignInName <emailOrUserprincipalname> `
-RoleDefinitionName "Data Operator for Managed Disks" `
-Scope /subscriptions/<subscriptionId>
Use Add-AzVHD
The following example uploads a VHD from your local machine to a new Azure managed disk using Add-AzVHD. Replace <your-filepath-here>, <your-resource-group-name>,<desired-region>, and <desired-managed-disk-name> with your parameters:
Note
If you're using Azure AD to enforce upload restrictions, add DataAccessAuthMode 'AzureActiveDirectory' to the end of your Add-AzVhd command.
# Required parameters
$path = <your-filepath-here>.vhd
$resourceGroup = <your-resource-group-name>
$location = <desired-region>
$name = <desired-managed-disk-name>
# Optional parameters
# $Zone = <desired-zone>
# $sku=<desired-SKU>
# -DataAccessAuthMode 'AzureActiveDirectory'
# -DiskHyperVGeneration = V1 or V2. This applies only to OS disks.
# To use $Zone or #sku, add -Zone or -DiskSKU parameters to the command
Add-AzVhd -LocalFilePath $path -ResourceGroupName $resourceGroup -Location $location -DiskName $name
Manual upload
Prerequisites
Download the latest version of AzCopy v10.
Install the Azure PowerShell module.
A fixed size VHD that has been prepared for Azure, stored locally.
To upload your VHD to Azure, you'll need to create an empty managed disk that is configured for this upload process. Before you create one, there's some additional information you should know about these disks.
This kind of managed disk has two unique states:
ReadyToUpload, which means the disk is ready to receive an upload but, no secure access signature (SAS) has been generated.
ActiveUpload, which means that the disk is ready to receive an upload and the SAS has been generated.
Note
While in either of these states, the managed disk will be billed at standard HDD pricing, regardless of the actual type of disk. For example, a P10 will be billed as an S10. This will be true until revoke-access is called on the managed disk, which is required in order to attach the disk to a VM.
Create an empty managed disk
Before you can create an empty standard HDD for uploading, you'll need the file size of the VHD you want to upload, in bytes. The example code will get that for you but, to do it yourself you can use: $vhdSizeBytes = (Get-Item "<fullFilePathHere>").length. This value is used when specifying the -UploadSizeInBytes parameter.
Now, on your local shell, create an empty standard HDD for uploading by specifying the Upload setting in the -CreateOption parameter as well as the -UploadSizeInBytes parameter in the New-AzDiskConfig cmdlet. Then call New-AzDisk to create the disk.
Replace <yourdiskname>, <yourresourcegroupname>, and <yourregion> then run the following commands:
Tip
If you're creating an OS disk, add -HyperVGeneration '<yourGeneration>' to New-AzDiskConfig.
If you're using Azure AD to secure your uploads, add -dataAccessAuthMode 'AzureActiveDirectory' to New-AzDiskConfig.
$vhdSizeBytes = (Get-Item "<fullFilePathHere>").length
$diskconfig = New-AzDiskConfig -SkuName 'Standard_LRS' -OsType 'Windows' -UploadSizeInBytes $vhdSizeBytes -Location '<yourregion>' -CreateOption 'Upload'
New-AzDisk -ResourceGroupName '<yourresourcegroupname>' -DiskName '<yourdiskname>' -Disk $diskconfig
If you would like to upload either a premium SSD or a standard SSD, replace Standard_LRS with either Premium_LRS or StandardSSD_LRS. Ultra disks aren't currently supported.
Generate writeable SAS
Now that you've created an empty managed disk that is configured for the upload process, you can upload a VHD to it. To upload a VHD to the disk, you'll need a writeable SAS, so that you can reference it as the destination for your upload.
To generate a writable SAS of your empty managed disk, replace <yourdiskname>and <yourresourcegroupname>, then use the following commands:
$diskSas = Grant-AzDiskAccess -ResourceGroupName '<yourresourcegroupname>' -DiskName '<yourdiskname>' -DurationInSecond 86400 -Access 'Write'
$disk = Get-AzDisk -ResourceGroupName '<yourresourcegroupname>' -DiskName '<yourdiskname>'
Upload a VHD
Now that you have a SAS for your empty managed disk, you can use it to set your managed disk as the destination for your upload command.
Use AzCopy v10 to upload your local VHD file to a managed disk by specifying the SAS URI you generated.
This upload has the same throughput as the equivalent standard HDD. For example, if you have a size that equates to S4, you will have a throughput of up to 60 MiB/s. But, if you have a size that equates to S70, you will have a throughput of up to 500 MiB/s.
AzCopy.exe copy "c:\somewhere\mydisk.vhd" $diskSas.AccessSAS --blob-type PageBlob
After the upload is complete, and you no longer need to write any more data to the disk, revoke the SAS. Revoking the SAS will change the state of the managed disk and allow you to attach the disk to a VM.
Replace <yourdiskname>and <yourresourcegroupname>, then run the following command:
Revoke-AzDiskAccess -ResourceGroupName '<yourresourcegroupname>' -DiskName '<yourdiskname>'
Copy a managed disk
Direct upload also simplifies the process of copying a managed disk. You can either copy within the same region or copy your managed disk to another region.
The following script will do this for you, the process is similar to the steps described earlier, with some differences, since you're working with an existing disk.
Important
You must add an offset of 512 when you're providing the disk size in bytes of a managed disk from Azure. This is because Azure omits the footer when returning the disk size. The copy will fail if you don't do this. The following script already does this for you.
Replace the <sourceResourceGroupHere>, <sourceDiskNameHere>, <targetDiskNameHere>, <targetResourceGroupHere>, <yourOSTypeHere> and <yourTargetLocationHere> (an example of a location value would be uswest2) with your values, then run the following script in order to copy a managed disk.
Tip
If you are creating an OS disk, add -HyperVGeneration '<yourGeneration>' to New-AzDiskConfig.
$sourceRG = <sourceResourceGroupHere>
$sourceDiskName = <sourceDiskNameHere>
$targetDiskName = <targetDiskNameHere>
$targetRG = <targetResourceGroupHere>
$targetLocate = <yourTargetLocationHere>
$targetVmGeneration = "V1" # either V1 or V2
#Expected value for OS is either "Windows" or "Linux"
$targetOS = <yourOSTypeHere>
$sourceDisk = Get-AzDisk -ResourceGroupName $sourceRG -DiskName $sourceDiskName
# Adding the sizeInBytes with the 512 offset, and the -Upload flag
$targetDiskconfig = New-AzDiskConfig -SkuName 'Standard_LRS' -osType $targetOS -UploadSizeInBytes $($sourceDisk.DiskSizeBytes+512) -Location $targetLocate -CreateOption 'Upload' -HyperVGeneration $targetVmGeneration
$targetDisk = New-AzDisk -ResourceGroupName $targetRG -DiskName $targetDiskName -Disk $targetDiskconfig
$sourceDiskSas = Grant-AzDiskAccess -ResourceGroupName $sourceRG -DiskName $sourceDiskName -DurationInSecond 86400 -Access 'Read'
$targetDiskSas = Grant-AzDiskAccess -ResourceGroupName $targetRG -DiskName $targetDiskName -DurationInSecond 86400 -Access 'Write'
azcopy copy $sourceDiskSas.AccessSAS $targetDiskSas.AccessSAS --blob-type PageBlob
Revoke-AzDiskAccess -ResourceGroupName $sourceRG -DiskName $sourceDiskName
Revoke-AzDiskAccess -ResourceGroupName $targetRG -DiskName $targetDiskName
Next steps
Now that you've successfully uploaded a VHD to a managed disk, you can attach your disk to a VM and begin using it.
To learn how to attach a data disk to a VM, see our article on the subject: Attach a data disk to a Windows VM with PowerShell. To use the disk as the OS disk, see Create a Windows VM from a specialized disk.
If you've additional questions, see the section on uploading a managed disk in the FAQ.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

10039
Learn how to upload a VHD to an Azure managed disk and copy a managed disk across regions, using the Azure CLI, via direct upload.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/disks-upload-vhd-to-managed-disk-cli 

>>>
Upload a VHD to Azure or copy a disk across regions - Azure CLI - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Upload a VHD to Azure or copy a managed disk to another region - Azure CLI

Article
03/08/2023

																	14 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets
This article explains how to either upload a VHD from your local machine to an Azure managed disk or copy a managed disk to another region, using AzCopy. This process, direct upload, enables you to upload a VHD up to 32 TiB in size directly into a managed disk. Currently, direct upload is supported for standard HDD, standard SSD, and premium SSD managed disks. It isn't supported for ultra disks, yet.
If you're providing a backup solution for IaaS VMs in Azure, you should use direct upload to restore customer backups to managed disks. When uploading a VHD from a source external to Azure, speeds depend on your local bandwidth. When uploading or copying from an Azure VM, your bandwidth would be the same as standard HDDs.
Secure uploads with Azure AD
If you're using Azure Active Directory (Azure AD) to control resource access, you can now use it to restrict uploading of Azure managed disks. This feature is available as a GA offering in all regions. When a user attempts to upload a disk, Azure validates the identity of the requesting user in Azure AD, and confirms that user has the required permissions. At a higher level, a system administrator could set a policy at the Azure account or subscription level, to ensure that an Azure AD identity has the necessary permissions for uploading before allowing a disk or a disk snapshot to be uploaded. If you have any questions on securing uploads with Azure AD, reach out to this email: azuredisks@microsoft .com
Prerequisites
Install the Azure CLI.
Restrictions
VHDs can't be uploaded to empty snapshots.
Azure Backup doesn't currently support disks secured with Azure AD.
Assign RBAC role
To access managed disks secured with Azure AD, the requesting user must have either the Data Operator for Managed Disks role, or a custom role with the following permissions:
Microsoft.Compute/disks/download/action
Microsoft.Compute/disks/upload/action
Microsoft.Compute/snapshots/download/action
Microsoft.Compute/snapshots/upload/action
For detailed steps on assigning a role, see Assign Azure roles using Azure CLI. To create or update a custom role, see Create or update Azure custom roles using Azure CLI.
Get started
If you'd prefer to upload disks through a GUI, you can do so using Azure Storage Explorer. For details refer to: Use Azure Storage Explorer to manage Azure managed disks
Prerequisites
Download the latest version of AzCopy v10.
Install the Azure CLI.
If you intend to upload a VHD from on-premises: A fixed size VHD that has been prepared for Azure, stored locally.
Or, a managed disk in Azure, if you intend to perform a copy action.
To upload your VHD to Azure, you'll need to create an empty managed disk that is configured for this upload process. Before you create one, there's some additional information you should know about these disks.
This kind of managed disk has two unique states:
ReadToUpload, which means the disk is ready to receive an upload but, no secure access signature (SAS) has been generated.
ActiveUpload, which means that the disk is ready to receive an upload and the SAS has been generated.
Note
While in either of these states, the managed disk will be billed at standard HDD pricing, regardless of the actual type of disk. For example, a P10 will be billed as an S10. This will be true until revoke-access is called on the managed disk, which is required in order to attach the disk to a VM.
Create an empty managed disk
Before you can create an empty standard HDD for uploading, you'll need the file size of the VHD you want to upload, in bytes. To get that, you can use either wc -c <yourFileName>.vhd or ls -al <yourFileName>.vhd. This value is used when specifying the --upload-size-bytes parameter.
Create an empty standard HDD for uploading by specifying both the -–for-upload parameter and the --upload-size-bytes parameter in a disk create cmdlet:
Replace <yourdiskname>, <yourresourcegroupname>, <yourregion> with values of your choosing. The --upload-size-bytes parameter contains an example value of 34359738880, replace it with a value appropriate for you.
Tip
If you're creating an OS disk, add --hyper-v-generation <yourGeneration> to az disk create.
If you're using Azure AD to secure disk uploads, add -dataAccessAuthmode 'AzureActiveDirectory'.
az disk create -n <yourdiskname> -g <yourresourcegroupname> -l <yourregion> --os-type Linux --for-upload --upload-size-bytes 34359738880 --sku standard_lrs
If you would like to upload either a premium SSD or a standard SSD, replace standard_lrs with either premium_LRS or standardssd_lrs. Ultra disks are not supported for now.
(Optional) Grant access to the disk
If you're using Azure AD to secure uploads, you'll need to assign RBAC permissions to grant access to the disk and generate a writeable SAS.
az role assignment create --assignee "{assignee}" \
--role "{Data Operator for Managed Disks}" \
--scope "/subscriptions/{subscriptionId}/resourcegroups/{resourceGroupName}/providers/{providerName}/{resourceType}/{resourceSubType}/{diskName}"
Generate writeable SAS
Now that you've created an empty managed disk that is configured for the upload process, you can upload a VHD to it. To upload a VHD to the disk, you'll need a writeable SAS, so that you can reference it as the destination for your upload.
To generate a writable SAS of your empty managed disk, replace <yourdiskname>and <yourresourcegroupname>, then use the following command:
az disk grant-access -n <yourdiskname> -g <yourresourcegroupname> --access-level Write --duration-in-seconds 86400
Sample returned value:
{
  "accessSas": "https://md-impexp-t0rdsfgsdfg4.blob.core.windows.net/w2c3mj0ksfgl/abcd?sv=2017-04-17&sr=b&si=600a9281-d39e-4cc3-91d2-923c4a696537&sig=xXaT6mFgf139ycT87CADyFxb%2BnPXBElYirYRlbnJZbs%3D"
}
Upload a VHD
Now that you have a SAS for your empty managed disk, you can use it to set your managed disk as the destination for your upload command.
Use AzCopy v10 to upload your local VHD file to a managed disk by specifying the SAS URI you generated.
This upload has the same throughput as the equivalent standard HDD. For example, if you have a size that equates to S4, you will have a throughput of up to 60 MiB/s. But, if you have a size that equates to S70, you will have a throughput of up to 500 MiB/s.
AzCopy.exe copy "c:\somewhere\mydisk.vhd" "sas-URI" --blob-type PageBlob
After the upload is complete, and you no longer need to write any more data to the disk, revoke the SAS. Revoking the SAS will change the state of the managed disk and allow you to attach the disk to a VM.
Replace <yourdiskname>and <yourresourcegroupname>, then use the following command to make the disk usable:
az disk revoke-access -n <yourdiskname> -g <yourresourcegroupname>
Copy a managed disk
Direct upload also simplifies the process of copying a managed disk. You can either copy within the same region or cross-region (to another region).
The following script will do this for you, the process is similar to the steps described earlier, with some differences since you're working with an existing disk.
Important
You need to add an offset of 512 when you're providing the disk size in bytes of a managed disk from Azure. This is because Azure omits the footer when returning the disk size. The copy will fail if you don't do this. The following script already does this for you.
Replace the <sourceResourceGroupHere>, <sourceDiskNameHere>, <targetDiskNameHere>, <targetResourceGroupHere>, and <yourTargetLocationHere> (an example of a location value would be uswest2) with your values, then run the following script in order to copy a managed disk.
Tip
If you are creating an OS disk, add --hyper-v-generation <yourGeneration> to az disk create.
sourceDiskName=<sourceDiskNameHere>
sourceRG=<sourceResourceGroupHere>
targetDiskName=<targetDiskNameHere>
targetRG=<targetResourceGroupHere>
targetLocation=<yourTargetLocationHere>
#Expected value for OS is either "Windows" or "Linux"
targetOS=<yourOSTypeHere>
sourceDiskSizeBytes=$(az disk show -g $sourceRG -n $sourceDiskName --query '[diskSizeBytes]' -o tsv)
az disk create -g $targetRG -n $targetDiskName -l $targetLocation --os-type $targetOS --for-upload --upload-size-bytes $(($sourceDiskSizeBytes+512)) --sku standard_lrs
targetSASURI=$(az disk grant-access -n $targetDiskName -g $targetRG  --access-level Write --duration-in-seconds 86400 -o tsv)
sourceSASURI=$(az disk grant-access -n $sourceDiskName -g $sourceRG --duration-in-seconds 86400 --query [accessSas] -o tsv)
azcopy copy $sourceSASURI $targetSASURI --blob-type PageBlob
az disk revoke-access -n $sourceDiskName -g $sourceRG
az disk revoke-access -n $targetDiskName -g $targetRG
Next steps
Now that you've successfully uploaded a VHD to a managed disk, you can attach the disk as a data disk to an existing VM or attach the disk to a VM as an OS disk, to create a new VM.
If you've additional questions, see the uploading a managed disk section in the FAQ.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5685
Azure CLI Script Sample - Export/Copy snapshot as VHD to a storage account in same or different region.
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/copy-snapshot-to-storage-account 

>>>
Copy a snapshot to a storage account in another region using the CLI - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Export/Copy a snapshot to a storage account in different region with CLI

Article
03/31/2023

																	4 contributors
Feedback
In this article
This script exports a managed snapshot to a storage account in different region. It first generates the SAS URI of the snapshot and then uses it to copy it to a storage account in different region. Use this script to maintain backup of your managed disks in different region for disaster recovery.
If you don't have an Azure subscription, create an Azure free account before you begin.
Prerequisites
Use the Bash environment in Azure Cloud Shell. For more information, see Quickstart for Bash in Azure Cloud Shell.
If you prefer to run CLI reference commands locally, install the Azure CLI. If you're running on Windows or macOS, consider running Azure CLI in a Docker container. For more information, see How to run the Azure CLI in a Docker container.
If you're using a local installation, sign in to the Azure CLI by using the az login command. To finish the authentication process, follow the steps displayed in your terminal. For other sign-in options, see Sign in with the Azure CLI.
When you're prompted, install the Azure CLI extension on first use. For more information about extensions, see Use extensions with the Azure CLI.
Run az version to find the version and dependent libraries that are installed. To upgrade to the latest version, run az upgrade.
Sample script
Launch Azure Cloud Shell
The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account.
To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also launch Cloud Shell in a separate browser tab by going to https://shell.azure.com.
When Cloud Shell opens, verify that Bash is selected for your environment. Subsequent sessions will use Azure CLI in a Bash environment, Select Copy to copy the blocks of code, paste it into the Cloud Shell, and press Enter to run it.
Sign in to Azure
Cloud Shell is automatically authenticated under the initial account signed-in with. Use the following script to sign in using a different subscription, replacing <Subscription ID> with your Azure Subscription ID.  If you don't have an Azure subscription, create an Azure free account before you begin.
subscription="<subscriptionId>" # add subscription here
az account set -s $subscription # ...or use 'az login'
For more information, see set active subscription or log in interactively
Run the script
#Provide the subscription Id where snapshot is created
subscriptionId="<subscriptionId>"
#Provide the name of your resource group where snapshot is created
resourceGroupName=myResourceGroupName
#Provide the snapshot name
snapshotName=mySnapshotName
#Provide Shared Access Signature (SAS) expiry duration in seconds e.g. 3600.
#Know more about SAS here: https://docs.microsoft.com/en-us/azure/storage/storage-dotnet-shared-access-signature-part-1
sasExpiryDuration=3600
#Provide storage account name where you want to copy the snapshot.
storageAccountName=mystorageaccountname
#Name of the storage container where the downloaded snapshot will be stored
storageContainerName=mystoragecontainername
#Provide the key of the storage account where you want to copy snapshot.
storageAccountKey=mystorageaccountkey
#Provide the name of the VHD file to which snapshot will be copied.
destinationVHDFileName=myvhdfilename
az account set --subscription $subscriptionId
sas=$(az snapshot grant-access --resource-group $resourceGroupName --name $snapshotName --duration-in-seconds $sasExpiryDuration --query [accessSas] -o tsv)
az storage blob copy start --destination-blob $destinationVHDFileName --destination-container $storageContainerName --account-name $storageAccountName --account-key $storageAccountKey --source-uri $sas
Clean up resources
Run the following command to remove the resource group, VM, and all related resources.
az group delete --name myResourceGroupName
Sample reference
This script uses following commands to generate SAS URI for a managed snapshot and copies the snapshot to a storage account using SAS URI. Each command in the table links to command specific documentation.
Command
Notes
az snapshot grant-access
Generates read-only SAS that is used to copy underlying VHD file to a storage account or download it to on-premises
az storage blob copy start
Copies a blob asynchronously from one storage account to another
Next steps
Create a managed disk from a VHD
Create a virtual machine from a managed disk
For more information on the Azure CLI, see Azure CLI documentation.
Additional virtual machine and managed disks CLI script samples can be found in the Azure Linux VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5940
Azure CLI sample - Export or copy a managed disk to a storage account.
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/copy-managed-disks-vhd-to-storage-account 

>>>
Copy a managed disk to a storage account - CLI - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Export/Copy a managed disk to a storage account using the Azure CLI

Article
01/13/2023

																	4 contributors
Feedback
In this article
This script exports the underlying VHD of a managed disk to a storage account in same or different region. It first generates the SAS URI of the managed disk and then uses it to copy the VHD to a storage account. Use this script to copy managed disks to another region for regional expansion. If you want to publish the VHD file of a managed disk in Azure Marketplace, you can use this script to copy the VHD file to a storage account and then generate a SAS URI of the copied VHD to publish it in the Marketplace.
If you don't have an Azure subscription, create an Azure free account before you begin.
Prerequisites
Use the Bash environment in Azure Cloud Shell. For more information, see Quickstart for Bash in Azure Cloud Shell.
If you prefer to run CLI reference commands locally, install the Azure CLI. If you're running on Windows or macOS, consider running Azure CLI in a Docker container. For more information, see How to run the Azure CLI in a Docker container.
If you're using a local installation, sign in to the Azure CLI by using the az login command. To finish the authentication process, follow the steps displayed in your terminal. For other sign-in options, see Sign in with the Azure CLI.
When you're prompted, install the Azure CLI extension on first use. For more information about extensions, see Use extensions with the Azure CLI.
Run az version to find the version and dependent libraries that are installed. To upgrade to the latest version, run az upgrade.
Sample script
Launch Azure Cloud Shell
The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account.
To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also launch Cloud Shell in a separate browser tab by going to https://shell.azure.com.
When Cloud Shell opens, verify that Bash is selected for your environment. Subsequent sessions will use Azure CLI in a Bash environment, Select Copy to copy the blocks of code, paste it into the Cloud Shell, and press Enter to run it.
Sign in to Azure
Cloud Shell is automatically authenticated under the initial account signed-in with. Use the following script to sign in using a different subscription, replacing <Subscription ID> with your Azure Subscription ID.  If you don't have an Azure subscription, create an Azure free account before you begin.
subscription="<subscriptionId>" # add subscription here
az account set -s $subscription # ...or use 'az login'
For more information, see set active subscription or log in interactively
Run the script
#Provide the subscription Id where managed disk is created
subscriptionId="<subscriptionId>"
#Provide the name of your resource group where managed disk is created
resourceGroupName=myResourceGroupName
#Provide the managed disk name
diskName=myDiskName
#Provide Shared Access Signature (SAS) expiry duration in seconds e.g. 3600.
#Know more about SAS here: https://docs.microsoft.com/en-us/azure/storage/storage-dotnet-shared-access-signature-part-1
sasExpiryDuration=3600
#Provide storage account name where you want to copy the underlying VHD file of the managed disk.
storageAccountName=mystorageaccountname
#Name of the storage container where the downloaded VHD will be stored
storageContainerName=mystoragecontainername
#Provide the key of the storage account where you want to copy the VHD
storageAccountKey=mystorageaccountkey
#Provide the name of the destination VHD file to which the VHD of the managed disk will be copied.
destinationVHDFileName=myvhdfilename.vhd
az account set --subscription $subscriptionId
sas=$(az disk grant-access --resource-group $resourceGroupName --name $diskName --duration-in-seconds $sasExpiryDuration --query [accessSas] -o tsv)
az storage blob copy start --destination-blob $destinationVHDFileName --destination-container $storageContainerName --account-name $storageAccountName --account-key $storageAccountKey --source-uri $sas
Clean up resources
Run the following command to remove the resource group, VM, and all related resources.
az group delete --name myResourceGroupName
Sample reference
This script uses following commands to generate the SAS URI for a managed disk and copies the underlying VHD to a storage account using the SAS URI. Each command in the table links to command specific documentation.
Command
Notes
az disk grant-access
Generates read-only SAS that is used to copy the underlying VHD file to a storage account or download it to on-premises
az storage blob copy start
Copies a blob asynchronously from one storage account to another
Next steps
Create a managed disk from a VHD
Create a virtual machine from a managed disk
For more information on the Azure CLI, see Azure CLI documentation.
Additional virtual machine and managed disks CLI script samples can be found in the Azure Linux VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4357
Azure PowerShell Script Sample -  Export/Copy snapshot as VHD to a storage account in same different region
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-powershell-sample-copy-snapshot-to-storage-account 

>>>
PowerShell Sample - Export/Copy snapshot as VHD to a storage account in different region - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Export/Copy managed snapshots as VHD to a storage account in different region with PowerShell

Article
03/31/2023

																	2 contributors
Feedback
In this article
This script exports a managed snapshot to a storage account in different region. It first generates the SAS URI of the snapshot and then uses it to copy it to a storage account in different region. Use this script to maintain backup of your managed disks in different region for disaster recovery.
If needed, install the Azure PowerShell module using the instructions found in the Azure PowerShell guide, and then run Connect-AzAccount to create a connection with Azure. Also, you need to have an SSH public key named id_rsa.pub in the .ssh directory of your user profile.
If you don't have an Azure subscription, create an Azure free account before you begin.
Sample script
#Provide the subscription Id of the subscription where snapshot is created
$subscriptionId = "yourSubscriptionId"
#Provide the name of your resource group where snapshot is created
$resourceGroupName ="yourResourceGroupName"
#Provide the snapshot name
$snapshotName = "yourSnapshotName"
#Provide Shared Access Signature (SAS) expiry duration in seconds e.g. 3600.
#Know more about SAS here: https://docs.microsoft.com/en-us/Az.Storage/storage-dotnet-shared-access-signature-part-1
$sasExpiryDuration = "3600"
#Provide storage account name where you want to copy the snapshot.
$storageAccountName = "yourstorageaccountName"
#Name of the storage container where the downloaded snapshot will be stored
$storageContainerName = "yourstoragecontainername"
#Provide the key of the storage account where you want to copy snapshot.
$storageAccountKey = 'yourStorageAccountKey'
#Provide the name of the VHD file to which snapshot will be copied.
$destinationVHDFileName = "yourvhdfilename"
# Set the context to the subscription Id where Snapshot is created
Select-AzSubscription -SubscriptionId $SubscriptionId
#Generate the SAS for the snapshot
$sas = Grant-AzSnapshotAccess -ResourceGroupName $ResourceGroupName -SnapshotName $SnapshotName  -DurationInSecond $sasExpiryDuration -Access Read
#Create the context for the storage account which will be used to copy snapshot to the storage account
$destinationContext = New-AzStorageContext -StorageAccountName $storageAccountName -StorageAccountKey $storageAccountKey
#Copy the snapshot to the storage account
Start-AzStorageBlobCopy -AbsoluteUri $sas.AccessSAS -DestContainer $storageContainerName -DestContext $destinationContext -DestBlob $destinationVHDFileName
Script explanation
This script uses following commands to generate SAS URI for a managed snapshot and copies the snapshot to a storage account using SAS URI. Each command in the table links to command specific documentation.
Command
Notes
Grant-AzSnapshotAccess
Generates SAS URI for a snapshot that is used to copy it to a storage account.
New-AzureStorageContext
Creates a storage account context using the account name and key. This context can be used to perform read/write operations on the storage account.
Start-AzureStorageBlobCopy
Copies the underlying VHD of a snapshot to a storage account
Next steps
Create a managed disk from a VHD
Create a virtual machine from a managed disk
For more information on the Azure PowerShell module, see Azure PowerShell documentation.
Additional virtual machine PowerShell script samples can be found in the Azure Linux VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5185
Azure PowerShell script sample -  Export/Copy the VHD of a managed disk to a storage account in same or different region
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-powershell-sample-copy-managed-disks-vhd 

>>>
Export/Copy the VHD of a managed disk to another region's account (Windows) - PowerShell - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Export/Copy the VHD of a managed disk to a storage account in different region with PowerShell (Windows)

Article
03/31/2023

																	5 contributors
Feedback
In this article
This script exports the VHD of a managed disk to a storage account in different region. It first generates the SAS URI of the managed disk and then uses it to copy the underlying VHD to a storage account in different region. Use this script to copy managed disks to another region for regional expansion.
If needed, install the Azure PowerShell module using the instructions found in the Azure PowerShell guide, and then run Connect-AzAccount to create a connection with Azure. Also, you need to have an SSH public key named id_rsa.pub in the .ssh directory of your user profile.
If you don't have an Azure subscription, create an Azure free account before you begin.
Sample script
#Provide the subscription Id of the subscription where managed disk is created
$subscriptionId = "yourSubscriptionId"
#Provide the name of your resource group where managed is created
$resourceGroupName ="yourResourceGroupName"
#Provide the managed disk name
$diskName = "yourDiskName"
#Provide Shared Access Signature (SAS) expiry duration in seconds e.g. 3600.
#Know more about SAS here: https://docs.microsoft.com/en-us/Az.Storage/storage-dotnet-shared-access-signature-part-1
$sasExpiryDuration = "3600"
#Provide storage account name where you want to copy the underlying VHD of the managed disk.
$storageAccountName = "yourstorageaccountName"
#Name of the storage container where the downloaded VHD will be stored
$storageContainerName = "yourstoragecontainername"
#Provide the key of the storage account where you want to copy the VHD of the managed disk.
$storageAccountKey = 'yourStorageAccountKey'
#Provide the name of the destination VHD file to which the VHD of the managed disk will be copied.
$destinationVHDFileName = "yourvhdfilename"
#Set the value to 1 to use AzCopy tool to download the data. This is the recommended option for faster copy.
#Download AzCopy v10 from the link here: https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-v10
#Ensure that AzCopy is downloaded in the same folder as this file
#If you set the value to 0 then Start-AzStorageBlobCopy will be used. Azure storage will asynchronously copy the data.
$useAzCopy = 1
# Set the context to the subscription Id where managed disk is created
Select-AzSubscription -SubscriptionId $SubscriptionId
#Generate the SAS for the managed disk
$sas = Grant-AzDiskAccess -ResourceGroupName $ResourceGroupName -DiskName $diskName -DurationInSecond $sasExpiryDuration -Access Read
#Create the context of the storage account where the underlying VHD of the managed disk will be copied
$destinationContext = New-AzStorageContext -StorageAccountName $storageAccountName -StorageAccountKey $storageAccountKey
#Copy the VHD of the managed disk to the storage account
if($useAzCopy -eq 1)
{
    $containerSASURI = New-AzStorageContainerSASToken -Context $destinationContext -ExpiryTime(get-date).AddSeconds($sasExpiryDuration) -FullUri -Name $storageContainerName -Permission rw
    azcopy copy $sas.AccessSAS $containerSASURI
}else{
    Start-AzStorageBlobCopy -AbsoluteUri $sas.AccessSAS -DestContainer $storageContainerName -DestContext $destinationContext -DestBlob $destinationVHDFileName
}
Script explanation
This script uses the following commands to generate SAS URI of a managed disk and copies the underlying VHD to a storage account using the SAS URI. Each command in the table links to the command specific documentation.
Command
Notes
Grant-AzDiskAccess
Generates SAS URI for a managed disk that is used to copy the underlying VHD to a storage account.
New-AzureStorageContext
Creates a storage account context using the account name and key. This context can be used to perform read/write operations on the storage account.
Start-AzureStorageBlobCopy
Copies the underlying VHD of a snapshot to a storage account
Next steps
Create a managed disk from a VHD
Create a virtual machine from a managed disk
For more information on the Azure PowerShell module, see Azure PowerShell documentation.
Additional virtual machine PowerShell script samples can be found in the Azure Windows VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

7218
Download a Linux VHD using the Azure CLI and the Azure portal.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/download-vhd 

>>>
Download a Linux VHD from Azure - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Download a Linux VHD from Azure

Article
03/31/2023

																	13 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
In this article, you learn how to download a Linux virtual hard disk (VHD) file from Azure using the Azure portal.
Stop the VM
A VHD can’t be downloaded from Azure if it's attached to a running VM. If you want to keep the VM running, you can create a snapshot and then download the snapshot.
To stop the VM:
Sign in to the Azure portal.
On the left menu, select Virtual Machines.
Select the VM from the list.
On the page for the VM, select Stop.
Alternative: Snapshot the VM disk
Take a snapshot of the disk to download.
Select the VM in the portal.
Select Disks in the left menu and then select the disk you want to snapshot. The details of the disk will be displayed.
Select Create Snapshot from the menu at the top of the page. The Create snapshot page will open.
In Name, type a name for the snapshot.
For Snapshot type, select Full or Incremental.
When you are done, select Review + create.
Your snapshot will be created shortly, and can then be used to download or create another VM.
Note
If you don't stop the VM first, the snapshot will not be clean. The snapshot will be in the same state as if the VM had been power cycled or crashed at the point in time when the snapshot was made. While usually safe, it could cause problems if the running applications running at the time were not crash resistant.
This method is only recommended for VMs with a single OS disk. VMs with one or more data disks should be stopped before download or before creating a snapshot for the OS disk and each data disk.
Secure downloads and uploads with Azure AD
If you're using Azure Active Directory (Azure AD) to control resource access, you can now use it to restrict uploads and downloads of Azure managed disks. This feature is available as a GA offering in all regions. When a user attempts to upload or download a disk, Azure validates the identity of the requesting user in Azure AD, and confirms that user has the required permissions. At a higher level, a system administrator could set a policy at the Azure account or subscription level, to ensure that all disks and snapshots must use Azure AD for uploads or downloads. If you have any questions on securing uploads or downloads with Azure AD, reach out to this email: azuredisks@microsoft .com
Restrictions
VHDs can't be uploaded to empty snapshots.
Azure Backup doesn't currently support disks secured with Azure AD.
Prerequisites
Install the latest Azure PowerShell module.
Assign RBAC role
To access managed disks secured with Azure AD, the requesting user must have either the Data Operator for Managed Disks role, or a custom role with the following permissions:
Microsoft.Compute/disks/download/action
Microsoft.Compute/disks/upload/action
Microsoft.Compute/snapshots/download/action
Microsoft.Compute/snapshots/upload/action
For detailed steps on assigning a role, see the following articles for portal, PowerShell, or CLI. To create or update a custom role, see the following articles for portal, PowerShell, or CLI.
Enable data access authentication mode
Portal
PowerShell
Azure CLI
Enable data access authentication mode to restrict access to the disk. You can either enable it when creating the disk, or you can enable it on the Disk Export page for existing disks.
Set dataAccessAuthMode to "AzureActiveDirectory" on your disk, in order to download it when it's been secured. Use the following script to update an existing disk, replace the values for -ResourceGroupName and -DiskName before running the script:
New-AzDiskUpdateConfig -DataAccessAuthMode "AzureActiveDirectory" | Update-AzDisk -ResourceGroupName 'yourResourceGroupName' -DiskName 'yourDiskName"
Set dataAccessAuthMode to "AzureActiveDirectory" on your disk, in order to download it when it's been secured. Use the following script to update an existing disk, replace the values for --resource-group and --Name before running the script:
az disk update --name yourDiskName --resource-group yourResourceGroup --data-access-auth-mode AzureActiveDirectory
Generate SAS URL
To download the VHD file, you need to generate a shared access signature (SAS) URL. When the URL is generated, an expiration time is assigned to the URL.
Portal
PowerShell
Azure CLI
On the menu of the page for the VM, select Disks.
Select the operating system disk for the VM, and then select Disk Export.
If required, update the value of URL expires in (seconds) to give you enough time to complete the download. The default is 3600 seconds (one hour).
Select Generate URL.
$diskSas = Grant-AzDiskAccess -ResourceGroupName "yourRGName" -DiskName "yourDiskName" -DurationInSecond 86400 -Access 'Read'
az disk grant-access --duration-in-seconds 86400 --access-level Read --name yourDiskName --resource-group yourRGName
Download VHD
Note
If you're using Azure AD to secure managed disk downloads, the user downloading the VHD must have the appropriate RBAC permissions.
Portal
PowerShell
Azure CLI
Under the URL that was generated, select Download the VHD file.
You may need to select Save in the browser to start the download. The default name for the VHD file is abcd.
Use the following script to download your VHD:
Connect-AzAccount
#Set localFolder to your desired download location
$localFolder = "yourPathHere"
$blob = Get-AzStorageBlobContent -Uri $diskSas.AccessSAS -Destination $localFolder -Force
When the download finishes, revoke access to your disk using Revoke-AzDiskAccess -ResourceGroupName "yourRGName" -DiskName "yourDiskName".
Replace yourPathhere and sas-URI with your values, then use the following script to download your VHD:
Note
If you're using Azure AD to secure your managed disk uploads and downloads, add --auth-mode login to az storage blob download.
#set localFolder to your desired download location
localFolder=yourPathHere
#If you're using Azure AD to secure your managed disk uploads and downloads, add --auth-mode login to the following command.
az storage blob download -f $localFolder --blob-url "sas-URI"
When the download finishes, revoke access to your disk using az disk revoke-access --name diskName --resource-group yourRGName.
Next steps
Learn how to upload and create a Linux VM from custom disk with the Azure CLI.
Manage Azure disks the Azure CLI.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

8651
Download a Windows VHD using the Azure portal.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/download-vhd 

>>>
Download a Windows VHD from Azure - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Download a Windows VHD from Azure

Article
01/04/2023

																	11 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs
In this article, you learn how to download a Windows virtual hard disk (VHD) file from Azure using the Azure portal.
Optional: Generalize the VM
If you want to use the VHD as an image to create other VMs, you should use Sysprep to generalize the operating system. Otherwise, you will have to make a copy of the disk for each VM you want to create.
To use the VHD as an image to create other VMs, generalize the VM.
If you haven't already done so, sign in to the Azure portal.
Connect to the VM.
On the VM, open the Command Prompt window as an administrator.
Change the directory to %windir%\system32\sysprep and run sysprep.exe.
In the System Preparation Tool dialog box, select Enter System Out-of-Box Experience (OOBE), and make sure that Generalize is selected.
In Shutdown Options, select Shutdown, and then click OK.
If you don't want to generalize your current VM, you can still create a generalized image by first making a snapshot of the OS disk, creating a new VM from the snapshot, and then generalizing the copy.
Stop the VM
A VHD can’t be downloaded from Azure if it's attached to a running VM. If you want to keep the VM running, you can create a snapshot and then download the snapshot.
On the Hub menu in the Azure portal, click Virtual Machines.
Select the VM from the list.
On the blade for the VM, click Stop.
Alternative: Snapshot the VM disk
Take a snapshot of the disk to download.
Select the VM in the portal.
Select Disks in the left menu and then select the disk you want to snapshot. The details of the disk will be displayed.
Select Create Snapshot from the menu at the top of the page. The Create snapshot page will open.
In Name, type a name for the snapshot.
For Snapshot type, select Full or Incremental.
When you are done, select Review + create.
Your snapshot will be created shortly, and can then be used to download or create another VM.
Note
If you don't stop the VM first, the snapshot will not be clean. The snapshot will be in the same state as if the VM had been power cycled or crashed at the point in time when the snapshot was made.  While usually safe, it could cause problems if the running applications running at the time were not crash resistant.
This method is only recommended for VMs with a single OS disk. VMs with one or more data disks should be stopped before download or before creating a snapshot for the OS disk and each data disk.
Secure downloads and uploads with Azure AD
If you're using Azure Active Directory (Azure AD) to control resource access, you can now use it to restrict uploads and downloads of Azure managed disks. This feature is available as a GA offering in all regions. When a user attempts to upload or download a disk, Azure validates the identity of the requesting user in Azure AD, and confirms that user has the required permissions. At a higher level, a system administrator could set a policy at the Azure account or subscription level, to ensure that all disks and snapshots must use Azure AD for uploads or downloads. If you have any questions on securing uploads or downloads with Azure AD, reach out to this email: azuredisks@microsoft .com
Restrictions
VHDs can't be uploaded to empty snapshots.
Azure Backup doesn't currently support disks secured with Azure AD.
Prerequisites
Install the latest Azure PowerShell module.
Assign RBAC role
To access managed disks secured with Azure AD, the requesting user must have either the Data Operator for Managed Disks role, or a custom role with the following permissions:
Microsoft.Compute/disks/download/action
Microsoft.Compute/disks/upload/action
Microsoft.Compute/snapshots/download/action
Microsoft.Compute/snapshots/upload/action
For detailed steps on assigning a role, see the following articles for portal, PowerShell, or CLI. To create or update a custom role, see the following articles for portal, PowerShell, or CLI.
Enable data access authentication mode
Portal
PowerShell
Azure CLI
Enable data access authentication mode to restrict access to the disk. You can either enable it when creating the disk, or you can enable it on the Disk Export page for existing disks.
Set dataAccessAuthMode to "AzureActiveDirectory" on your disk, in order to download it when it's been secured. Use the following script to update an existing disk, replace the values for -ResourceGroupName and -DiskName before running the script:
New-AzDiskUpdateConfig -DataAccessAuthMode "AzureActiveDirectory" | Update-AzDisk -ResourceGroupName 'yourResourceGroupName' -DiskName 'yourDiskName"
Set dataAccessAuthMode to "AzureActiveDirectory" on your disk, in order to download it when it's been secured. Use the following script to update an existing disk, replace the values for --resource-group and --Name before running the script:
az disk update --name yourDiskName --resource-group yourResourceGroup --data-access-auth-mode AzureActiveDirectory
Generate download URL
To download the VHD file, you need to generate a shared access signature (SAS) URL. When the URL is generated, an expiration time is assigned to the URL.
Portal
PowerShell
Azure CLI
On the page for the VM, click Disks in the left menu.
Select the operating system disk for the VM.
On the page for the disk, select Disk Export from the left menu.
The default expiration time of the URL is 3600 seconds (one hour). You may need to increase this for Windows OS disks or large data disks. 36000 seconds (10 hours) is usually sufficient.
Click Generate URL.
Replace yourRGName and yourDiskName with your values, then run the following command to get your SAS.
$diskSas = Grant-AzDiskAccess -ResourceGroupName "yourRGName" -DiskName "yourDiskName" -DurationInSecond 86400 -Access 'Read'
Replace yourRGName and yourDiskName with your values, then run the following command to get your SAS.
az disk grant-access --duration-in-seconds 86400 --access-level Read --name yourDiskName --resource-group yourRGName
Note
The expiration time is increased from the default to provide enough time to download the large VHD file for a Windows Server operating system. Large VHDs can take up to several hours to download depending on your connection and the size of the VM.
Download VHD
Note
If you're using Azure AD to secure managed disk downloads, the user downloading the VHD must have the appropriate RBAC permissions.
Portal
PowerShell
Azure CLI
Under the URL that was generated, click Download the VHD file.
You may need to click Save in your browser to start the download. The default name for the VHD file is abcd.
Use the following script to download your VHD:
Connect-AzAccount
#Set localFolder to your desired download location
$localFolder = "c:\tempfiles"
$blob = Get-AzStorageBlobContent -Uri $diskSas.AccessSAS -Destination $localFolder -Force
When the download finishes, revoke access to your disk using Revoke-AzDiskAccess -ResourceGroupName "yourRGName" -DiskName "yourDiskName".
Replace yourPathhere and sas-URI with your values, then use the following script to download your VHD:
Note
If you're using Azure AD to secure your managed disk uploads and downloads, add --auth-mode login to az storage blob download.
#set localFolder to your desired download location
localFolder=yourPathHere
#If you're using Azure AD to secure your managed disk uploads and downloads, add --auth-mode login to the following command.
az storage blob download -f $localFolder --blob-url "sas-URI"
When the download finishes, revoke access to your disk using az disk revoke-access --name diskName --resource-group yourRGName.
Next steps
Learn how to upload a VHD file to Azure.
Create managed disks from unmanaged disks in a storage account.
Manage Azure disks with PowerShell.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

12263
How to convert Azure managed disks between the different disks types by using Azure PowerShell, Azure CLI, or the Azure portal.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-convert-types 

>>>
Convert managed disks storage between different disk types - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Change the disk type of an Azure managed disk

Article
06/21/2023

1 contributor
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows
There are five disk types of Azure managed disks: Azure Ultra Disks, Premium SSD v2, premium SSD, Standard SSD, and Standard HDD. You can easily switch between Premium SSD, Standard SSD, and Standard HDD based on your performance needs. You aren't yet able to switch from or to an Ultra Disk or a Premium SSD v2, you must deploy a new one.
This functionality isn't supported for unmanaged disks. But you can easily convert an unmanaged disk to a managed disk with CLI or PowerShell to be able to switch between disk types.
Before you begin
Because conversion requires a restart of the virtual machine (VM), schedule the migration of your disk during a pre-existing maintenance window.
Restrictions
You can only change disk type once per day.
You can only change the disk type of managed disks. If your disk is unmanaged, convert it to a managed disk with CLI or PowerShell to switch between disk types.
Switch all managed disks of a VM between from one account to another
This example shows how to convert all of a VM's disks to premium storage. However, by changing the $storageType variable in this example, you can convert the VM's disks type to standard SSD or standard HDD. To use Premium managed disks, your VM must use a VM size that supports Premium storage. This example also switches to a size that supports premium storage:
Azure PowerShell
Azure CLI
Portal
# Name of the resource group that contains the VM
$rgName = 'yourResourceGroup'
# Name of the your virtual machine
$vmName = 'yourVM'
# Choose between Standard_LRS, StandardSSD_LRS and Premium_LRS based on your scenario
$storageType = 'Premium_LRS'
# Premium capable size
# Required only if converting storage from Standard to Premium
$size = 'Standard_DS2_v2'
# Stop and deallocate the VM before changing the size
Stop-AzVM -ResourceGroupName $rgName -Name $vmName -Force
$vm = Get-AzVM -Name $vmName -resourceGroupName $rgName
# Change the VM size to a size that supports Premium storage
# Skip this step if converting storage from Premium to Standard
$vm.HardwareProfile.VmSize = $size
Update-AzVM -VM $vm -ResourceGroupName $rgName
# Get all disks in the resource group of the VM
$vmDisks = Get-AzDisk -ResourceGroupName $rgName
# For disks that belong to the selected VM, convert to Premium storage
foreach ($disk in $vmDisks)
{
	if ($disk.ManagedBy -eq $vm.Id)
	{
		$disk.Sku = [Microsoft.Azure.Management.Compute.Models.DiskSku]::new($storageType)
		$disk | Update-AzDisk
	}
}
Start-AzVM -ResourceGroupName $rgName -Name $vmName
#resource group that contains the virtual machine
$rgName='yourResourceGroup'
#Name of the virtual machine
vmName='yourVM'
#Premium capable size
#Required only if converting from Standard to Premium
size='Standard_DS2_v2'
#Choose between Standard_LRS, StandardSSD_LRS and Premium_LRS based on your scenario
sku='Premium_LRS'
#Deallocate the VM before changing the size of the VM
az vm deallocate --name $vmName --resource-group $rgName
#Change the VM size to a size that supports Premium storage
#Skip this step if converting storage from Premium to Standard
az vm resize --resource-group $rgName --name $vmName --size $size
#Update the SKU of all the data disks
az vm show -n $vmName -g $rgName --query storageProfile.dataDisks[*].managedDisk -o tsv \
| awk -v sku=$sku '{system("az disk update --sku "sku" --ids "$1)}'
#Update the SKU of the OS disk
az vm show -n $vmName -g $rgName --query storageProfile.osDisk.managedDisk -o tsv \
| awk -v sku=$sku '{system("az disk update --sku "sku" --ids "$1)}'
az vm start --name $vmName --resource-group $rgName
Use either PowerShell or CLI.
Change the type of an individual managed disk
For your dev/test workload, you might want a mix of Standard and Premium disks to reduce your costs. You can choose to upgrade only those disks that need better performance. This example shows how to convert a single VM disk from Standard to Premium storage. However, by changing the $storageType variable in this example, you can convert the VM's disks type to standard SSD or standard HDD. To use Premium managed disks, your VM must use a VM size that supports Premium storage. You can also use these examples to change a disk from Locally redundant storage (LRS) disk to a Zone-redundant storage (ZRS) disk or vice-versa. This example also shows how to switch to a size that supports Premium storage:
Azure PowerShell
Azure CLI
Portal
$diskName = 'yourDiskName'
# resource group that contains the managed disk
$rgName = 'yourResourceGroupName'
# Choose between Standard_LRS, StandardSSD_LRS and Premium_LRS based on your scenario
$storageType = 'Premium_LRS'
# Premium capable size
$size = 'Standard_DS2_v2'
$disk = Get-AzDisk -DiskName $diskName -ResourceGroupName $rgName
# Get parent VM resource
$vmResource = Get-AzResource -ResourceId $disk.ManagedBy
# Stop and deallocate the VM before changing the storage type
Stop-AzVM -ResourceGroupName $vmResource.ResourceGroupName -Name $vmResource.Name -Force
$vm = Get-AzVM -ResourceGroupName $vmResource.ResourceGroupName -Name $vmResource.Name
# Change the VM size to a size that supports Premium storage
# Skip this step if converting storage from Premium to Standard
$vm.HardwareProfile.VmSize = $size
Update-AzVM -VM $vm -ResourceGroupName $rgName
# Update the storage type
$disk.Sku = [Microsoft.Azure.Management.Compute.Models.DiskSku]::new($storageType)
$disk | Update-AzDisk
Start-AzVM -ResourceGroupName $vm.ResourceGroupName -Name $vm.Name
#resource group that contains the managed disk
$rgName='yourResourceGroup'
#Name of your managed disk
diskName='yourManagedDiskName'
#Premium capable size
#Required only if converting from Standard to Premium
size='Standard_DS2_v2'
#Choose between Standard_LRS, StandardSSD_LRS and Premium_LRS based on your scenario
sku='Premium_LRS'
#Get the parent VM Id
vmId=$(az disk show --name $diskName --resource-group $rgName --query managedBy --output tsv)
#Deallocate the VM before changing the size of the VM
az vm deallocate --ids $vmId
#Change the VM size to a size that supports Premium storage
#Skip this step if converting storage from Premium to Standard
az vm resize --ids $vmId --size $size
# Update the SKU
az disk update --sku $sku --name $diskName --resource-group $rgName
az vm start --ids $vmId
Follow these steps:
Sign in to the Azure portal.
Select the VM from the list of Virtual machines.
If the VM isn't stopped, select Stop at the top of the VM Overview pane, and wait for the VM to stop.
In the pane for the VM, select Disks from the menu.
Select the disk that you want to convert.
Select Size + performance from the menu.
Change the Account type from the original disk type to the desired disk type.
Select Save, and close the disk pane.
The disk type conversion is instantaneous. You can start your VM after the conversion.
Migrate to Premium SSD v2 or Ultra Disk
Currently, you can only migrate an existing disk to either an Ultra Disk or a Premium SSD v2 through snapshots. Both Premium SSD v2 disks and Ultra Disks have their own set of restrictions. For example, neither can be used as an OS disk, and also aren't available in all regions. See the Premium SSD v2 limitations and Ultra Disk GA scope and limitations sections of their articles for more information.
Important
When migrating a Standard HDD, Standard SSD, or Premium SSD to either an Ultra Disk or Premium SSD v2, the logical sector size must be 512.
Azure PowerShell
Azure CLI
Portal
The following script migrates a snapshot of a Standard HDD, Standard SSD, or Premium SSD to either an Ultra Disk or a Premium SSD v2.
$diskName = "yourDiskNameHere"
$resourceGroupName = "yourResourceGroupNameHere"
$snapshotName = "yourDesiredSnapshotNameHere"
# Valid values are 1, 2, or 3
$zone = "yourZoneNumber"
#Provide the size of the disks in GB. It should be greater than the VHD file size.
$diskSize = '128'
#Provide the storage type. Use PremiumV2_LRS or UltraSSD_LRS.
$storageType = 'PremiumV2_LRS'
#Provide the Azure region (e.g. westus) where Managed Disks will be located.
#This location should be same as the snapshot location
#Get all the Azure location using command below:
#Get-AzLocation
#Select the same location as the current disk
#Note that Premium SSD v2 and Ultra Disks are only supported in a select number of regions
$location = 'eastus'
#When migrating a Standard HDD, Standard SSD, or Premium SSD to either an Ultra Disk or Premium SSD v2, the logical sector size must be 512
$logicalSectorSize=512
# Get the disk that you need to backup by creating an incremental snapshot
$yourDisk = Get-AzDisk -DiskName $diskName -ResourceGroupName $resourceGroupName
# Create an incremental snapshot by setting the SourceUri property with the value of the Id property of the disk
$snapshotConfig=New-AzSnapshotConfig -SourceUri $yourDisk.Id -Location $yourDisk.Location -CreateOption Copy -Incremental
$snapshot = New-AzSnapshot -ResourceGroupName $resourceGroupName -SnapshotName $snapshotName -Snapshot $snapshotConfig
$diskConfig = New-AzDiskConfig -SkuName $storageType -Location $location -CreateOption Copy -SourceResourceId $snapshot.Id -DiskSizeGB $diskSize -LogicalSectorSize $logicalSectorSize -Zone $zone
New-AzDisk -Disk $diskConfig -ResourceGroupName $resourceGroupName -DiskName $diskName
The following script migrates a snapshot of a Standard HDD, Standard SSD, or Premium SSD to either an Ultra Disk or a Premium SSD v2.
# Declare variables
diskName="yourExistingDiskNameHere"
newDiskName="newDiskNameHere"
resourceGroupName="yourResourceGroupNameHere"
snapshotName="desiredSnapshotNameHere"
#Provide the storage type. Use PremiumV2_LRS or UltraSSD_LRS.
storageType=PremiumV2_LRS
#Select the same location as the current disk
#Note that Premium SSD v2 and Ultra Disks are only supported in a select number of regions
location=eastus
#When migrating a Standard HDD, Standard SSD, or Premium SSD to either an Ultra Disk or Premium SSD v2, the logical sector size must be 512
logicalSectorSize=512
#Select an Availability Zone, acceptable values are 1,2, or 3
zone=1
# Get the disk you need to backup
yourDiskID=$(az disk show -n $diskName -g $resourceGroupName --query "id" --output tsv)
# Create the snapshot
snapshot=$(az snapshot create -g $resourceGroupName -n $snapshotName --source $yourDiskID --incremental true)
az disk create -g resourceGroupName -n newDiskName --source $snapshot --logical-sector-size $logicalSectorSize --location $location --zone $zone
The following steps assume you already have a snapshot. To learn how to create one, see Create a snapshot of a virtual hard disk,
Sign in to the Azure portal.
Select the search bar at the top. Search for and select Disks.
Select +Create and fill in the details.
Make sure the Region and Availability zone meet the requirements of either your Premium SSD v2 or Ultra Disk.
For Region select the same region as the snapshot you took.
For Source Type select Snapshot.
Select the snapshot you created.
Select Change size and select either Premium SSD v2 or Ultra Disk for the Storage Type.
Select the performance and capacity you'd like the disk to have.
Continue to the Advanced tab.
Select 512 for Logical sector size (bytes).
Select Review+Create and then Create.
Next steps
Make a read-only copy of a VM by using a snapshot.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

7472
Azure CLI Script Sample - Copy (or move) managed disks to the same or a different subscription
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/copy-managed-disks-to-same-or-different-subscription 

>>>
Copy managed disks to same or different subscription - CLI Sample - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Copy managed disks to same or different subscription with CLI

Article
03/31/2023

																	4 contributors
Feedback
In this article
This article contains two scripts. The first script copies a managed disk that's using platform-managed keys to same or different subscription but in the same region. The second script copies a managed disk that's using customer-managed keys to the same or a different subscription in the same region. Either copy only works when the subscriptions are part of the same Azure AD tenant.
If you don't have an Azure subscription, create an Azure free account before you begin.
Prerequisites
Use the Bash environment in Azure Cloud Shell. For more information, see Quickstart for Bash in Azure Cloud Shell.
If you prefer to run CLI reference commands locally, install the Azure CLI. If you're running on Windows or macOS, consider running Azure CLI in a Docker container. For more information, see How to run the Azure CLI in a Docker container.
If you're using a local installation, sign in to the Azure CLI by using the az login command. To finish the authentication process, follow the steps displayed in your terminal. For other sign-in options, see Sign in with the Azure CLI.
When you're prompted, install the Azure CLI extension on first use. For more information about extensions, see Use extensions with the Azure CLI.
Run az version to find the version and dependent libraries that are installed. To upgrade to the latest version, run az upgrade.
Sample script
Launch Azure Cloud Shell
The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account.
To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also launch Cloud Shell in a separate browser tab by going to https://shell.azure.com.
When Cloud Shell opens, verify that Bash is selected for your environment. Subsequent sessions will use Azure CLI in a Bash environment, Select Copy to copy the blocks of code, paste it into the Cloud Shell, and press Enter to run it.
Sign in to Azure
Cloud Shell is automatically authenticated under the initial account signed-in with. Use the following script to sign in using a different subscription, replacing <Subscription ID> with your Azure Subscription ID.  If you don't have an Azure subscription, create an Azure free account before you begin.
subscription="<subscriptionId>" # add subscription here
az account set -s $subscription # ...or use 'az login'
For more information, see set active subscription or log in interactively
Disks with platform-managed keys
#Provide the subscription Id of the subscription where managed disk exists
sourceSubscriptionId="<subscriptionId>"
#Provide the name of your resource group where managed disk exists
sourceResourceGroupName=mySourceResourceGroupName
#Provide the name of the managed disk
managedDiskName=myDiskName
#Set the context to the subscription Id where managed disk exists
az account set --subscription $sourceSubscriptionId
#Get the managed disk Id
managedDiskId=$(az disk show --name $managedDiskName --resource-group $sourceResourceGroupName --query [id] -o tsv)
#If managedDiskId is blank then it means that managed disk does not exist.
echo 'source managed disk Id is: ' $managedDiskId
#Provide the subscription Id of the subscription where managed disk will be copied to
targetSubscriptionId=6492b1f7-f219-446b-b509-314e17e1efb0
#Name of the resource group where managed disk will be copied to
targetResourceGroupName=mytargetResourceGroupName
#Set the context to the subscription Id where managed disk will be copied to
az account set --subscription $targetSubscriptionId
#Copy managed disk to different subscription using managed disk Id
az disk create --resource-group $targetResourceGroupName --name $managedDiskName --source $managedDiskId
Disks with customer-managed keys
#Provide the subscription Id of the subscription where managed disk exists
sourceSubscriptionId="<subscriptionId>"
#Provide the name of your resource group where managed disk exists
sourceResourceGroupName=mySourceResourceGroupName
#Provide the name of the managed disk
managedDiskName=myDiskName
#Provide the name of the target disk encryption set
diskEncryptionSetName=myName
#Provide the target disk encryption set resource group
diskEncryptionResourceGroup=myGroup
#Set the context to the subscription Id where managed disk exists
az account set --subscription $sourceSubscriptionId
#Get the managed disk Id
managedDiskId=$(az disk show --name $managedDiskName --resource-group $sourceResourceGroupName --query [id] -o tsv)
#If managedDiskId is blank then it means that managed disk does not exist.
echo 'source managed disk Id is: ' $managedDiskId
#Get the disk encryption set ID
diskEncryptionSetId=$(az disk-encryption-set show --name $diskEncryptionSetName --resource-group $diskEncryptionResourceGroup)
#Provide the subscription Id of the subscription where managed disk will be copied to
targetSubscriptionId=6492b1f7-f219-446b-b509-314e17e1efb0
#Name of the resource group where managed disk will be copied to
targetResourceGroupName=mytargetResourceGroupName
#Set the context to the subscription Id where managed disk will be copied to
az account set --subscription $targetSubscriptionId
#Copy managed disk to different subscription using managed disk Id and disk encryption set ID
#Add --location parameter to change the location
az disk create -g $targetResourceGroupName -n $managedDiskName --source $managedDiskId --disk-encryption-set $diskEncrpytonSetId
Clean up resources
Run the following command to remove the resource group, VM, and all related resources.
az group delete --name mySourceResourceGroupName
Sample reference
This script uses following commands to create a new managed disk in the target subscription using the Id of the source managed disk. Each command in the table links to command specific documentation.
Command
Notes
az disk show
Gets all the properties of a managed disk using the name and resource group properties of the managed disk. The Id property is used to copy the managed disk to different subscription.
az disk create
Copies a managed disk by creating a new managed disk in different subscription using the Id and name the parent managed disk.
Next steps
Create a virtual machine from a managed disk
For more information on the Azure CLI, see Azure CLI documentation.
More virtual machine and managed disks CLI script samples can be found in the Azure Linux VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

8831
Azure CLI Script Sample - Copy (or move) snapshot of a managed disk to same or different subscription with CLI
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/copy-snapshot-to-same-or-different-subscription 

>>>
Copy managed disk snapshot to a subscription - CLI Sample - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Copy snapshot of a managed disk to same or different subscription with CLI

Article
03/31/2023

																	4 contributors
Feedback
In this article
This article contains two scripts. The first script copies a snapshot of a managed disk that was using platform-managed keys to the same or a different subscription. The second script copies a snapshot of a managed disk that was using customer-managed keys to the same or a different subscription. These scripts can be used for the following scenarios:
Migrate a snapshot in Premium storage (Premium_LRS) to Standard storage (Standard_LRS or Standard_ZRS) to reduce your cost.
Migrate a snapshot from locally redundant storage (Premium_LRS, Standard_LRS) to zone redundant storage (Standard_ZRS) to benefit from the higher reliability of ZRS storage.
Move a snapshot to different subscription in the same region for longer retention.
Note
Both subscriptions must be located under the same tenant
If you don't have an Azure subscription, create an Azure free account before you begin.
Prerequisites
Use the Bash environment in Azure Cloud Shell. For more information, see Quickstart for Bash in Azure Cloud Shell.
If you prefer to run CLI reference commands locally, install the Azure CLI. If you're running on Windows or macOS, consider running Azure CLI in a Docker container. For more information, see How to run the Azure CLI in a Docker container.
If you're using a local installation, sign in to the Azure CLI by using the az login command. To finish the authentication process, follow the steps displayed in your terminal. For other sign-in options, see Sign in with the Azure CLI.
When you're prompted, install the Azure CLI extension on first use. For more information about extensions, see Use extensions with the Azure CLI.
Run az version to find the version and dependent libraries that are installed. To upgrade to the latest version, run az upgrade.
Sample script
Launch Azure Cloud Shell
The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account.
To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also launch Cloud Shell in a separate browser tab by going to https://shell.azure.com.
When Cloud Shell opens, verify that Bash is selected for your environment. Subsequent sessions will use Azure CLI in a Bash environment, Select Copy to copy the blocks of code, paste it into the Cloud Shell, and press Enter to run it.
Sign in to Azure
Cloud Shell is automatically authenticated under the initial account signed-in with. Use the following script to sign in using a different subscription, replacing <Subscription ID> with your Azure Subscription ID.  If you don't have an Azure subscription, create an Azure free account before you begin.
subscription="<subscriptionId>" # add subscription here
az account set -s $subscription # ...or use 'az login'
For more information, see set active subscription or log in interactively
Disks with platform-managed keys
#Provide the subscription Id of the subscription where snapshot exists
sourceSubscriptionId="<subscriptionId>"
#Provide the name of your resource group where snapshot exists
sourceResourceGroupName=mySourceResourceGroupName
#Provide the name of the snapshot
snapshotName=mySnapshotName
#Set the context to the subscription Id where snapshot exists
az account set --subscription $sourceSubscriptionId
#Get the snapshot Id
snapshotId=$(az snapshot show --name $snapshotName --resource-group $sourceResourceGroupName --query [id] -o tsv)
#If snapshotId is blank then it means that snapshot does not exist.
echo 'source snapshot Id is: ' $snapshotId
#Provide the subscription Id of the subscription where snapshot will be copied to
#If snapshot is copied to the same subscription then you can skip this step
targetSubscriptionId=6492b1f7-f219-446b-b509-314e17e1efb0
#Name of the resource group where snapshot will be copied to
targetResourceGroupName=mytargetResourceGroupName
#Set the context to the subscription Id where snapshot will be copied to
#If snapshot is copied to the same subscription then you can skip this step
az account set --subscription $targetSubscriptionId
#Copy snapshot to different subscription using the snapshot Id
#We recommend you to store your snapshots in Standard storage to reduce cost. Please use Standard_ZRS in regions where zone redundant storage (ZRS) is available, otherwise use Standard_LRS
#Please check out the availability of ZRS here: https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy-zrs#support-coverage-and-regional-availability
az snapshot create --resource-group $targetResourceGroupName --name $snapshotName --source $snapshotId --sku Standard_LRS
Disks with customer-managed keys
#Provide the subscription Id of the subscription where snapshot exists
sourceSubscriptionId="<subscriptionId>"
#Provide the name of your resource group where snapshot exists
sourceResourceGroupName=mySourceResourceGroupName
#Provide the name of the target disk encryption set
diskEncryptionSetName=myName
#Provide the target disk encryption set resource group
diskEncryptionResourceGroup=myGroup
#Provide the name of the snapshot
snapshotName=mySnapshotName
#Set the context to the subscription Id where snapshot exists
az account set --subscription $sourceSubscriptionId
#Get the snapshot Id
snapshotId=$(az snapshot show --name $snapshotName --resource-group $sourceResourceGroupName --query [id] -o tsv)
#If snapshotId is blank then it means that snapshot does not exist.
echo 'source snapshot Id is: ' $snapshotId
#Get the disk encryption set ID
diskEncryptionSetId=$(az disk-encryption-set show --name $diskEncryptionSetName --resource-group $diskEncryptionResourceGroup)
#Provide the subscription Id of the subscription where snapshot will be copied to
#If snapshot is copied to the same subscription then you can skip this step
targetSubscriptionId=6492b1f7-f219-446b-b509-314e17e1efb0
#Name of the resource group where snapshot will be copied to
targetResourceGroupName=mytargetResourceGroupName
#Set the context to the subscription Id where snapshot will be copied to
#If snapshot is copied to the same subscription then you can skip this step
az account set --subscription $targetSubscriptionId
#Copy snapshot to different subscription using the snapshot Id
#We recommend you to store your snapshots in Standard storage to reduce cost. Please use Standard_ZRS in regions where zone redundant storage (ZRS) is available, otherwise use Standard_LRS
#Please check out the availability of ZRS here: https://docs.microsoft.com/en-us/azure/storage/common/storage-redundancy-zrs#support-coverage-and-regional-availability
#To change the region, use the --location parameter
az snapshot create -g $targetResourceGroupName -n $snapshotName --source $snapshotId --disk-encryption-set $diskEncryptionSetID --sku Standard_LRS --encryption-type EncryptionAtRestWithCustomerKey
Clean up resources
Run the following command to remove the resource group, VM, and all related resources.
az group delete --name mySourceResourceGroupName
Sample reference
This script uses following commands to create a snapshot in the target subscription using the Id of the source snapshot. Each command in the table links to command specific documentation.
Command
Notes
az snapshot show
Gets all the properties of a snapshot using the name and resource group properties of the snapshot. The Id property is used to copy the snapshot to different subscription.
az snapshot create
Copies a snapshot by creating a snapshot in different subscription using the Id and name of the parent snapshot.
Next steps
Create a virtual machine from a snapshot
For more information on the Azure CLI, see Azure CLI documentation.
More virtual machine and managed disks CLI script samples can be found in the Azure Linux VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4497
Azure PowerShell Script Sample -  Copy (move) snapshot of a managed disk to same or different subscription
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-powershell-sample-copy-snapshot-to-same-or-different-subscription 

>>>
Copy snapshot of managed disk to subscription (Windows) - PowerShell - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Copy snapshot of a managed disk in same subscription or different subscription with PowerShell (Windows)

Article
03/31/2023

																	4 contributors
Feedback
In this article
This script copies a snapshot of a managed disk to same or different subscription. Use this script for the following scenarios:
Migrate a snapshot in Premium storage (Premium_LRS) to Standard storage (Standard_LRS or Standard_ZRS) to reduce your cost.
Migrate a snapshot from locally redundant storage (Premium_LRS, Standard_LRS) to zone redundant storage (Standard_ZRS) to benefit from the higher reliability of ZRS storage.
Move a snapshot to different subscription in the same region for longer retention.
If needed, install the Azure PowerShell module using the instructions found in the Azure PowerShell guide, and then run Connect-AzAccount to create a connection with Azure. Also, you need to have an SSH public key named id_rsa.pub in the .ssh directory of your user profile.
If you don't have an Azure subscription, create an Azure free account before you begin.
Sample script
#Provide the subscription Id of the subscription where snapshot exists
$sourceSubscriptionId='yourSourceSubscriptionId'
#Provide the name of your resource group where snapshot exists
$sourceResourceGroupName='yourResourceGroupName'
#Provide the name of the snapshot
$snapshotName='yourSnapshotName'
#Set the context to the subscription Id where snapshot exists
Select-AzSubscription -SubscriptionId $sourceSubscriptionId
#Get the source snapshot
$snapshot= Get-AzSnapshot -ResourceGroupName $sourceResourceGroupName -Name $snapshotName
#Provide the subscription Id of the subscription where snapshot will be copied to
#If snapshot is copied to the same subscription then you can skip this step
$targetSubscriptionId='yourTargetSubscriptionId'
#Name of the resource group where snapshot will be copied to
$targetResourceGroupName='yourTargetResourceGroupName'
#Set the context to the subscription Id where snapshot will be copied to
#If snapshot is copied to the same subscription then you can skip this step
Select-AzSubscription -SubscriptionId $targetSubscriptionId
#We recommend you to store your snapshots in Standard storage to reduce cost. Please use Standard_ZRS in regions where zone redundant storage (ZRS) is available, otherwise use Standard_LRS
#Please check out the availability of ZRS here: https://docs.microsoft.com/en-us/Az.Storage/common/storage-redundancy-zrs#support-coverage-and-regional-availability
$snapshotConfig = New-AzSnapshotConfig -SourceResourceId $snapshot.Id -Location $snapshot.Location -CreateOption Copy -SkuName Standard_LRS
#Create a new snapshot in the target subscription and resource group
New-AzSnapshot -Snapshot $snapshotConfig -SnapshotName $snapshotName -ResourceGroupName $targetResourceGroupName
Script explanation
This script uses following commands to create a snapshot in the target subscription using the Id of the source snapshot. Each command in the table links to command specific documentation.
Command
Notes
New-AzSnapshotConfig
Creates snapshot configuration that is used for snapshot creation. It includes the resource Id of the parent snapshot and location that is same as the parent snapshot.
New-AzSnapshot
Creates a snapshot using snapshot configuration, snapshot name, and resource group name passed as parameters.
Next steps
Create a virtual machine from a snapshot
For more information on the Azure PowerShell module, see Azure PowerShell documentation.
Additional virtual machine PowerShell script samples can be found in the Azure Windows VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4994
Create VMs in Azure using VHDs uploaded from other clouds like AWS or other virtualization platforms and use Azure managed disks.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/on-prem-to-azure 

>>>
Migrate from AWS and other platforms to managed disks in Azure - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Migrate from Amazon Web Services (AWS) and other platforms to managed disks in Azure

Article
05/26/2022

																	10 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs
You can upload VHD files from AWS or on-premises virtualization solutions to Azure to create virtual machines (VMs) that use managed disks. Azure managed disks removes the need to manage storage accounts for Azure IaaS VMs. You just specify the type of disk, and the size of that disk that you need, and Azure creates and manages the disk for you.
You can upload either generalized and specialized VHDs.
Generalized VHD - has had all of your personal account information removed using Sysprep.
Specialized VHD - maintains the user accounts, applications, and other state data from your original VM.
Important
Before uploading any VHD to Azure, you should follow Prepare a Windows VHD or VHDX to upload to Azure
Scenario
Documentation
You have existing AWS EC2 instances that you would like to migrate to Azure VMs using managed disks
Move a VM from Amazon Web Services (AWS) to Azure
You have a VM from another virtualization platform that you would like to use as an image to create multiple Azure VMs.
Upload a generalized VHD and use it to create a new VM in Azure
You have a uniquely customized VM that you would like to recreate in Azure.
Upload a specialized VHD to Azure and create a new VM
Overview of managed disks
Azure managed disks simplifies VM management by removing the need to manage storage accounts. Managed disks also benefit from better reliability of VMs in an Availability Set. It ensures that the disks of different VMs in an Availability Set are sufficiently isolated from each other to avoid a single point of failure. It automatically places disks of different VMs in an Availability Set in different Storage scale units (stamps) which limits the impact of single Storage scale unit failures caused due to hardware and software failures.
Based on your needs, you can choose from four types of storage options. To learn about the available disk types, see our article Select a disk type.
Plan for the migration to managed disks
This section helps you to make the best decision on VM and disk types.
If you are planning on migrating from unmanaged disks to managed disks, you should be aware that users with the Virtual Machine Contributor role will not be able to change the VM size (as they could pre-conversion). This is because VMs with managed disks require the user to have the Microsoft.Compute/disks/write permission on the OS disks.
Location
Pick a location where Azure managed disks are available. If you are migrating to premium SSDs, also ensure that premium storage is available in the region where you are planning to migrate to. See Azure Services by Region for up-to-date information on available locations.
VM sizes
If you are migrating to premium SSDs, you have to update the size of the VM to premium storage capable size available in the region where VM is located. Review the VM sizes that are premium storage capable. The Azure VM size specifications are listed in Sizes for virtual machines.
Review the performance characteristics of virtual machines that work with premium storage and choose the most appropriate VM size that best suits your workload. Make sure that there is sufficient bandwidth available on your VM to drive the disk traffic.
Disk sizes
For information on available disk types and sizes, see What disk types are available in Azure?.
Disk caching policy
Premium Managed Disks
By default, disk caching policy is Read-Only for all the Premium data disks, and Read-Write for the Premium operating system disk attached to the VM. This configuration setting is recommended to achieve the optimal performance for your application’s IOs. For write-heavy or write-only data disks (such as SQL Server log files), disable disk caching so that you can achieve better application performance.
Pricing
Review the pricing for managed disks.
Next Steps
Before uploading any VHD to Azure, you should follow Prepare a Windows VHD or VHDX to upload to Azure
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

14946
Migrate your existing virtual machines to Azure Premium Storage by using Site Recovery. Premium Storage offers high-performance, low-latency disk support for I/O-intensive workloads running on Azure Virtual Machines.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/migrate-to-premium-storage-using-azure-site-recovery 

>>>
Migrate your Linux VMs to Azure Premium Storage with Azure Site Recovery - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Use Site Recovery to migrate to Premium Storage

Article
01/10/2023

																	13 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
Azure premium SSDs delivers high-performance, low-latency disk support for virtual machines (VMs) that are running I/O-intensive workloads. This guide helps you migrate your VM disks from a standard storage account to a premium storage account by using Azure Site Recovery.
Site Recovery is an Azure service that contributes to your strategy for business continuity and disaster recovery by orchestrating the replication of on-premises physical servers and VMs to the cloud (Azure) or to a secondary datacenter. When outages occur in your primary location, you fail over to the secondary location to keep applications and workloads available. You fail back to your primary location when it returns to normal operation.
Site Recovery provides test failovers to support disaster recovery drills without affecting production environments. You can run failovers with minimal data loss (depending on replication frequency) for unexpected disasters. In the scenario of migrating to Premium Storage, you can use the failover in Site Recovery to migrate target disks to a premium storage account.
We recommend migrating to Premium Storage by using Site Recovery because this option provides minimal downtime. This option also avoids the manual execution of copying disks and creating new VMs. Site Recovery will systematically copy your disks and create new VMs during failover.
Site Recovery supports a number of types of failover with minimal or no downtime. To plan your downtime and estimate data loss, see the types of failover in Site Recovery. If you prepare to connect to Azure VMs after failover, you should be able to connect to the Azure VM by using RDP after failover.
Azure Site Recovery components
These Site Recovery components are relevant to this migration scenario:
Configuration server is an Azure VM that coordinates communication and manages data replication and recovery processes. On this VM, you run a single setup file to install the configuration server and an additional component, called a process server, as a replication gateway. Read about configuration server prerequisites. You set up the configuration server only once, and you can use it for all migrations to the same region.
Process server is a replication gateway that:
Receives replication data from source VMs.
Optimizes the data with caching, compression, and encryption.
Sends the data to a storage account.
It also handles push installation of the mobility service to source VMs and performs automatic discovery of source VMs. The default process server is installed on the configuration server. You can deploy additional standalone process servers to scale your deployment. Read about best practices for process server deployment and deploying additional process servers. You set up the process server only once, and you can use it for all migrations to the same region.
Mobility service is a component that is deployed on every standard VM that you want to replicate. It captures data writes on the standard VM and forwards them to the process server. Read about replicated machine prerequisites.
This graphic shows how these components interact:
Note
Site Recovery does not support the migration of Storage Spaces disks.
For additional components for other scenarios, see Scenario architecture.
Azure essentials
These are the Azure requirements for this migration scenario:
An Azure subscription.
An Azure premium storage account to store replicated data.
An Azure virtual network to which VMs will connect when they're created at failover. The Azure virtual network must be in the same region as the one in which Site Recovery runs.
An Azure standard storage account to store replication logs. This can be the same storage account for the VM disks that are being migrated.
Prerequisites
Understand the relevant migration scenario components in the preceding section.
Plan your downtime by learning about failover in Site Recovery.
Setup and migration steps
You can use Site Recovery to migrate Azure IaaS VMs between regions or within same region. The following instructions are tailored for this migration scenario from the article Replicate VMware VMs or physical servers to Azure. Please follow the links for detailed steps in addition to the instructions in this article.
Step 1: Create a Recovery Services vault
Open the Azure portal.
Select Create a resource > Management > Backup and Site Recovery (OMS). Alternatively, you can select Browse > Recovery Services Vault > Add.
Specify a region that VMs will be replicated to. For the purpose of migration in the same region, select the region where your source VMs and source storage accounts are.
Step 2: Choose your protection goals
On the VM where you want to install the configuration server, open the Azure portal.
Go to Recovery Services vaults > Settings > Site Recovery > Step 1: Prepare Infrastructure > Protection goal.
Under Protection goal, in the first drop-down list, select To Azure. In the second drop-down list, select Not virtualized / Other, and then select OK.
Step 3: Set up the source environment (configuration server)
Download Azure Site Recovery Unified Setup and the vault registration key by going to the Prepare infrastructure > Prepare source > Add Server panes.
You will need the vault registration key to run the unified setup. The key is valid for five days after you generate it.
In the Add Server pane, add a configuration server.
On the VM that you're using as the configuration server, run Unified Setup to install the configuration server and the process server. You can walk through the screenshots to complete the installation. You can refer to the following screenshots for steps specified for this migration scenario.
In Before You Begin, select Install the configuration server and process server.
In Registration, browse and select the registration key that you downloaded from the vault.
In Environment Details, select whether you're going to replicate VMware VMs. For this migration scenario, choose No.
After the installation is complete, do the following in the Microsoft Azure Site Recovery Configuration Server window:
Use the Manage Accounts tab to create the account that Site Recovery can use for automatic discovery. (In the scenario about protecting physical machines, setting up the account isn't relevant, but you need at least one account to enable one of the following steps. In this case, you can name the account and password as any.)
Use the Vault Registration tab to upload the vault credential file.
Step 4: Set up the target environment
Select Prepare infrastructure > Target, and specify the deployment model that you want to use for VMs after failover. You can choose Classic or Resource Manager, depending on your scenario.
Site Recovery checks that you have one or more compatible Azure storage accounts and networks.
Note
If you're using a premium storage account for replicated data, you need to set up an additional standard storage account to store replication logs.
Step 5: Set up replication settings
To verify that your configuration server is successfully associated with the replication policy that you create, follow Set up replication settings.
Step 6: Plan capacity
Use the capacity planner to accurately estimate network bandwidth, storage, and other requirements to meet your replication needs.
When you're done, select Yes, I have done it in Have you completed capacity planning?.
Step 7: Install the mobility service and enable replication
You can choose to push installation to your source VMs or to manually install the mobility service on your source VMs. You can find the requirement of pushing installation and the path of the manual installer in the provided link. If you're doing a manual installation, you might need to use an internal IP address to find the configuration server.
The failed-over VM will have two temporary disks: one from the primary VM and the other created during the provisioning of the VM in the recovery region. To exclude the temporary disk before replication, install the mobility service before you enable replication. To learn more about how to exclude the temporary disk, see Exclude disks from replication.
Enable replication as follows:
Select Replicate Application > Source. After you've enabled replication for the first time, select +Replicate in the vault to enable replication for additional machines.
In step 1, set up Source as your process server.
In step 2, specify the post-failover deployment model, a premium storage account to migrate to, a standard storage account to save logs, and a virtual network to fail to.
In step 3, add protected VMs by IP address. (You might need an internal IP address to find them.)
In step 4, configure the properties by selecting the accounts that you set up previously on the process server.
In step 5, choose the replication policy that you created previously in "Step 5: Set up replication settings."
Select OK.
Note
When an Azure VM is deallocated and started again, there is no guarantee that it will get the same IP address. If the IP address of the configuration server/process server or the protected Azure VMs changes, the replication in this scenario might not work correctly.
When you design your Azure Storage environment, we recommend that you use separate storage accounts for each VM in an availability set. We recommend that you follow the best practice in the storage layer to use multiple storage accounts for each availability set. Distributing VM disks to multiple storage accounts helps to improve storage availability and distributes the I/O across the Azure storage infrastructure.
If your VMs are in an availability set, instead of replicating disks of all VMs into one storage account, we highly recommend migrating multiple VMs multiple times. That way, the VMs in the same availability set do not share a single storage account. Use the Enable Replication pane to set up a destination storage account for each VM, one at a time.
You can choose a post-failover deployment model according to your need. If you choose Azure Resource Manager as your post-failover deployment model, you can fail over a VM (Resource Manager) to a VM (Resource Manager), or you can fail over a VM (classic) to a VM (Resource Manager).
Step 8: Run a test failover
To check whether your replication is complete, select your Site Recovery instance and then select Settings > Replicated Items. You will see the status and percentage of your replication process.
After initial replication is complete, run a test failover to validate your replication strategy. For detailed steps of a test failover, see Run a test failover in Site Recovery.
Note
Before you run any failover, make sure that your VMs and replication strategy meet the requirements. For more information about running a test failover, see Test failover to Azure in Site Recovery.
You can see the status of your test failover in Settings > Jobs > YOUR_FAILOVER_PLAN_NAME. In the pane, you  can see a breakdown of the steps and success/failure results. If the test failover fails at any step, select the step to check the error message.
Step 9: Run a failover
After the test failover is completed, run a failover to migrate your disks to Premium Storage and replicate the VM instances. Follow the detailed steps in Run a failover.
Be sure to select Shut down VMs and synchronize the latest data. This option specifies that Site Recovery should try to shut down the protected VMs and synchronize the data so that the latest version of the data will be failed over. If you don't select this option or the attempt doesn't succeed, the failover will be from the latest available recovery point for the VM.
Site Recovery will create a VM instance whose type is the same as or similar to a Premium Storage-capable VM. You can check the performance and price of various VM instances by going to Windows Virtual Machines Pricing or Linux Virtual Machines Pricing.
Post-migration steps
Configure replicated VMs to the availability set if applicable. Site Recovery does not support migrating VMs along with the availability set. Depending on the deployment of your replicated VM, do one of the following:
For a VM created through the classic deployment model: Add the VM to the availability set in the Azure portal. For detailed steps, go to Add an existing virtual machine to an availability set.
For a VM created through the Resource Manager deployment model: Save your configuration of the VM and then delete and re-create the VMs in the availability set. To do so, use the script at Set Azure Resource Manager VM Availability Set. Before you run this script, check its limitations and plan your downtime.
Delete old VMs and disks. Make sure that the Premium disks are consistent with source disks and that the new VMs perform the same function as the source VMs. Delete the VM and delete the disks from your source storage accounts in the Azure portal. If there's a problem in which the disk is not deleted even though you deleted the VM, see Troubleshoot storage resource deletion errors.
Clean the Azure Site Recovery infrastructure. If Site Recovery is no longer needed, you can clean its infrastructure. Delete replicated items, the configuration server, and the recovery policy, and then delete the Azure Site Recovery vault.
Troubleshooting
Monitor and troubleshoot protection for virtual machines and physical servers
Microsoft Q&A question page for Microsoft Azure Site Recovery
Next steps
For specific scenarios for migrating virtual machines, see the following resources:
Migrate Azure Virtual Machines between Storage Accounts
Upload a Linux virtual hard disk
Migrating Virtual Machines from Amazon AWS to Microsoft Azure
Also, see the following resources to learn more about Azure Storage and Azure Virtual Machines:
Azure Storage
Azure Virtual Machines
Select a disk type for IaaS VMs
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

14996
Learn how to migrate your VM disks from a standard storage account to a premium storage account by using Azure Site Recovery.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/migrate-to-premium-storage-using-azure-site-recovery 

>>>
Migrate your Windows VMs to Azure Premium Storage with Azure Site Recovery - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Migrate to Premium Storage by using Azure Site Recovery

Article
04/09/2023

																	15 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs
Azure premium SSDs deliver high-performance, low-latency disk support for virtual machines (VMs) that are running I/O-intensive workloads. This guide helps you migrate your VM disks from a standard storage account to a premium storage account by using Azure Site Recovery.
Site Recovery is an Azure service that contributes to your strategy for business continuity and disaster recovery by orchestrating the replication of on-premises physical servers and VMs to the cloud (Azure) or to a secondary datacenter. When outages occur in your primary location, you fail over to the secondary location to keep applications and workloads available. You fail back to your primary location when it returns to normal operation.
Site Recovery provides test failovers to support disaster recovery drills without affecting production environments. You can run failovers with minimal data loss (depending on replication frequency) for unexpected disasters. In the scenario of migrating to Premium Storage, you can use the failover in Site Recovery to migrate target disks to a premium storage account.
We recommend migrating to Premium Storage by using Site Recovery because this option provides minimal downtime. This option also avoids the manual execution of copying disks and creating new VMs. Site Recovery will systematically copy your disks and create new VMs during failover.
Site Recovery supports a number of types of failover with minimal or no downtime. To plan your downtime and estimate data loss, see the types of failover in Site Recovery. If you prepare to connect to Azure VMs after failover, you should be able to connect to the Azure VM by using RDP after failover.
Azure Site Recovery components
These Site Recovery components are relevant to this migration scenario:
Configuration server is an Azure VM that coordinates communication and manages data replication and recovery processes. On this VM, you run a single setup file to install the configuration server and an additional component, called a process server, as a replication gateway. Read about configuration server prerequisites. You set up the configuration server only once, and you can use it for all migrations to the same region.
Process server is a replication gateway that:
Receives replication data from source VMs.
Optimizes the data with caching, compression, and encryption.
Sends the data to a storage account.
It also handles push installation of the mobility service to source VMs and performs automatic discovery of source VMs. The default process server is installed on the configuration server. You can deploy additional standalone process servers to scale your deployment. Read about best practices for process server deployment and deploying additional process servers. You set up the process server only once, and you can use it for all migrations to the same region.
Mobility service is a component that is deployed on every standard VM that you want to replicate. It captures data writes on the standard VM and forwards them to the process server. Read about replicated machine prerequisites.
This graphic shows how these components interact:
Note
Site Recovery does not support the migration of Storage Spaces disks.
For additional components for other scenarios, see Scenario architecture.
Azure essentials
These are the Azure requirements for this migration scenario:
An Azure subscription.
An Azure premium storage account to store replicated data.
An Azure virtual network to which VMs will connect when they're created at failover. The Azure virtual network must be in the same region as the one in which Site Recovery runs.
An Azure standard storage account to store replication logs. This can be the same storage account for the VM disks that are being migrated.
Prerequisites
Understand the relevant migration scenario components in the preceding section.
Plan your downtime by learning about failover in Site Recovery.
Setup and migration steps
You can use Site Recovery to migrate Azure IaaS VMs between regions or within same region. The following instructions are tailored for this migration scenario from the article Replicate VMware VMs or physical servers to Azure. Please follow the links for detailed steps in addition to the instructions in this article.
Step 1: Create a Recovery Services vault
Open the Azure portal.
Select Create a resource > Management > Backup and Site Recovery (OMS). Alternatively, you can select Browse > Recovery Services Vault > Add.
Note
Backup and Site Recovery was formerly part of the OMS suite.
Specify a region that VMs will be replicated to. For the purpose of migration in the same region, select the region where your source VMs and source storage accounts are.
Step 2: Choose your protection goals
On the VM where you want to install the configuration server, open the Azure portal.
Go to Recovery Services vaults > Settings > Site Recovery > Step 1: Prepare Infrastructure > Protection goal.
Under Protection goal, in the first drop-down list, select To Azure. In the second drop-down list, select Not virtualized / Other, and then select OK.
Step 3: Set up the source environment (configuration server)
Download Azure Site Recovery Unified Setup and the vault registration key by going to the Prepare infrastructure > Prepare source > Add Server panes.
You will need the vault registration key to run the unified setup. The key is valid for five days after you generate it.
In the Add Server pane, add a configuration server.
On the VM that you're using as the configuration server, run Unified Setup to install the configuration server and the process server. You can walk through the screenshots to complete the installation. You can refer to the following screenshots for steps specified for this migration scenario.
In Before You Begin, select Install the configuration server and process server.
In Registration, browse and select the registration key that you downloaded from the vault.
In Environment Details, select whether you're going to replicate VMware VMs. For this migration scenario, choose No.
After the installation is complete, do the following in the Microsoft Azure Site Recovery Configuration Server window:
Use the Manage Accounts tab to create the account that Site Recovery can use for automatic discovery. (In the scenario about protecting physical machines, setting up the account isn't relevant, but you need at least one account to enable one of the following steps. In this case, you can name the account and password as any.)
Use the Vault Registration tab to upload the vault credential file.
Step 4: Set up the target environment
Select Prepare infrastructure > Target, and specify the deployment model that you want to use for VMs after failover. You can choose Classic or Resource Manager, depending on your scenario.
Site Recovery checks that you have one or more compatible Azure storage accounts and networks.
Note
If you're using a premium storage account for replicated data, you need to set up an additional standard storage account to store replication logs.
Step 5: Set up replication settings
To verify that your configuration server is successfully associated with the replication policy that you create, follow Set up replication settings.
Step 6: Plan capacity
Use the capacity planner to accurately estimate network bandwidth, storage, and other requirements to meet your replication needs.
When you're done, select Yes, I have done it in Have you completed capacity planning?.
Step 7: Install the mobility service and enable replication
You can choose to push installation to your source VMs or to manually install the mobility service on your source VMs. You can find the requirement of pushing installation and the path of the manual installer in the provided link. If you're doing a manual installation, you might need to use an internal IP address to find the configuration server.
The failed-over VM will have two temporary disks: one from the primary VM and the other created during the provisioning of the VM in the recovery region. To exclude the temporary disk before replication, install the mobility service before you enable replication. To learn more about how to exclude the temporary disk, see Exclude disks from replication.
Enable replication as follows:
Select Replicate Application > Source. After you've enabled replication for the first time, select +Replicate in the vault to enable replication for additional machines.
In step 1, set up Source as your process server.
In step 2, specify the post-failover deployment model, a premium storage account to migrate to, a standard storage account to save logs, and a virtual network to fail to.
In step 3, add protected VMs by IP address. (You might need an internal IP address to find them.)
In step 4, configure the properties by selecting the accounts that you set up previously on the process server.
In step 5, choose the replication policy that you created previously in "Step 5: Set up replication settings."
Select OK.
Note
When an Azure VM is deallocated and started again, there is no guarantee that it will get the same IP address. If the IP address of the configuration server/process server or the protected Azure VMs changes, the replication in this scenario might not work correctly.
When you design your Azure Storage environment, we recommend that you use separate storage accounts for each VM in an availability set. We recommend that you follow the best practice in the storage layer to use multiple storage accounts for each availability set. Distributing VM disks to multiple storage accounts helps to improve storage availability and distributes the I/O across the Azure storage infrastructure.
If your VMs are in an availability set, instead of replicating disks of all VMs into one storage account, we highly recommend migrating multiple VMs multiple times. That way, the VMs in the same availability set do not share a single storage account. Use the Enable Replication pane to set up a destination storage account for each VM, one at a time.
You can choose a post-failover deployment model according to your need. If you choose Azure Resource Manager as your post-failover deployment model, you can fail over a VM (Resource Manager) to a VM (Resource Manager), or you can fail over a VM (classic) to a VM (Resource Manager).
Step 8: Run a test failover
To check whether your replication is complete, select your Site Recovery instance and then select Settings > Replicated Items. You will see the status and percentage of your replication process.
After initial replication is complete, run a test failover to validate your replication strategy. For detailed steps of a test failover, see Run a test failover in Site Recovery.
Note
Before you run any failover, make sure that your VMs and replication strategy meet the requirements. For more information about running a test failover, see Test failover to Azure in Site Recovery.
You can see the status of your test failover in Settings > Jobs > YOUR_FAILOVER_PLAN_NAME. In the pane, you  can see a breakdown of the steps and success/failure results. If the test failover fails at any step, select the step to check the error message.
Step 9: Run a failover
After the test failover is completed, run a failover to migrate your disks to Premium Storage and replicate the VM instances. Follow the detailed steps in Run a failover.
Be sure to select Shut down VMs and synchronize the latest data. This option specifies that Site Recovery should try to shut down the protected VMs and synchronize the data so that the latest version of the data will be failed over. If you don't select this option or the attempt doesn't succeed, the failover will be from the latest available recovery point for the VM.
Site Recovery will create a VM instance whose type is the same as or similar to a Premium Storage-capable VM. You can check the performance and price of various VM instances by going to Windows Virtual Machines Pricing or Linux Virtual Machines Pricing.
Post-migration steps
Configure replicated VMs to the availability set if applicable. Site Recovery does not support migrating VMs along with the availability set. Depending on the deployment of your replicated VM, do one of the following:
For a VM created through the classic deployment model: Add the VM to the availability set in the Azure portal. For detailed steps, go to Add an existing virtual machine to an availability set.
For a VM created through the Resource Manager deployment model: Save your configuration of the VM and then delete and re-create the VMs in the availability set. To do so, use the script at Set Azure Resource Manager VM Availability Set. Before you run this script, check its limitations and plan your downtime.
Delete old VMs and disks. Make sure that the Premium disks are consistent with source disks and that the new VMs perform the same function as the source VMs. Delete the VM and delete the disks from your source storage accounts in the Azure portal. If there's a problem in which the disk is not deleted even though you deleted the VM, see Troubleshoot storage resource deletion errors.
Clean the Azure Site Recovery infrastructure. If Site Recovery is no longer needed, you can clean its infrastructure. Delete replicated items, the configuration server, and the recovery policy, and then delete the Azure Site Recovery vault.
Troubleshooting
Monitor and troubleshoot protection for virtual machines and physical servers
Microsoft Q&A question page for Microsoft Azure Site Recovery
Next steps
For specific scenarios for migrating virtual machines, see the following resources:
Migrate Azure Virtual Machines between Storage Accounts
Create and upload a Windows Server VHD to Azure
Migrating Virtual Machines from Amazon AWS to Microsoft Azure
Also, see the following resources to learn more about Azure Storage and Azure Virtual Machines:
Azure Storage
Azure Virtual Machines
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

2997
Migrate Azure virtual machines created using unmanaged disks in storage accounts to use Managed Disks.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/migrate-to-managed-disks 

>>>
Migrate Azure VMs to Managed Disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Migrate Azure VMs to Managed Disks in Azure

Article
08/18/2022

																	11 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs
Azure Managed Disks simplifies your storage management by removing the need to separately manage storage accounts.  You can also migrate your existing Azure VMs to Managed Disks to benefit from better reliability of VMs in an Availability Set. It ensures that the disks of different VMs in an Availability Set are sufficiently isolated from each other to avoid single point of failures. It automatically places disks of different VMs in an Availability Set in different Storage scale units (stamps) which limits the impact of single Storage scale unit failures caused due to hardware and software failures.
Based on your needs, you can choose from four types of storage options. To learn about the available disk types, see our article Select a disk type
Migration scenarios
You can migrate to Managed Disks in following scenarios:
Scenario
Article
Convert stand alone VMs and VMs in an availability set to managed disks
Convert VMs to use managed disks
Convert a single VM from classic to Resource Manager on managed disks
Create a VM from a classic VHD
Convert all the VMs in a vNet from classic to Resource Manager on managed disks
Migrate IaaS resources from classic to Resource Manager and then Convert a VM from unmanaged disks to managed disks
Upgrade VMs with standard unmanaged disks to VMs with managed premium disks
First, Convert a Windows virtual machine from unmanaged disks to managed disks. Then Update the storage type of a managed disk.
Important
VMs created through the classic deployment model will be retired on September 1, 2023.
If you use IaaS resources from Azure Service Management, please complete your migration by September 1, 2023. We encourage you to make the switch sooner to take advantage of the many feature enhancements in Azure Resource Manager.
For more information, see Migrate your IaaS resources to Azure Resource Manager by September 1, 2023.
Next steps
Learn more about Managed Disks
Review the pricing for Managed Disks.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3772
This article provides a high-level overview of the retirement of Azure unmanaged disks and how to migrate to Azure managed disks.
https://learn.microsoft.com/en-us/azure/virtual-machines/unmanaged-disks-deprecation 

>>>
We're retiring Azure unmanaged disks by September 30, 2025 - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Migrate your Azure unmanaged disks by September 30, 2025

Article
06/06/2023

																	6 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs
In 2017, we launched Azure managed disks. We've been enhancing capabilities ever since. Because Azure managed disks now have the full capabilities of unmanaged disks and other advancements, we'll begin deprecating unmanaged disks on September 13, 2022. This functionality will be fully retired on September 30, 2025.
With managed disks, you don't have to worry about managing storage accounts for creating a disk, because Azure manages the storage accounts under the hood. The abstraction reduces maintenance overhead for you. Also, it allows managed disks to provide numerous benefits over unmanaged disks, such as better reliability, scalability, large disks, bursting, and shared disks. If you use unmanaged disks, start planning your Windows or Linux migration now. Complete the migration by September 30, 2025, to take advantage of Azure managed disks.
How does this affect me?
As of September 30, 2023, new customers won't be able to create unmanaged disks.
On September 30, 2025, customers will no longer be able to start IaaS VMs by using unmanaged disks. Any VMs that are still running or allocated will be stopped and deallocated.
What actions should I take?
Start planning your migration to Azure managed disks today.
Make a list of all affected VMs:
The VMs with Uses managed disks set to No on the Azure portal's VM pane are all the affected VMs within the subscription.
You can also query Azure Resource Graph by using the portal or PowerShell to view the list of all flagged VMs and related information for the selected subscriptions.
On February 28, 2020, we sent out emails to subscription owners with a list of all subscriptions that contain these VMs. Please use them to build this list.
Learn more about migrating your VMs to managed disks. For more information, see Frequently asked questions about migrating to managed disks.
For technical questions, issues, and help with adding subscriptions to the allowlist, contact support.
Complete the migration as soon as possible to prevent business impact and to take advantage of the improved reliability, scalability, security, and new features of Azure managed disks.
What resources are available for this migration?
Microsoft Q&A: Microsoft and community support for migration.
Azure Migration Support: Dedicated support team for technical assistance during migration.
Microsoft FastTrack: FastTrack can assist eligible customers with planning and execution of this migration. Nominate yourself.
If your company/organization has partnered with Microsoft or works with Microsoft representatives such as cloud solution architects (CSAs) or technical account managers (TAMs), please work with them for additional resources for migration.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

6343
How to Migrate a Linux VM from unmanaged disks to managed disks by using Azure CLI.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/convert-unmanaged-to-managed-disks 

>>>
Migrate a Linux VM from unmanaged disks to managed disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Migrate a Linux virtual machine from unmanaged disks to managed disks

Article
03/08/2023

																	15 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs
If you have existing Linux virtual machines (VMs) that use unmanaged disks, you can migrate the VMs to use Azure Managed Disks. This process converts both the OS disk and any attached data disks.
This article shows you how to migrate VMs by using the Azure CLI. If you need to install or upgrade it, see Install Azure CLI.
Before you begin
Review the FAQ about migration to Managed Disks.
The migration will restart the VM, so schedule the migration of your VMs during a pre-existing maintenance window.
The migration isn't reversible.
Any users with the Virtual Machine Contributor role won't be able to change the VM size (as they could pre-migration). This is because VMs with managed disks require the user to have the Microsoft.Compute/disks/write permission on the OS disks.
Be sure to test the migration. Migrate a test virtual machine before you perform the migration in production.
During the migration, you deallocate the VM. The VM receives a new IP address when it's started after the migration. If needed, you can assign a static IP address to the VM.
Review the minimum version of the Azure VM agent required to support the migration process. For information on how to check and update your agent version, see Minimum version support for VM agents in Azure
The original VHDs and the storage account used by the VM before migration are not deleted. They continue to incur charges. To avoid being billed for these artifacts, delete the original VHD blobs after you verify that the migration is complete. If you need to find these unattached disks in order to delete them, see our article Find and delete unattached Azure managed and unmanaged disks.
Migrate single-instance VMs
This section covers how to migrate single-instance Azure VMs from unmanaged disks to managed disks. (If your VMs are in an availability set, see the next section.) You can use this process to migrate the VMs from premium (SSD) unmanaged disks to premium managed disks, or from standard (HDD) unmanaged disks to standard managed disks.
Deallocate the VM by using az vm deallocate. The following example deallocates the VM named myVM in the resource group named myResourceGroup:
az vm deallocate --resource-group myResourceGroup --name myVM
Migrate the VM to managed disks by using az vm convert. The following process converts the VM named myVM, including the OS disk and any data disks:
az vm convert --resource-group myResourceGroup --name myVM
Start the VM after the migration to managed disks by using az vm start. The following example starts the VM named myVM in the resource group named myResourceGroup.
az vm start --resource-group myResourceGroup --name myVM
Migrate VMs in an availability set
If the VMs that you want to migrate to managed disks are in an availability set, you first need to migrate the availability set to a managed availability set.
All VMs in the availability set must be deallocated before you migrate the availability set. Plan to migrate all VMs to managed disks after the availability set itself has been converted to a managed availability set. Then, start all the VMs and continue operating as normal.
List all VMs in an availability set by using az vm availability-set list. The following example lists all VMs in the availability set named myAvailabilitySet in the resource group named myResourceGroup:
az vm availability-set show \
    --resource-group myResourceGroup \
    --name myAvailabilitySet \
    --query [virtualMachines[*].id] \
    --output table
Deallocate all the VMs by using az vm deallocate. The following example deallocates the VM named myVM in the resource group named myResourceGroup:
az vm deallocate --resource-group myResourceGroup --name myVM
Migrate the availability set by using az vm availability-set convert. The following example converts the availability set named myAvailabilitySet in the resource group named myResourceGroup:
az vm availability-set convert \
    --resource-group myResourceGroup \
    --name myAvailabilitySet
Migrate all the VMs to managed disks by using az vm convert. The following process converts the VM named myVM, including the OS disk and any data disks:
az vm convert --resource-group myResourceGroup --name myVM
Start all the VMs after the migration to managed disks by using az vm start. The following example starts the VM named myVM in the resource group named myResourceGroup:
az vm start --resource-group myResourceGroup --name myVM
Migrate using the Azure portal
You can also migrate unmanaged disks to managed disks using the Azure portal.
Sign in to the Azure portal.
Select the VM from the list of VMs in the portal.
In the blade for the VM, select Disks from the menu.
At the top of the Disks blade, select Migrate to managed disks.
If your VM is in an availability set, there will be a warning on the Migrate to managed disks blade that you need to migrate the availability set first. The warning should have a link you can click to migrate the availability set. Once the availability set is converted or if your VM is not in an availability set, click Migrate to start the process of migrating your disks to managed disks.
The VM will be stopped and restarted after migration is complete.
Next steps
For more information about storage options, see Azure Managed Disks overview.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

6693
How to migrate a Windows VM from unmanaged disks to managed disks by using PowerShell in the Resource Manager deployment model
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/convert-unmanaged-to-managed-disks 

>>>
Migrate a Windows virtual machine from unmanaged disks to managed disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Migrate a Windows virtual machine from unmanaged disks to managed disks

Article
03/08/2023

																	20 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs
If you have existing Windows virtual machines (VMs) that use unmanaged disks, you can migrate the VMs to use managed disks through the Azure Managed Disks service. This process converts both the operating system (OS) disk and any attached data disks.
Before you begin
Review Plan for the migration to Managed Disks.
Review the FAQ about migration to Managed Disks.
The migration will restart the VM, so schedule the migration of your VMs during a pre-existing maintenance window.
The migration isn't reversible.
Any users with the Virtual Machine Contributor role won't be able to change the VM size (as they could pre-migration). This is because VMs with managed disks require the user to have the Microsoft.Compute/disks/write permission on the OS disks.
Be sure to test the migration. Migrate a test virtual machine before you perform the migration in production.
During the migration, you deallocate the VM. The VM receives a new IP address when it's started after the migration. If needed, you can assign a static IP address to the VM.
Review the minimum version of the Azure VM agent required to support the migration process. For information on how to check and update your agent version, see Minimum version support for VM agents in Azure
The original VHDs and the storage account used by the VM before migration are not deleted. They continue to incur charges. To avoid being billed for these artifacts, delete the original VHD blobs after you verify that the migration is complete. If you need to find these unattached disks in order to delete them, see our article Find and delete unattached Azure managed and unmanaged disks.
Migrate single-instance VMs
This section covers how to migrate single-instance Azure VMs from unmanaged disks to managed disks. (If your VMs are in an availability set, see the next section.)
Deallocate the VM by using the Stop-AzVM cmdlet. The following example deallocates the VM named myVM in the resource group named myResourceGroup:
$rgName = "myResourceGroup"
$vmName = "myVM"
Stop-AzVM -ResourceGroupName $rgName -Name $vmName -Force
Migrate the VM to managed disks by using the ConvertTo-AzVMManagedDisk cmdlet. The following process converts the previous VM, including the OS disk and any data disks, and starts the Virtual Machine:
ConvertTo-AzVMManagedDisk -ResourceGroupName $rgName -VMName $vmName
Migrate VMs in an availability set
If the VMs that you want to migrate to managed disks are in an availability set, you first need to migrate the availability set to a managed availability set.
Migrate the availability set by using the Update-AzAvailabilitySet cmdlet. The following example updates the availability set named myAvailabilitySet in the resource group named myResourceGroup:
$rgName = 'myResourceGroup'
$avSetName = 'myAvailabilitySet'
$avSet = Get-AzAvailabilitySet -ResourceGroupName $rgName -Name $avSetName
Update-AzAvailabilitySet -AvailabilitySet $avSet -Sku Aligned
If the region where your availability set is located has only 2 managed fault domains but the number of unmanaged fault domains is 3, this command shows an error similar to "The specified fault domain count 3 must fall in the range 1 to 2." To resolve the error, update the fault domain to 2 and update Sku to Aligned as follows:
$avSet.PlatformFaultDomainCount = 2
Update-AzAvailabilitySet -AvailabilitySet $avSet -Sku Aligned
Deallocate and migrate the VMs in the availability set. The following script deallocates each VM by using the Stop-AzVM cmdlet, converts it by using ConvertTo-AzVMManagedDisk, and restarts it automatically as apart of the migration process:
$avSet = Get-AzAvailabilitySet -ResourceGroupName $rgName -Name $avSetName
foreach($vmInfo in $avSet.VirtualMachinesReferences)
{
  $vm = Get-AzVM -ResourceGroupName $rgName | Where-Object {$_.Id -eq $vmInfo.id}
  Stop-AzVM -ResourceGroupName $rgName -Name $vm.Name -Force
  ConvertTo-AzVMManagedDisk -ResourceGroupName $rgName -VMName $vm.Name
}
Troubleshooting
Before converting, make sure all the VM extensions are in the 'Provisioning succeeded' state or the migration will fail with the error code 409.
If there is an error during migration, or if a VM is in a failed state because of issues in a previous migration, run the ConvertTo-AzVMManagedDisk cmdlet again. A simple retry usually unblocks the situation.
If you are converting a Linux VM to managed disks, use the latest version of the Azure Linux Agent. Operations using Azure Linux Agent versions '2.2.0' and earlier will likely fail. Running the migration on a generalized VM or a VM that belongs to a classic availability set is also not supported.
If the migration fails with the "SnapshotCountExceeded" error, delete some snapshots and attempt the operation again.
Migrate using the Azure portal
You can also migrate unmanaged disks to managed disks using the Azure portal.
Sign in to the Azure portal.
Select the VM from the list of VMs in the portal.
In the blade for the VM, select Disks from the menu.
At the top of the Disks blade, select Migrate to managed disks.
If your VM is in an availability set, there will be a warning on the Migrate to managed disks blade that you need to migrate the availability set first. The warning should have a link you can click to migrate the availability set. Once the availability set is converted or if your VM is not in an availability set, click Migrate to start the process of migrating your disks to managed disks.
The VM will be stopped and restarted after migration is complete.
Next steps
Change the disk type of an Azure managed disk.
Take a read-only copy of a VM by using snapshots.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5530
Azure CLI Script Sample - Create a managed disk from a VHD file in a storage account in the same subscription
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/create-managed-disk-from-vhd 

>>>
Create a managed disk from a VHD file in the same account - CLI sample - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Create a managed disk from a VHD file in a storage account in the same subscription with CLI (Linux)

Article
03/31/2023

																	4 contributors
Feedback
In this article
This script creates a managed disk from a VHD file in a storage account in the same subscription. Use this script to import a specialized (not generalized/sysprepped) VHD to managed OS disk to create a virtual machine. Or, use it to import a data VHD to managed data disk.
If you don't have an Azure subscription, create an Azure free account before you begin.
Prerequisites
Use the Bash environment in Azure Cloud Shell. For more information, see Quickstart for Bash in Azure Cloud Shell.
If you prefer to run CLI reference commands locally, install the Azure CLI. If you're running on Windows or macOS, consider running Azure CLI in a Docker container. For more information, see How to run the Azure CLI in a Docker container.
If you're using a local installation, sign in to the Azure CLI by using the az login command. To finish the authentication process, follow the steps displayed in your terminal. For other sign-in options, see Sign in with the Azure CLI.
When you're prompted, install the Azure CLI extension on first use. For more information about extensions, see Use extensions with the Azure CLI.
Run az version to find the version and dependent libraries that are installed. To upgrade to the latest version, run az upgrade.
Sample script
Launch Azure Cloud Shell
The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account.
To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also launch Cloud Shell in a separate browser tab by going to https://shell.azure.com.
When Cloud Shell opens, verify that Bash is selected for your environment. Subsequent sessions will use Azure CLI in a Bash environment, Select Copy to copy the blocks of code, paste it into the Cloud Shell, and press Enter to run it.
Sign in to Azure
Cloud Shell is automatically authenticated under the initial account signed-in with. Use the following script to sign in using a different subscription, replacing <Subscription ID> with your Azure Subscription ID.  If you don't have an Azure subscription, create an Azure free account before you begin.
subscription="<subscriptionId>" # add subscription here
az account set -s $subscription # ...or use 'az login'
For more information, see set active subscription or log in interactively
Run the script
#Provide the subscription Id
subscriptionId="<subscriptionId>"
#Provide the name of your resource group.
#Ensure that resource group is already created
resourceGroupName=myResourceGroupName
#Provide the name of the Managed Disk
diskName=myDiskName
#Provide the size of the disks in GB. It should be greater than the VHD file size.
diskSize=128
#Provide the URI of the VHD file that will be used to create Managed Disk.
# VHD file can be deleted as soon as Managed Disk is created.
# e.g. https://contosostorageaccount1.blob.core.windows.net/vhds/contosovhd123.vhd
vhdUri=https://contosostorageaccount1.blob.core.windows.net/vhds/contosoumd78620170425131836.vhd
#Provide the storage type for the Managed Disk. Premium_LRS or Standard_LRS.
storageType=Premium_LRS
#Provide the Azure location (e.g. westus) where Managed Disk will be located.
#The location should be same as the location of the storage account where VHD file is stored.
#Get all the Azure location supported for your subscription using command below:
#az account list-locations
location=westus
#Set the context to the subscription Id where Managed Disk will be created
az account set --subscription $subscriptionId
#Create the Managed disk from the VHD file
az disk create --resource-group $resourceGroupName --name $diskName --sku $storageType --location $location --size-gb $diskSize --source $vhdUri
Clean up resources
Run the following command to remove the resource group, VM, and all related resources.
az group delete --name myResourceGroupName
Sample reference
This script uses following commands to create a managed disk from a VHD. Each command in the table links to command specific documentation.
Command
Notes
az disk create
Creates a managed disk using URI of a VHD in a storage account in the same subscription
Next steps
Create a virtual machine by attaching a managed disk as OS disk
For more information on the Azure CLI, see Azure CLI documentation.
Additional virtual machine and managed disks CLI script samples can be found in the Azure Linux VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

7672
Azure CLI Script Sample - Create a managed disk from a snapshot
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/create-managed-disk-from-snapshot 

>>>
Create managed disk from snapshot (Linux) - CLI sample - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Create a managed disk from a snapshot with CLI (Linux)

Article
03/31/2023

																	6 contributors
Feedback
In this article
This article contains two scripts for creating a managed disk from a snapshot. The first script is for a managed disk with platform-managed keys and the second script is for a managed disk with customer-managed keys. Use these scripts to restore a virtual machine from snapshots of OS and data disks. Create OS and data managed disks from respective snapshots and then create a new virtual machine by attaching managed disks. You can also restore data disks of an existing VM by attaching data disks created from snapshots.
If you don't have an Azure subscription, create an Azure free account before you begin.
Prerequisites
Use the Bash environment in Azure Cloud Shell. For more information, see Quickstart for Bash in Azure Cloud Shell.
If you prefer to run CLI reference commands locally, install the Azure CLI. If you're running on Windows or macOS, consider running Azure CLI in a Docker container. For more information, see How to run the Azure CLI in a Docker container.
If you're using a local installation, sign in to the Azure CLI by using the az login command. To finish the authentication process, follow the steps displayed in your terminal. For other sign-in options, see Sign in with the Azure CLI.
When you're prompted, install the Azure CLI extension on first use. For more information about extensions, see Use extensions with the Azure CLI.
Run az version to find the version and dependent libraries that are installed. To upgrade to the latest version, run az upgrade.
Sample script
Launch Azure Cloud Shell
The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account.
To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also launch Cloud Shell in a separate browser tab by going to https://shell.azure.com.
When Cloud Shell opens, verify that Bash is selected for your environment. Subsequent sessions will use Azure CLI in a Bash environment, Select Copy to copy the blocks of code, paste it into the Cloud Shell, and press Enter to run it.
Sign in to Azure
Cloud Shell is automatically authenticated under the initial account signed-in with. Use the following script to sign in using a different subscription, replacing <Subscription ID> with your Azure Subscription ID.  If you don't have an Azure subscription, create an Azure free account before you begin.
subscription="<subscriptionId>" # add subscription here
az account set -s $subscription # ...or use 'az login'
For more information, see set active subscription or log in interactively
Disks with platform-managed keys
#Provide the subscription Id of the subscription where you want to create Managed Disks
subscriptionId="<subscriptionId>"
#Provide the name of your resource group
resourceGroupName=myResourceGroupName
#Provide the name of the snapshot that will be used to create Managed Disks
snapshotName=mySnapshotName
#Provide the name of the new Managed Disks that will be create
diskName=myDiskName
#Provide the size of the disks in GB. It should be greater than the VHD file size.
diskSize=128
#Provide the storage type for Managed Disk. Acceptable values are Standard_LRS, Premium_LRS, PremiumV2_LRS, StandardSSD_LRS, UltraSSD_LRS, Premium_ZRS, and StandardSSD_ZRS.
storageType=Premium_LRS
#Required for Premium SSD v2 and Ultra Disks
#Provide the Availability Zone you'd like the disk to be created in, default is 1
zone=1
#Set the context to the subscription Id where Managed Disk will be created
az account set --subscription $subscriptionId
#Get the snapshot Id
snapshotId=$(az snapshot show --name $snapshotName --resource-group $resourceGroupName --query [id] -o tsv)
#Create a new Managed Disks using the snapshot Id
#Note that managed disk will be created in the same location as the snapshot
#If you're creating a Premium SSD v2 or an Ultra Disk, add "--zone $zone" to the end of the command
az disk create --resource-group $resourceGroupName --name $diskName --sku $storageType --size-gb $diskSize --source $snapshotId
Disks with customer-managed keys
#Provide the subscription Id of the subscription where you want to create Managed Disks
subscriptionId="<subscriptionId>"
#Provide the name of your resource group
resourceGroupName=myResourceGroupName
#Provide the name of the snapshot that will be used to create Managed Disks
snapshotName=mySnapshotName
#Provide the name of the new Managed Disks that will be create
diskName=myDiskName
#Provide the size of the disks in GB. It should be greater than the VHD file size.
diskSize=128
#Provide the storage type for Managed Disk. Premium_LRS or Standard_LRS.
storageType=Premium_LRS
#Provide the name of the target disk encryption set
diskEncryptionSetName=myName
#Provide the target disk encryption set resource group
diskEncryptionResourceGroup=myGroup
#Required for Premium SSD v2 and Ultra Disks
#Provide the Availability Zone you'd like the disk to be created in, default is 1
zone=1
#Set the context to the subscription Id where Managed Disk will be created
az account set --subscription $subscriptionId
#Get the snapshot Id
snapshotId=$(az snapshot show --name $snapshotName --resource-group $resourceGroupName --query [id] -o tsv)
#Get the disk encryption set ID
diskEncryptionSetId=$(az disk-encryption-set show --name $diskEncryptionSetName --resource-group $diskEncryptionResourceGroup)
#Create a new Managed Disks using the snapshot Id
#Note that managed disk will be created in the same location as the snapshot
#To change the location, add the --location parameter
#If you're creating a Premium SSD v2 or an Ultra Disk, add "--zone $zone" to the end of the command
az disk create -g $resourceGroupName -n $diskName --source $snapshotId --disk-encryption-set $diskEncryptionSetID --location eastus2euap
Clean up resources
Run the following command to remove the resource group, VM, and all related resources.
az group delete --name myResourceGroupName
Sample reference
This script uses following commands to create a managed disk from a snapshot. Each command in the table links to command specific documentation.
Command
Notes
az snapshot show
Gets all the properties of a snapshot using the name and resource group properties of the snapshot. ID property is used to create managed disk.
az disk create
Creates a managed disk using snapshot ID of a managed snapshot
Next steps
Create a virtual machine by attaching a managed disk as OS disk
For more information on the Azure CLI, see Azure CLI documentation.
More virtual machine and managed disks CLI script samples can be found in the Azure Linux VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5260
Azure PowerShell Script Sample -  Create a managed disk from a VHD file in a storage account in same or different subscription
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-powershell-sample-create-managed-disk-from-vhd 

>>>
Create a managed disk from a VHD file in a storage account in a subscription - PowerShell Sample - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Create a managed disk from a VHD file in a storage account in same or different subscription with PowerShell

Article
03/31/2023

																	3 contributors
Feedback
In this article
This script creates a managed disk from a VHD file in a storage account in same or different subscription. Use this script to import a specialized (not generalized/sysprepped) VHD to managed OS disk to create a virtual machine. Also, use it to import a data VHD to managed data disk.
Don't create multiple identical managed disks from a VHD file in small amount of time. To create managed disks from a vhd file, blob snapshot of the vhd file is created and then it is used to create managed disks. Only one blob snapshot can be created in a minute that causes disk creation failures due to throttling. To avoid this throttling, create a managed snapshot from the vhd file and then use the managed snapshot to create multiple managed disks in short amount of time.
If you don't have an Azure subscription, create an Azure free account before you begin.
Sample script
<#
.DESCRIPTION
This sample demonstrates how to create a Managed Disk from a VHD file.
Create Managed Disks from VHD files in following scenarios:
1. Create a Managed OS Disk from a specialized VHD file. A specialized VHD is a copy of VHD from an exisitng VM that maintains the user accounts, applications and other state data from your original VM.
   Attach this Managed Disk as OS disk to create a new virtual machine.
2. Create a Managed data Disk from a VHD file. Attach the Managed Disk to an existing VM or attach it as data disk to create a new virtual machine.
.NOTES
1. Before you use this sample, please install the latest version of Azure PowerShell from here: http://go.microsoft.com/?linkid=9811175&clcid=0x409
2. Provide the appropriate values for each variable. Note: The angled brackets should not be included in the values you provide.
#>
#Provide the subscription Id
$subscriptionId = 'yourSubscriptionId'
#Provide the name of your resource group
$resourceGroupName ='yourResourceGroupName'
#Provide the name of the Managed Disk
$diskName = 'yourDiskName'
#Provide the size of the disks in GB. It should be greater than the VHD file size.
$diskSize = '128'
#Provide the URI of the VHD file that will be used to create Managed Disk.
# VHD file can be deleted as soon as Managed Disk is created.
# e.g. https://contosostorageaccount1.blob.core.windows.net/vhds/contoso-um-vm120170302230408.vhd
$vhdUri = 'https://contosoststorageaccount1.blob.core.windows.net/vhds/contosovhd123.vhd'
#Provide the storage type for the Managed Disk. PremiumLRS or StandardLRS.
$sku = 'PremiumLRS'
#Provide the Azure location (e.g. westus) where Managed Disk will be located.
#The location should be same as the location of the storage account where VHD file is stored.
#Get all the Azure location using command below:
#Get-AzureRmLocation
$location = 'westus'
#Set the context to the subscription Id where Managed Disk will be created
Set-AzContext -Subscription $subscriptionId
#If you're creating an OS disk, add the following lines
#Acceptable values are either Windows or Linux
#$OSType = 'yourOSType'
#Acceptable values are either V1 or V2
#$HyperVGeneration = 'yourHyperVGen'
#If you're creating an OS disk, add -HyperVGeneration and -OSType parameters
$diskConfig = New-AzDiskConfig -SkuName $sku -Location $location -DiskSizeGB $diskSize -SourceUri $vhdUri -CreateOption Import
#Create Managed disk
New-AzDisk -DiskName $diskName -Disk $diskConfig -ResourceGroupName $resourceGroupName
Script explanation
This script uses following commands to create a managed disk from a VHD in different subscription. Each command in the table links to command specific documentation.
Command
Notes
New-AzDiskConfig
Creates disk configuration that is used for disk creation. It includes storage type, location, resource ID of the storage account where the parent VHD is stored, VHD URI of the parent VHD.
New-AzDisk
Creates a disk using disk configuration, disk name, and resource group name passed as parameters.
Next steps
Create a virtual machine by attaching a managed disk as OS disk
For more information on the Azure PowerShell module, see Azure PowerShell documentation.
Additional virtual machine PowerShell script samples can be found in the Azure Windows VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3801
Azure PowerShell Script Sample - Create a managed disk from a snapshot
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-powershell-sample-create-managed-disk-from-snapshot 

>>>
Create managed disk from snapshot - PowerShell sample - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Create a managed disk from a snapshot with PowerShell

Article
03/31/2023

																	2 contributors
Feedback
In this article
This script creates a managed disk from a snapshot. Use it to restore a virtual machine from snapshots of OS and data disks. Create OS and data managed disks from respective snapshots and then create a new virtual machine by attaching managed disks. You can also restore data disks of an existing VM by attaching data disks created from snapshots.
If you don't have an Azure subscription, create an Azure free account before you begin.
Sample script
#Provide the subscription Id
$subscriptionId = 'yourSubscriptionId'
#Provide the name of your resource group
$resourceGroupName ='yourResourceGroupName'
#Provide the name of the snapshot that will be used to create Managed Disks
$snapshotName = 'yourSnapshotName'
#Provide the name of the Managed Disk
$diskName = 'yourManagedDiskName'
#Provide the size of the disks in GB. It should be greater than the VHD file size.
$diskSize = '128'
#Provide the storage type for Managed Disk. Acceptable values are Standard_LRS, Premium_LRS, PremiumV2_LRS, StandardSSD_LRS, UltraSSD_LRS, Premium_ZRS and StandardSSD_ZRS.
$storageType = 'Premium_LRS'
#Required for Premium SSD v2 and Ultra Disks
#Provide the Availability Zone you'd like the disk to be created in, default is 1
$zone=1
#Provide the Azure region (e.g. westus) where Managed Disks will be located.
#This location should be same as the snapshot location
#Get all the Azure location using command below:
#Get-AzLocation
$location = 'westus'
#Set the context to the subscription Id where Managed Disk will be created
Select-AzSubscription -SubscriptionId $SubscriptionId
$snapshot = Get-AzSnapshot -ResourceGroupName $resourceGroupName -SnapshotName $snapshotName
#If you're creating a Premium SSD v2 or an Ultra Disk, add "-Zone $zone" to the end of the command
$diskConfig = New-AzDiskConfig -SkuName $storageType -Location $location -CreateOption Copy -SourceResourceId $snapshot.Id -DiskSizeGB $diskSize
 
New-AzDisk -Disk $diskConfig -ResourceGroupName $resourceGroupName -DiskName $diskName
Script explanation
This script uses following commands to create a managed disk from a snapshot. Each command in the table links to command specific documentation.
Command
Notes
Get-AzSnapshot
Gets snapshot properties.
New-AzDiskConfig
Creates disk configuration that is used for disk creation. It includes the resource Id of the parent snapshot, location that is same as the location of parent snapshot and the storage type.
New-AzDisk
Creates a disk using disk configuration, disk name, and resource group name passed as parameters.
Next steps
Create a virtual machine from a managed disk
For more information on the Azure PowerShell module, see Azure PowerShell documentation.
Additional virtual machine PowerShell script samples can be found in the Azure Windows VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3824
Azure PowerShell Script Sample -  Create a snapshot from a VHD to create multiple identical managed disks in small amount of time
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/virtual-machines-powershell-sample-create-snapshot-from-vhd 

>>>
VHD snapshot to make many identical managed disks (Windows) - PowerShell - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Create a snapshot from a VHD to create multiple identical managed disks in small amount of time with PowerShell (Windows)

Article
03/31/2023

																	2 contributors
Feedback
In this article
This script creates a snapshot from a VHD file in a storage account in same or different subscription. Use this script to import a specialized (not generalized/sysprepped) VHD to a snapshot and then use the snapshot to create multiple identical managed disks in small amount of time. Also, use it to import a data VHD to a snapshot and then use the snapshot to create multiple managed disks in small amount of time.
If you don't have an Azure subscription, create an Azure free account before you begin.
Sample script
#Provide the subscription Id where snapshot will be created
$subscriptionId = 'yourSubscriptionId'
#Provide the name of your resource group where snapshot will be created.
$resourceGroupName ='yourResourceGroupName'
#Provide the name of the snapshot
$snapshotName = 'yourSnapshotName'
#Provide the storage type for snapshot. PremiumLRS or StandardLRS.
$storageType = 'StandardLRS'
#Provide the Azure region (e.g. westus) where snapshot will be located.
#This location should be same as the storage account location where VHD file is stored
#Get all the Azure location using command below:
#Get-AzLocation
$location = 'westus'
#Provide the URI of the VHD file (page blob) in a storage account. Please not that this is NOT the SAS URI of the storage container where VHD file is stored.
#e.g. https://contosostorageaccount1.blob.core.windows.net/vhds/contosovhd123.vhd
#Note: VHD file can be deleted as soon as Managed Disk is created.
$sourceVHDURI = 'https://yourStorageAccountName.blob.core.windows.net/vhds/yourVHDName.vhd'
#Provide the resource Id of the storage account where VHD file is stored.
#e.g. /subscriptions/6582b1g7-e212-446b-b509-314e17e1efb0/resourceGroups/MDDemo/providers/Microsoft.Storage/storageAccounts/contosostorageaccount1
#This is an optional parameter if you are creating snapshot in the same subscription
$storageAccountId = '/subscriptions/yourSubscriptionId/resourceGroups/yourResourceGroupName/providers/Microsoft.Storage/storageAccounts/yourStorageAccountName'
#Set the context to the subscription Id where Managed Disk will be created
Select-AzSubscription -SubscriptionId $SubscriptionId
$snapshotConfig = New-AzSnapshotConfig -AccountType $storageType -Location $location -CreateOption Import -StorageAccountId $storageAccountId -SourceUri $sourceVHDURI
New-AzSnapshot -Snapshot $snapshotConfig -ResourceGroupName $resourceGroupName -SnapshotName $snapshotName
Next steps
Create a managed disk from snapshot
Create a virtual machine by attaching a managed disk as OS disk
For more information on the Azure PowerShell module, see Azure PowerShell documentation.
Additional virtual machine PowerShell script samples can be found in the Azure Windows VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5311
Azure CLI Script Sample - Create a VM from a snapshot
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/create-vm-from-snapshot 

>>>
Create a VM from a snapshot - CLI Sample - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Create a virtual machine from a snapshot with CLI

Article
03/31/2023

																	5 contributors
Feedback
In this article
This script creates a virtual machine from a snapshot of an OS disk.
If you don't have an Azure subscription, create an Azure free account before you begin.
Prerequisites
Use the Bash environment in Azure Cloud Shell. For more information, see Quickstart for Bash in Azure Cloud Shell.
If you prefer to run CLI reference commands locally, install the Azure CLI. If you're running on Windows or macOS, consider running Azure CLI in a Docker container. For more information, see How to run the Azure CLI in a Docker container.
If you're using a local installation, sign in to the Azure CLI by using the az login command. To finish the authentication process, follow the steps displayed in your terminal. For other sign-in options, see Sign in with the Azure CLI.
When you're prompted, install the Azure CLI extension on first use. For more information about extensions, see Use extensions with the Azure CLI.
Run az version to find the version and dependent libraries that are installed. To upgrade to the latest version, run az upgrade.
Sample script
Launch Azure Cloud Shell
The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account.
To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also launch Cloud Shell in a separate browser tab by going to https://shell.azure.com.
When Cloud Shell opens, verify that Bash is selected for your environment. Subsequent sessions will use Azure CLI in a Bash environment, Select Copy to copy the blocks of code, paste it into the Cloud Shell, and press Enter to run it.
Sign in to Azure
Cloud Shell is automatically authenticated under the initial account signed-in with. Use the following script to sign in using a different subscription, replacing <Subscription ID> with your Azure Subscription ID.  If you don't have an Azure subscription, create an Azure free account before you begin.
subscription="<subscriptionId>" # add subscription here
az account set -s $subscription # ...or use 'az login'
For more information, see set active subscription or log in interactively
Run the script
#Provide the subscription Id of the subscription where you want to create Managed Disks
subscriptionId="<subscriptionId>"
#Provide the name of your resource group
resourceGroupName=myResourceGroupName
#Provide the name of the snapshot that will be used to create Managed Disks
snapshotName=mySnapshotName
#Provide the name of the Managed Disk
osDiskName=myOSDiskName
#Provide the size of the disks in GB. It should be greater than the VHD file size.
diskSize=128
#Provide the storage type for Managed Disk. Premium_LRS or Standard_LRS.
storageType=Premium_LRS
#Provide the OS type
osType=linux
#Provide the name of the virtual machine
virtualMachineName=myVirtualMachineName
#Set the context to the subscription Id where Managed Disk will be created
az account set --subscription $subscriptionId
#Get the snapshot Id
snapshotId=$(az snapshot show --name $snapshotName --resource-group $resourceGroupName --query [id] -o tsv)
#Create a new Managed Disks using the snapshot Id
az disk create --resource-group $resourceGroupName --name $osDiskName --sku $storageType --size-gb $diskSize --source $snapshotId
#Create VM by attaching created managed disks as OS
az vm create --name $virtualMachineName --resource-group $resourceGroupName --attach-os-disk $osDiskName --os-type $osType
Clean up resources
Run the following command to remove the resource group, VM, and all related resources.
az group delete --name myResourceGroupName
Sample reference
This script uses the following commands to create a managed disk, virtual machine, and all related resources. Each command in the table links to command specific documentation.
Command
Notes
az snapshot show
Gets snapshot using snapshot name and resource group name. Id property of the returned object is used to create a managed disk.
az disk create
Creates managed disks from a snapshot using snapshot Id, disk name, storage type, and size
az vm create
Creates a VM using a managed OS disk
Next steps
For more information on the Azure CLI, see Azure CLI documentation.
Additional virtual machine CLI script samples can be found in the Azure Linux VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5098
Azure CLI Script Sample - Create a VM by attaching a managed disk as OS disk
https://learn.microsoft.com/en-us/azure/virtual-machines/scripts/create-vm-from-managed-os-disks 

>>>
Create a VM by attaching a managed disk as OS disk - CLI Sample - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Create a virtual machine using an existing managed OS disk with CLI

Article
03/31/2023

																	5 contributors
Feedback
In this article
This script creates a virtual machine by attaching an existing managed disk as OS disk. Use this script in preceding scenarios:
Create a VM from an existing managed OS disk that was copied from a managed disk in different subscription
Create a VM from an existing managed disk that was created from a specialized VHD file
Create a VM from an existing managed OS disk that was created from a snapshot
If you don't have an Azure subscription, create an Azure free account before you begin.
Prerequisites
Use the Bash environment in Azure Cloud Shell. For more information, see Quickstart for Bash in Azure Cloud Shell.
If you prefer to run CLI reference commands locally, install the Azure CLI. If you're running on Windows or macOS, consider running Azure CLI in a Docker container. For more information, see How to run the Azure CLI in a Docker container.
If you're using a local installation, sign in to the Azure CLI by using the az login command. To finish the authentication process, follow the steps displayed in your terminal. For other sign-in options, see Sign in with the Azure CLI.
When you're prompted, install the Azure CLI extension on first use. For more information about extensions, see Use extensions with the Azure CLI.
Run az version to find the version and dependent libraries that are installed. To upgrade to the latest version, run az upgrade.
Sample script
Launch Azure Cloud Shell
The Azure Cloud Shell is a free interactive shell that you can use to run the steps in this article. It has common Azure tools preinstalled and configured to use with your account.
To open the Cloud Shell, just select Try it from the upper right corner of a code block. You can also launch Cloud Shell in a separate browser tab by going to https://shell.azure.com.
When Cloud Shell opens, verify that Bash is selected for your environment. Subsequent sessions will use Azure CLI in a Bash environment, Select Copy to copy the blocks of code, paste it into the Cloud Shell, and press Enter to run it.
Sign in to Azure
Cloud Shell is automatically authenticated under the initial account signed-in with. Use the following script to sign in using a different subscription, replacing <Subscription ID> with your Azure Subscription ID.  If you don't have an Azure subscription, create an Azure free account before you begin.
subscription="<subscriptionId>" # add subscription here
az account set -s $subscription # ...or use 'az login'
For more information, see set active subscription or log in interactively
Run the script
#Provide the subscription Id
subscriptionId="<subscriptionId>"
#Provide the name of your resource group
resourceGroupName=myResourceGroupName
#Provide the name of the Managed Disk
managedDiskName=myDiskName
#Provide the OS type
osType=linux
#Provide the name of the virtual machine
virtualMachineName=myVirtualMachineName123
#Set the context to the subscription Id where Managed Disk exists and where VM will be created
az account set --subscription $subscriptionId
#Get the resource Id of the managed disk
managedDiskId=$(az disk show --name $managedDiskName --resource-group $resourceGroupName --query [id] -o tsv)
#Create VM by attaching existing managed disks as OS
az vm create --name $virtualMachineName --resource-group $resourceGroupName --attach-os-disk $managedDiskId --os-type $osType
Clean up resources
Run the following command to remove the resource group, VM, and all related resources.
az group delete --name myResourceGroupName
Sample reference
This script uses the following commands to get managed disk properties, attach a managed disk to a new VM and create a VM. Each item in the table links to command specific documentation.
Command
Notes
az disk show
Gets managed disk properties using disk name and resource group name. Id property is used to attach a managed disk to a new VM
az vm create
Creates a VM using a managed OS disk
Next steps
For more information on the Azure CLI, see Azure CLI documentation.
Additional virtual machine CLI script samples can be found in the Azure Linux VM documentation.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

10974
Learn to add a persistent data disk to your Linux VM with the Azure CLI
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/add-disk 

>>>
Add a data disk to Linux VM using the Azure CLI - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Add a disk to a Linux VM

Article
03/29/2023

																	19 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
This article shows you how to attach a persistent disk to your VM so that you can preserve your data - even if your VM is reprovisioned due to maintenance or resizing.
Attach a new disk to a VM
If you want to add a new, empty data disk on your VM, use the az vm disk attach command with the --new parameter. If your VM is in an Availability Zone, the disk is automatically created in the same zone as the VM. For more information, see Overview of Availability Zones. The following example creates a disk named myDataDisk that is 50 Gb in size:
az vm disk attach \
   -g myResourceGroup \
   --vm-name myVM \
   --name myDataDisk \
   --new \
   --size-gb 50
Lower latency
In select regions, the disk attach latency has been reduced, so you'll see an improvement of up to 15%. This is useful if you have planned/unplanned failovers between VMs, you're scaling your workload, or are running a high scale stateful workload such as Azure Kubernetes Service. However, this improvement is limited to the explicit disk attach command, az vm disk attach. You won't see the performance improvement if you call a command that may implicitly perform an attach, like az vm update. You don't need to take any action other than calling the explicit attach command to see this improvement.
Lower latency is currently available in every public region except for:
Canada Central
Central US
East US
East US 2
South Central US
West US 2
Germany North
Jio India West
North Europe
West Europe
Attach an existing disk
To attach an existing disk, find the disk ID and pass the ID to the az vm disk attach command. The following example queries for a disk named myDataDisk in myResourceGroup, then attaches it to the VM named myVM:
diskId=$(az disk show -g myResourceGroup -n myDataDisk --query 'id' -o tsv)
az vm disk attach -g myResourceGroup --vm-name myVM --name $diskId
Format and mount the disk
To partition, format, and mount your new disk so your Linux VM can use it, SSH into your VM. For more information, see How to use SSH with Linux on Azure. The following example connects to a VM with the public IP address of 10.123.123.25 with the username azureuser:
ssh azureuser@10.123.123.25
Find the disk
Once you connect to your VM, find the disk. In this example, we're using lsblk to list the disks.
lsblk -o NAME,HCTL,SIZE,MOUNTPOINT | grep -i "sd"
The output is similar to the following example:
sda     0:0:0:0      30G
├─sda1             29.9G /
├─sda14               4M
└─sda15             106M /boot/efi
sdb     1:0:1:0      14G
└─sdb1               14G /mnt
sdc     3:0:0:0      50G
Here, sdc is the disk that we want, because it's 50G. If you add multiple disks, and aren't sure which disk it's based on size alone, you can go to the VM page in the portal, select Disks, and check the LUN number for the disk under Data disks. Compare the LUN number from the portal to the last number of the HTCL portion of the output, which is the LUN. Another option is to list the contents of the /dev/disk/azure/scsi1 directory:
ls -l /dev/disk/azure/scsi1
The output should be similar to the following example:
lrwxrwxrwx 1 root root 12 Mar 28 19:41 lun0 -> ../../../sdc
Format the disk
Format the disk with parted, if the disk size is two tebibytes (TiB) or larger then you must use GPT partitioning, if it is under 2TiB, then you can use either MBR or GPT partitioning.
Note
It is recommended that you use the latest version parted that is available for your distro.
If the disk size is 2 tebibytes (TiB) or larger, you must use GPT partitioning. If disk size is under 2 TiB, then you can use either MBR or GPT partitioning.
The following example uses parted on /dev/sdc, which is where the first data disk will typically be on most VMs. Replace sdc with the correct option for your disk. We're also formatting it using the XFS filesystem.
sudo parted /dev/sdc --script mklabel gpt mkpart xfspart xfs 0% 100%
sudo partprobe /dev/sdc1
sudo mkfs.xfs /dev/sdc1
Use the partprobe utility to make sure the kernel is aware of the new partition and filesystem. Failure to use partprobe can cause the blkid or lsblk commands to not return the UUID for the new filesystem immediately.
Mount the disk
Now, create a directory to mount the file system using mkdir. The following example creates a directory at /datadrive:
sudo mkdir /datadrive
Use mount to then mount the filesystem. The following example mounts the /dev/sdc1 partition to the /datadrive mount point:
sudo mount /dev/sdc1 /datadrive
Persist the mount
To ensure that the drive is remounted automatically after a reboot, it must be added to the /etc/fstab file. It's also highly recommended that the UUID (Universally Unique Identifier) is used in /etc/fstab to refer to the drive rather than just the device name (such as, /dev/sdc1). If the OS detects a disk error during boot, using the UUID avoids the incorrect disk being mounted to a given location. Remaining data disks would then be assigned those same device IDs. To find the UUID of the new drive, use the blkid utility:
sudo blkid
The output looks similar to the following example:
/dev/sda1: LABEL="cloudimg-rootfs" UUID="11111111-1b1b-1c1c-1d1d-1e1e1e1e1e1e" TYPE="ext4" PARTUUID="1a1b1c1d-11aa-1234-1a1a1a1a1a1a"
/dev/sda15: LABEL="UEFI" UUID="BCD7-96A6" TYPE="vfat" PARTUUID="1e1g1cg1h-11aa-1234-1u1u1a1a1u1u"
/dev/sdb1: UUID="22222222-2b2b-2c2c-2d2d-2e2e2e2e2e2e" TYPE="ext4" TYPE="ext4" PARTUUID="1a2b3c4d-01"
/dev/sda14: PARTUUID="2e2g2cg2h-11aa-1234-1u1u1a1a1u1u"
/dev/sdc1: UUID="33333333-3b3b-3c3c-3d3d-3e3e3e3e3e3e" TYPE="xfs" PARTLABEL="xfspart" PARTUUID="c1c2c3c4-1234-cdef-asdf3456ghjk"
Note
Improperly editing the /etc/fstab file could result in an unbootable system. If unsure, refer to the distribution's documentation for information on how to properly edit this file. It is also recommended that a backup of the /etc/fstab file is created before editing.
Next, open the /etc/fstab file in a text editor. Add a line to the end of the file, using the UUID value for the /dev/sdc1 device that was created in the previous steps, and the mountpoint of /datadrive. Using the example from this article, the new line would look like the following:
UUID=33333333-3b3b-3c3c-3d3d-3e3e3e3e3e3e   /datadrive   xfs   defaults,nofail   1   2
When you're done editing the file, save and close the editor.
Alternatively, you can run the following command to add the disk to the /etc/fstab file:
echo "UUID=33333333-3b3b-3c3c-3d3d-3e3e3e3e3e3e   /datadrive   xfs   defaults,nofail   1   2" >> /etc/fstab
Note
Later removing a data disk without editing fstab could cause the VM to fail to boot. Most distributions provide either the nofail and/or nobootwait fstab options. These options allow a system to boot even if the disk fails to mount at boot time. Consult your distribution's documentation for more information on these parameters.
The nofail option ensures that the VM starts even if the filesystem is corrupt or the disk does not exist at boot time. Without this option, you may encounter behavior as described in Cannot SSH to Linux VM due to FSTAB errors
The Azure VM Serial Console can be used for console access to your VM if modifying fstab has resulted in a boot failure. More details are available in the Serial Console documentation.
TRIM/UNMAP support for Linux in Azure
Some Linux kernels support TRIM/UNMAP operations to discard unused blocks on the disk. This feature is primarily useful to inform Azure that deleted pages are no longer valid and can be discarded. This feature can save money on disks that are billed based on the amount of consumed storage, such as unmanaged standard disks and disk snapshots.
There are two ways to enable TRIM support in your Linux VM. As usual, consult your distribution for the recommended approach:
Use the discard mount option in /etc/fstab, for example:
UUID=33333333-3b3b-3c3c-3d3d-3e3e3e3e3e3e   /datadrive   xfs   defaults,discard   1   2
In some cases, the discard option may have performance implications. Alternatively, you can run the fstrim command manually from the command line, or add it to your crontab to run regularly:
Ubuntu
RHEL
SLES
sudo apt install util-linux
sudo fstrim /datadrive
sudo yum install util-linux
sudo fstrim /datadrive
sudo zypper in util-linux
sudo fstrim /datadrive
Troubleshooting
When adding data disks to a Linux VM, you may encounter errors if a disk does not exist at LUN 0. If you are adding a disk manually using the az vm disk attach -new command and you specify a LUN (--lun) rather than allowing the Azure platform to determine the appropriate LUN, take care that a disk already exists / will exist at LUN 0.
Consider the following example showing a snippet of the output from lsscsi:
[5:0:0:0]    disk    Msft     Virtual Disk     1.0   /dev/sdc
[5:0:0:1]    disk    Msft     Virtual Disk     1.0   /dev/sdd
The two data disks exist at LUN 0 and LUN 1 (the first column in the lsscsi output details [host:channel:target:lun]). Both disks should be accessible from within the VM. If you had manually specified the first disk to be added at LUN 1 and the second disk at LUN 2, you may not see the disks correctly from within your VM.
Note
The Azure host value is 5 in these examples, but this may vary depending on the type of storage you select.
This disk behavior is not an Azure problem, but the way in which the Linux kernel follows the SCSI specifications. When the Linux kernel scans the SCSI bus for attached devices, a device must be found at LUN 0 in order for the system to continue scanning for additional devices. As such:
Review the output of lsscsi after adding a data disk to verify that you have a disk at LUN 0.
If your disk does not show up correctly within your VM, verify a disk exists at LUN 0.
Next steps
To ensure your Linux VM is configured correctly, review the Optimize your Linux machine performance recommendations.
Expand your storage capacity by adding more disks and configure RAID for extra performance.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

9282
Use the portal to attach new or existing data disk to a Linux VM.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/attach-disk-portal 

>>>
Attach a data disk to a Linux VM - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Use the portal to attach a data disk to a Linux VM

Article
04/10/2023

																	19 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
This article shows you how to attach both new and existing disks to a Linux virtual machine through the Azure portal. You can also attach a data disk to a Windows VM in the Azure portal.
Before you attach disks to your VM, review these tips:
The size of the virtual machine controls how many data disks you can attach. For details, see Sizes for virtual machines.
Disks attached to virtual machines are actually .vhd files stored in Azure. For details, see our Introduction to managed disks.
After attaching the disk, you need to connect to the Linux VM to mount the new disk.
Find the virtual machine
Go to the Azure portal to find the VM. Search for and select Virtual machines.
Choose the VM from the list.
In the Virtual machines page, under Settings, choose Disks.
Attach a new disk
On the Disks pane, under Data disks, select Create and attach a new disk.
Enter a name for your managed disk. Review the default settings, and update the Storage type, Size (GiB), Encryption and Host caching as necessary.
When you're done, select Save at the top of the page to create the managed disk and update the VM configuration.
Attach an existing disk
On the Disks pane, under Data disks, select  Attach existing disks.
Select the drop-down menu for Disk name and select a disk from the list of available managed disks.
Select Save to attach the existing managed disk and update the VM configuration:
Connect to the Linux VM to mount the new disk
To partition, format, and mount your new disk so your Linux VM can use it, SSH into your VM. For more information, see How to use SSH with Linux on Azure. The following example connects to a VM with the public IP address of 10.123.123.25 with the username azureuser:
ssh azureuser@10.123.123.25
Find the disk
Once connected to your VM, you need to find the disk. In this example, we're using lsblk to list the disks.
lsblk -o NAME,HCTL,SIZE,MOUNTPOINT | grep -i "sd"
The output is similar to the following example:
sda     0:0:0:0      30G
├─sda1             29.9G /
├─sda14               4M
└─sda15             106M /boot/efi
sdb     1:0:1:0      14G
└─sdb1               14G /mnt
sdc     3:0:0:0       4G
In this example, the disk that was added was sdc. It's a LUN 0 and is 4GB.
For a more complex example, here's what multiple data disks look like in the portal:
In the image, you can see that there are 3 data disks: 4 GB on LUN 0, 16GB at LUN 1, and 32G at LUN 2.
Here's what that might look like using lsblk:
sda     0:0:0:0      30G
├─sda1             29.9G /
├─sda14               4M
└─sda15             106M /boot/efi
sdb     1:0:1:0      14G
└─sdb1               14G /mnt
sdc     3:0:0:0       4G
sdd     3:0:0:1      16G
sde     3:0:0:2      32G
From the output of lsblk you can see that the 4GB disk at LUN 0 is sdc, the 16GB disk at LUN 1 is sdd, and the 32G disk at LUN 2 is sde.
Prepare a new empty disk
Important
If you are using an existing disk that contains data, skip to mounting the disk.
The following instructions will delete data on the disk.
If you're attaching a new disk, you need to partition the disk.
The parted utility can be used to partition and to format a data disk.
Use the latest version parted that is available for your distro.
If the disk size is 2 tebibytes (TiB) or larger, you must use GPT partitioning. If disk size is under 2 TiB, then you can use either MBR or GPT partitioning.
The following example uses parted on /dev/sdc, which is where the first data disk will typically be on most VMs. Replace sdc with the correct option for your disk. We're also formatting it using the XFS filesystem.
sudo parted /dev/sdc --script mklabel gpt mkpart xfspart xfs 0% 100%
sudo mkfs.xfs /dev/sdc1
sudo partprobe /dev/sdc1
Use the partprobe utility to make sure the kernel is aware of the new partition and filesystem. Failure to use partprobe can cause the blkid or lslbk commands to not return the UUID for the new filesystem immediately.
Mount the disk
Create a directory to mount the file system using mkdir. The following example creates a directory at /datadrive:
sudo mkdir /datadrive
Use mount to then mount the filesystem. The following example mounts the /dev/sdc1 partition to the /datadrive mount point:
sudo mount /dev/sdc1 /datadrive
To ensure that the drive is remounted automatically after a reboot, it must be added to the /etc/fstab file. It's also highly recommended that the UUID (Universally Unique Identifier) is used in /etc/fstab to refer to the drive rather than just the device name (such as, /dev/sdc1). If the OS detects a disk error during boot, using the UUID avoids the incorrect disk being mounted to a given location. Remaining data disks would then be assigned those same device IDs. To find the UUID of the new drive, use the blkid utility:
sudo blkid
The output looks similar to the following example:
/dev/sda1: LABEL="cloudimg-rootfs" UUID="11111111-1b1b-1c1c-1d1d-1e1e1e1e1e1e" TYPE="ext4" PARTUUID="1a1b1c1d-11aa-1234-1a1a1a1a1a1a"
/dev/sda15: LABEL="UEFI" UUID="BCD7-96A6" TYPE="vfat" PARTUUID="1e1g1cg1h-11aa-1234-1u1u1a1a1u1u"
/dev/sdb1: UUID="22222222-2b2b-2c2c-2d2d-2e2e2e2e2e2e" TYPE="ext4" TYPE="ext4" PARTUUID="1a2b3c4d-01"
/dev/sda14: PARTUUID="2e2g2cg2h-11aa-1234-1u1u1a1a1u1u"
/dev/sdc1: UUID="33333333-3b3b-3c3c-3d3d-3e3e3e3e3e3e" TYPE="xfs" PARTLABEL="xfspart" PARTUUID="c1c2c3c4-1234-cdef-asdf3456ghjk"
Note
Improperly editing the /etc/fstab file could result in an unbootable system. If unsure, refer to the distribution's documentation for information on how to properly edit this file. You should create a backup of the /etc/fstab file is created before editing.
Next, open the /etc/fstab file in a text editor. Add a line to the end of the file, using the UUID value for the /dev/sdc1 device that was created in the previous steps, and the mountpoint of /datadrive. Using the example from this article, the new line would look like the following:
UUID=33333333-3b3b-3c3c-3d3d-3e3e3e3e3e3e   /datadrive   xfs   defaults,nofail   1   2
When you're done editing the file, save and close the editor.
Note
Later removing a data disk without editing fstab could cause the VM to fail to boot. Most distributions provide either the nofail and/or nobootwait fstab options. These options allow a system to boot even if the disk fails to mount at boot time. Consult your distribution's documentation for more information on these parameters.
The nofail option ensures that the VM starts even if the filesystem is corrupt or the disk does not exist at boot time. Without this option, you may encounter behavior as described in Cannot SSH to Linux VM due to FSTAB errors
Verify the disk
You can now use lsblk again to see the disk and the mountpoint.
lsblk -o NAME,HCTL,SIZE,MOUNTPOINT | grep -i "sd"
The output will look something like this:
sda     0:0:0:0      30G
├─sda1             29.9G /
├─sda14               4M
└─sda15             106M /boot/efi
sdb     1:0:1:0      14G
└─sdb1               14G /mnt
sdc     3:0:0:0       4G
└─sdc1                4G /datadrive
You can see that sdc is now mounted at /datadrive.
TRIM/UNMAP support for Linux in Azure
Some Linux kernels support TRIM/UNMAP operations to discard unused blocks on the disk. This feature is primarily useful to inform Azure that deleted pages are no longer valid and can be discarded. This feature can save money on disks that are billed based on the amount of consumed storage, such as unmanaged standard disks and disk snapshots.
There are two ways to enable TRIM support in your Linux VM. As usual, consult your distribution for the recommended approach:
Use the discard mount option in /etc/fstab, for example:
UUID=33333333-3b3b-3c3c-3d3d-3e3e3e3e3e3e   /datadrive   xfs   defaults,discard   1   2
In some cases, the discard option may have performance implications. Alternatively, you can run the fstrim command manually from the command line, or add it to your crontab to run regularly:
Ubuntu
RHEL
SUSE
sudo apt-get install util-linux
sudo fstrim /datadrive
sudo yum install util-linux
sudo fstrim /datadrive
sudo zypper install util-linux
sudo fstrim /datadrive
Next steps
For more information, and to help troubleshoot disk issues, see Troubleshoot Linux VM device name changes.
You can also attach a data disk using the Azure CLI.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5765
How to attach a new or existing data disk to a Windows VM using PowerShell with the Resource Manager deployment model.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/attach-disk-ps 

>>>
Attach a data disk to a Windows VM in Azure by using PowerShell - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Attach a data disk to a Windows VM with PowerShell

Article
08/10/2022

																	16 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs ✔️ Flexible scale sets
This article shows you how to attach both new and existing disks to a Windows virtual machine by using PowerShell.
First, review these tips:
The size of the virtual machine controls how many data disks you can attach. For more information, see Sizes for virtual machines.
To use premium SSDs, you'll need a premium storage-enabled VM type, like the DS-series or GS-series virtual machine.
This article uses PowerShell within the Azure Cloud Shell, which is constantly updated to the latest version. To open the Cloud Shell, select Try it from the top of any code block.
Lower latency
In select regions, the disk attach latency has been reduced, so you'll see an improvement of up to 15%. This is useful if you have planned/unplanned failovers between VMs, you're scaling your workload, or are running a high scale stateful workload such as Azure Kubernetes Service. However, this improvement is limited to the explicit disk attach command, Add-AzVMDataDisk. You won't see the performance improvement if you call a command that may implicitly perform an attach, like Update-AzVM. You don't need to take any action other than calling the explicit attach command to see this improvement.
Lower latency is currently available in every public region except for:
Canada Central
Central US
East US
East US 2
South Central US
West US 2
Germany North
Jio India West
North Europe
West Europe
Add an empty data disk to a virtual machine
This example shows how to add an empty data disk to an existing virtual machine.
Using managed disks
$rgName = 'myResourceGroup'
$vmName = 'myVM'
$location = 'East US'
$storageType = 'Premium_LRS'
$dataDiskName = $vmName + '_datadisk1'
$diskConfig = New-AzDiskConfig -SkuName $storageType -Location $location -CreateOption Empty -DiskSizeGB 128
$dataDisk1 = New-AzDisk -DiskName $dataDiskName -Disk $diskConfig -ResourceGroupName $rgName
$vm = Get-AzVM -Name $vmName -ResourceGroupName $rgName
$vm = Add-AzVMDataDisk -VM $vm -Name $dataDiskName -CreateOption Attach -ManagedDiskId $dataDisk1.Id -Lun 1
Update-AzVM -VM $vm -ResourceGroupName $rgName
Using managed disks in an Availability Zone
To create a disk in an Availability Zone, use New-AzDiskConfig with the -Zone parameter. The following example creates a disk in zone 1.
$rgName = 'myResourceGroup'
$vmName = 'myVM'
$location = 'East US 2'
$storageType = 'Premium_LRS'
$dataDiskName = $vmName + '_datadisk1'
$diskConfig = New-AzDiskConfig -SkuName $storageType -Location $location -CreateOption Empty -DiskSizeGB 128 -Zone 1
$dataDisk1 = New-AzDisk -DiskName $dataDiskName -Disk $diskConfig -ResourceGroupName $rgName
$vm = Get-AzVM -Name $vmName -ResourceGroupName $rgName
$vm = Add-AzVMDataDisk -VM $vm -Name $dataDiskName -CreateOption Attach -ManagedDiskId $dataDisk1.Id -Lun 1
Update-AzVM -VM $vm -ResourceGroupName $rgName
Initialize the disk
After you add an empty disk, you'll need to initialize it. To initialize the disk, you can sign in to a VM and use disk management. If you enabled WinRM and a certificate on the VM when you created it, you can use remote PowerShell to initialize the disk. You can also use a custom script extension:
    $location = "location-name"
    $scriptName = "script-name"
    $fileName = "script-file-name"
    Set-AzVMCustomScriptExtension -ResourceGroupName $rgName -Location $locName -VMName $vmName -Name $scriptName -TypeHandlerVersion "1.4" -StorageAccountName "mystore1" -StorageAccountKey "primary-key" -FileName $fileName -ContainerName "scripts"
The script file can contain code to initialize the disks, for example:
    $disks = Get-Disk | Where partitionstyle -eq 'raw' | sort number
    $letters = 70..89 | ForEach-Object { [char]$_ }
    $count = 0
    $labels = "data1","data2"
    foreach ($disk in $disks) {
        $driveLetter = $letters[$count].ToString()
        $disk |
        Initialize-Disk -PartitionStyle MBR -PassThru |
        New-Partition -UseMaximumSize -DriveLetter $driveLetter |
        Format-Volume -FileSystem NTFS -NewFileSystemLabel $labels[$count] -Confirm:$false -Force
	$count++
    }
Attach an existing data disk to a VM
You can attach an existing managed disk to a VM as a data disk.
$rgName = "myResourceGroup"
$vmName = "myVM"
$dataDiskName = "myDisk"
$disk = Get-AzDisk -ResourceGroupName $rgName -DiskName $dataDiskName
$vm = Get-AzVM -Name $vmName -ResourceGroupName $rgName
$vm = Add-AzVMDataDisk -CreateOption Attach -Lun 0 -VM $vm -ManagedDiskId $disk.Id
Update-AzVM -VM $vm -ResourceGroupName $rgName
Next steps
You can also deploy managed disks using templates. For more information, see Using Managed Disks in Azure Resource Manager Templates or the quickstart template for deploying multiple data disks.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

2822
How to attach a managed data disk to a Windows VM by using the Azure portal.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/attach-managed-disk-portal 

>>>
Attach a managed data disk to a Windows VM - Azure - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Attach a managed data disk to a Windows VM by using the Azure portal

Article
08/10/2022

																	8 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs ✔️ Flexible scale sets
This article shows you how to attach a new managed data disk to a Windows virtual machine (VM) by using the Azure portal. The size of the VM determines how many data disks you can attach. For more information, see Sizes for virtual machines.
Add a data disk
Sign in to the Azure portal.
Search for and select Virtual machines.
Select a virtual machine from the list.
On the Virtual machine pane, select Disks.
On the Disks pane, select Create and attach a new disk.
In the drop-downs for the new disk, make the selections you want, and name the disk.
Select Save to create and attach the new data disk to the VM.
Initialize a new data disk
Connect to the VM.
Select the Windows Start menu inside the running VM and enter diskmgmt.msc in the search box. The Disk Management console opens.
Disk Management recognizes that you have a new, uninitialized disk and the Initialize Disk window appears.
Verify the new disk is selected and then select OK to initialize it.
The new disk appears as unallocated. Right-click anywhere on the disk and select New simple volume. The New Simple Volume Wizard window opens.
Proceed through the wizard, keeping all of the defaults, and when you're done select Finish.
Close Disk Management.
A pop-up window appears notifying you that you need to format the new disk before you can use it. Select Format disk.
In the Format new disk window, check the settings, and then select Start.
A warning appears notifying you that formatting the disks erases all of the data. Select OK.
When the formatting is complete, select OK.
Next steps
You can also attach a data disk by using PowerShell.
If your application needs to use the D: drive to store data, you can change the drive letter of the Windows temporary disk.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3905
Describes how to change drive letters for a Windows VM so that you can use the D: drive as a data drive.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/change-drive-letter 

>>>
Make the D: drive of a VM a data disk  - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Use the D: drive as a data drive on a Windows VM

Article
08/08/2022

																	7 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs
If your application needs to use the D drive to store data, follow these instructions to use a different drive letter for the temporary disk. Never use the temporary disk to store data that you need to keep.
If you resize or Stop (Deallocate) a virtual machine, this may trigger placement of the virtual machine to a new hypervisor. A planned or unplanned maintenance event may also trigger this placement. In this scenario, the temporary disk will be reassigned to the first available drive letter. If you have an application that specifically requires the D: drive, you need to follow these steps to temporarily move the pagefile.sys, attach a new data disk and assign it the letter D and then move the pagefile.sys back to the temporary drive. Once complete, Azure will not take back the D: if the VM moves to a different hypervisor.
For more information about how Azure uses the temporary disk, see Understanding the temporary drive on Microsoft Azure Virtual Machines
Attach the data disk
First, you'll need to attach the data disk to the virtual machine. To do this using the portal, see How to attach a managed data disk in the Azure portal.
Temporarily move pagefile.sys to C drive
Connect to the virtual machine.
Right-click the Start menu and select System.
In the left-hand menu, search for and select View advanced system settings.
In the Performance section, select Settings.
Select the Advanced tab.
In the Virtual memory section, select Change.
Select the C drive and then click System managed size and then click Set.
Select the D drive and then click No paging file and then click Set.
Click Apply. You will get a warning that the computer needs to be restarted for the changes to take affect.
Restart the virtual machine.
Change the drive letters
Once the VM restarts, log back on to the VM.
Click the Start menu and type diskmgmt.msc and hit Enter. Disk Management will start.
Right-click on D, the Temporary Storage drive, and select Change Drive Letter and Paths.
Under Drive letter, select a new drive such as T and then click OK.
Right-click on the data disk, and select Change Drive Letter and Paths.
Under Drive letter, select drive D and then click OK.
Move pagefile.sys back to the temporary storage drive
Right-click the Start menu and select System
In the left-hand menu, search for and select View advanced system settings.
In the Performance section, select Settings.
Select the Advanced tab.
In the Virtual memory section, select Change.
Select the OS drive C and click No paging file and then click Set.
Select the temporary storage drive T and then click System managed size and then click Set.
Click Apply. You will get a warning that the computer needs to be restarted for the changes to take affect.
Restart the virtual machine.
Next steps
You can increase the storage available to your virtual machine by attaching an additional data disk.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5428
Learn to detach a data disk from a virtual machine in Azure using Azure CLI or the Azure portal.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/detach-disk 

>>>
Detach a data disk from a Linux VM - Azure - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
How to detach a data disk from a Linux virtual machine

Article
04/09/2023

																	10 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
When you no longer need a data disk that's attached to a virtual machine, you can easily detach it. This removes the disk from the virtual machine, but doesn't remove it from storage. In this article, we are working with an Ubuntu LTS 16.04 distribution. If you are using a different distribution, the instructions for unmounting the disk might be different.
Warning
If you detach a disk it is not automatically deleted. If you have subscribed to Premium storage, you will continue to incur storage charges for the disk. For more information, see Pricing and Billing when using Premium Storage.
If you want to use the existing data on the disk again, you can reattach it to the same virtual machine, or another one.
Connect to the VM to unmount the disk
Before you can detach the disk using either CLI or the portal, you need to unmount the disk and removed references to if from your fstab file.
Connect to the VM. In this example, the public IP address of the VM is 10.0.1.4 with the username azureuser:
ssh azureuser@10.0.1.4
First, find the data disk that you want to detach. The following example uses dmesg to filter on SCSI disks:
dmesg | grep SCSI
The output is similar to the following example:
[    0.294784] SCSI subsystem initialized
[    0.573458] Block layer SCSI generic (bsg) driver version 0.4 loaded (major 252)
[    7.110271] sd 2:0:0:0: [sda] Attached SCSI disk
[    8.079653] sd 3:0:1:0: [sdb] Attached SCSI disk
[ 1828.162306] sd 5:0:0:0: [sdc] Attached SCSI disk
Here, sdc is the disk that we want to detach. You also should grab the UUID of the disk.
sudo -i blkid
The output looks similar to the following example:
/dev/sda1: UUID="11111111-1b1b-1c1c-1d1d-1e1e1e1e1e1e" TYPE="ext4"
/dev/sdb1: UUID="22222222-2b2b-2c2c-2d2d-2e2e2e2e2e2e" TYPE="ext4"
/dev/sdc1: UUID="33333333-3b3b-3c3c-3d3d-3e3e3e3e3e3e" TYPE="ext4"
Edit the /etc/fstab file to remove references to the disk.
Note
Improperly editing the /etc/fstab file could result in an unbootable system. If unsure, refer to the distribution's documentation for information on how to properly edit this file. It is also recommended that a backup of the /etc/fstab file is created before editing.
Open the /etc/fstab file in a text editor and remove the line containing the UUID of your disk. Using the example values in this article, the line would look like the following:
UUID=33333333-3b3b-3c3c-3d3d-3e3e3e3e3e3e   /datadrive   ext4   defaults,nofail   1   2
Save and close the file when you're done.
Next, use umount to unmount the disk. The following example unmounts the /dev/sdc1 partition from the /datadrive mount point:
sudo umount /dev/sdc1 /datadrive
Detach a data disk using Azure CLI
This example detaches the myDataDisk disk from VM named myVM in myResourceGroup.
az vm disk detach -g myResourceGroup --vm-name myVm -n myDataDisk
The disk stays in storage but is no longer attached to a virtual machine.
Lower latency
In select regions, the disk detach latency has been reduced, so you'll see an improvement of up to 15%. This is useful if you have planned/unplanned failovers between VMs, you're scaling your workload, or are running a high scale stateful workload such as Azure Kubernetes Service. However, this improvement is limited to the explicit disk detach command, az vm disk detach. You won't see the performance improvement if you call a command that may implicitly perform a detach, like az vm update.  You don't need to take any action other than calling the explicit detach command to see this improvement.
Lower latency is currently available in every public region except for:
Canada Central
Central US
East US
East US 2
South Central US
West US 2
Germany North
Jio India West
North Europe
West Europe
Detach a data disk using the portal
In the left menu, select Virtual Machines.
In the virtual machine blade, select Disks.
In the Disks blade, to the far right of the data disk that you would like to detach, select the X button, to detach the disk.
After the disk has been removed, select Save on the top of the blade.
The disk stays in storage but is no longer attached to a virtual machine. The disk is not deleted.
Next steps
If you want to reuse the data disk, you can just attach it to another VM.
If you want to delete the disk, so that you no longer incur storage costs, see Find and delete unattached Azure managed and unmanaged disks - Azure portal.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3997
Detach a data disk from a virtual machine in Azure using the Resource Manager deployment model.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/detach-disk 

>>>
Detach a data disk from a Windows VM - Azure - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
How to detach a data disk from a Windows virtual machine

Article
03/08/2023

																	13 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs ✔️ Flexible scale sets
When you no longer need a data disk that's attached to a virtual machine, you can easily detach it. This removes the disk from the virtual machine, but doesn't remove it from storage.
Warning
If you detach a disk it is not automatically deleted. If you have subscribed to Premium storage, you will continue to incur storage charges for the disk. For more information, see Pricing and Billing when using Premium Storage.
If you want to use the existing data on the disk again, you can reattach it to the same virtual machine, or another one.
Detach a data disk using PowerShell
You can hot remove a data disk using PowerShell, but make sure nothing is actively using the disk before detaching it from the VM.
In this example, we remove the disk named myDisk from the VM myVM in the myResourceGroup resource group. First you remove the disk using the Remove-AzVMDataDisk cmdlet. Then, you update the state of the virtual machine, using the Update-AzVM cmdlet, to complete the process of removing the data disk.
$VirtualMachine = Get-AzVM `
   -ResourceGroupName "myResourceGroup" `
   -Name "myVM"
Remove-AzVMDataDisk `
   -VM $VirtualMachine `
   -Name "myDisk"
Update-AzVM `
   -ResourceGroupName "myResourceGroup" `
   -VM $VirtualMachine
The disk stays in storage but is no longer attached to a virtual machine.
Lower latency
In select regions, the disk detach latency has been reduced, so you'll see an improvement of up to 15%. This is useful if you have planned/unplanned failovers between VMs, you're scaling your workload, or are running a high scale stateful workload such as Azure Kubernetes Service. However, this improvement is limited to the explicit disk detach command, Remove-AzVMDataDisk. You won't see the performance improvement if you call a command that may implicitly perform a detach, like Update-AzVM. You don't need to take any action other than calling the explicit detach command to see this improvement.
Lower latency is currently available in every public region except for:
Canada Central
Central US
East US
East US 2
South Central US
West US 2
Germany North
Jio India West
North Europe
West Europe
Detach a data disk using the portal
You can hot remove a data disk, but make sure nothing is actively using the disk before detaching it from the VM.
In the left menu, select Virtual Machines.
Select the virtual machine that has the data disk you want to detach.
Under Settings, select Disks.
In the Disks pane, to the far right of the data disk that you would like to detach, select the X button to detach.
Select Save on the top of the page to save your changes.
The disk stays in storage but is no longer attached to a virtual machine. The disk isn't deleted.
Next steps
If you want to reuse the data disk, you can just attach it to another VM.
If you want to delete the disk, so that you no longer incur storage costs, see Find and delete unattached Azure managed and unmanaged disks - Azure portal.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

25926
Learn how to expand virtual hard disks on a Linux VM with the Azure CLI.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/expand-disks 

>>>
Expand virtual hard disks on a Linux VM - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Expand virtual hard disks on a Linux VM

Article
03/12/2023

																	20 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
This article describes how to expand managed disks for a Linux virtual machine (VM). You can add data disks to provide for additional storage space, and you can also expand an existing data disk. The default virtual hard disk size for the operating system (OS) is typically 30 GB on a Linux VM in Azure. This article covers expanding either OS disks or data disks.
Warning
Always make sure that your filesystem is in a healthy state, your disk partition table type (GPT or MBR) will support the new size, and ensure your data is backed up before you perform disk expansion operations. For more information, see the Azure Backup quickstart.
Identify Azure data disk object within the operating system
In the case of expanding a data disk when there are several data disks present on the VM, it may be difficult to relate the Azure LUNs to the Linux devices.  If the OS disk needs expansion, it will be clearly labeled in the Azure portal as the OS disk.
Start by identifying the relationship between disk utilization, mount point, and device, with the df command.
df -Th
Filesystem                Type      Size  Used Avail Use% Mounted on
/dev/sda1                 xfs        97G  1.8G   95G   2% /
<truncated>
/dev/sdd1                 ext4       32G   30G  727M  98% /opt/db/data
/dev/sde1                 ext4       32G   49M   30G   1% /opt/db/log
Here we can see, for example, the /opt/db/data filesystem is nearly full, and is located on the /dev/sdd1 partition.  The output of df will show the device path regardless of whether the disk is mounted by device path or the (preferred) UUID in the fstab.  Also take note of the Type column, indicating the format of the filesystem.  This will be important later.
Now locate the LUN which correlates to /dev/sdd by examining the contents of /dev/disk/azure/scsi1.  The output of the following ls command will show that the device known as /dev/sdd within the Linux OS is located at LUN1 when looking in the Azure portal.
sudo ls -alF /dev/disk/azure/scsi1/
total 0
drwxr-xr-x. 2 root root 140 Sep  9 21:54 ./
drwxr-xr-x. 4 root root  80 Sep  9 21:48 ../
lrwxrwxrwx. 1 root root  12 Sep  9 21:48 lun0 -> ../../../sdc
lrwxrwxrwx. 1 root root  12 Sep  9 21:48 lun1 -> ../../../sdd
lrwxrwxrwx. 1 root root  13 Sep  9 21:48 lun1-part1 -> ../../../sdd1
lrwxrwxrwx. 1 root root  12 Sep  9 21:54 lun2 -> ../../../sde
lrwxrwxrwx. 1 root root  13 Sep  9 21:54 lun2-part1 -> ../../../sde1
Expand an Azure Managed Disk
Expand without downtime
You can expand your managed disks without deallocating your VM. The host cache setting of your disk doesn't change whether or not you can expand a data disk without deallocating your VM.
This feature has the following limitations:
Only supported for data disks.
If a disk is 4 TiB or less, you should deallocate your VM and detach the disk before expanding it beyond 4 TiB. If a disk is already greater than 4 TiB, you can expand it without deallocating the VM and detaching the disk.
Not supported for Ultra disks or Premium SSD v2 disks.
Not supported for shared disks.
Install and use either:
The latest Azure CLI
The latest Azure PowerShell module
The Azure portal
Or an Azure Resource Manager template with an API version that's 2021-04-01 or newer.
Not available on some classic VMs. Use this script to get a list of classic VM SKUs that support expanding without downtime.
Expand Azure Managed Disk
Make sure that you have the latest Azure CLI installed and are signed in to an Azure account by using az login.
This article requires an existing VM in Azure with at least one data disk attached and prepared. If you don't already have a VM that you can use, see Create and prepare a VM with data disks.
In the following samples, replace example parameter names such as myResourceGroup and myVM with your own values.
Important
If your disk meets the requirements in Expand without downtime, you can skip step 1 and 3.
Operations on virtual hard disks can't be performed with the VM running. Deallocate your VM with az vm deallocate. The following example deallocates the VM named myVM in the resource group named myResourceGroup:
az vm deallocate --resource-group myResourceGroup --name myVM
Note
The VM must be deallocated to expand the virtual hard disk. Stopping the VM with az vm stop doesn't release the compute resources. To release compute resources, use az vm deallocate.
View a list of managed disks in a resource group with az disk list. The following example displays a list of managed disks in the resource group named myResourceGroup:
az disk list \
    --resource-group myResourceGroup \
    --query '[*].{Name:name,Gb:diskSizeGb,Tier:accountType}' \
    --output table
Expand the required disk with az disk update. The following example expands the managed disk named myDataDisk to 200 GB:
az disk update \
    --resource-group myResourceGroup \
    --name myDataDisk \
    --size-gb 200
Note
When you expand a managed disk, the updated size is rounded up to the nearest managed disk size. For a table of the available managed disk sizes and tiers, see Azure Managed Disks Overview - Pricing and Billing.
Start your VM with az vm start. The following example starts the VM named myVM in the resource group named myResourceGroup:
az vm start --resource-group myResourceGroup --name myVM
Expand a disk partition and filesystem
Note
While there are many tools that may be used for performing the partition resizing, the tools detailed in the remainder of this document are the same tools used by certain automated processes such as cloud-init.  As described here, the  growpart tool with the gdisk package provides universal compatibility with GUID Partition Table (GPT) disks, as older versions of some tools such as fdisk did not support GPT.
Detecting a changed disk size
If a data disk was expanded without downtime using the procedure mentioned previously, the disk size won't be changed until the device is rescanned, which normally only happens during the boot process. This rescan can be called on-demand with the following procedure.  In this example we have detected using the methods in this document that the data disk is currently /dev/sda and has been resized from 256GB to 512GB.
Identify the currently recognized size on the first line of output from fdisk -l /dev/sda
sudo fdisk -l /dev/sda
Disk /dev/sda: 256 GiB, 274877906944 bytes, 536870912 sectors
Disk model: Virtual Disk
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: dos
Disk identifier: 0x43d10aad
Device     Boot Start       End   Sectors  Size Id Type
/dev/sda1        2048 536870878 536868831  256G 83 Linux
Insert a 1 character into the rescan file for this device.  Note the reference to sda, this would change if a different disk device was resized.
echo 1 | sudo tee /sys/class/block/sda/device/rescan
Verify that the new disk size has been recognized
sudo fdisk -l /dev/sda
Disk /dev/sda: 512 GiB, 549755813888 bytes, 1073741824 sectors
Disk model: Virtual Disk
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: dos
Disk identifier: 0x43d10aad
Device     Boot Start       End   Sectors  Size Id Type
/dev/sda1        2048 536870878 536868831  256G 83 Linux
The remainder of this article uses the OS disk for the examples of the procedure for increasing the size of a volume at the OS level.  If the expanded disk is a data disk, use the previous guidance for identifying the data disk device, and follow these instructions as a guideline, substituting the data disk device (for example /dev/sda), partition numbers, volume names, mount points, and filesystem formats, as necessary.
All Linux OS guidance should be viewed as generic and may apply on any distribution, but generally matches the conventions of the named marketplace publisher.  Reference the Red Hat documents for the package requirements on any distribution claiming Red Hat compatibility, such as CentOS and Oracle.
Increase the size of the OS disk
The following instructions apply to endorsed Linux distributions.
Note
Before you proceed, make a full backup copy of your VM, or at a minimum take a snapshot of your OS disk.
Ubuntu
SUSE
Red Hat/CentOS with LVM
Red Hat/CentOS without LVM
On Ubuntu 16.x and newer, the root partition of the OS disk and filesystems will be automatically expanded to utilize all free contiguous space on the root disk by cloud-init, provided there's a small bit of free space for the resize operation.  For this circumstance the sequence is simply
Increase the size of the OS disk as detailed previously
Restart the VM, and then access the VM using the root user account.
Verify that the OS disk now displays an increased file system size.
As shown in the following example, the OS disk has been resized from the portal to 100 GB. The /dev/sda1 file system mounted on / now displays 97 GB.
df -Th
Filesystem     Type      Size  Used Avail Use% Mounted on
udev           devtmpfs  314M     0  314M   0% /dev
tmpfs          tmpfs      65M  2.3M   63M   4% /run
/dev/sda1      ext4       97G  1.8G   95G   2% /
tmpfs          tmpfs     324M     0  324M   0% /dev/shm
tmpfs          tmpfs     5.0M     0  5.0M   0% /run/lock
tmpfs          tmpfs     324M     0  324M   0% /sys/fs/cgroup
/dev/sda15     vfat      105M  3.6M  101M   4% /boot/efi
/dev/sdb1      ext4       20G   44M   19G   1% /mnt
tmpfs          tmpfs      65M     0   65M   0% /run/user/1000
user@ubuntu:~#
To increase the OS disk size in SUSE 12 SP4, SUSE SLES 12 for SAP, SUSE SLES 15, and SUSE SLES 15 for SAP:
Follow the procedure above to expand the disk in the Azure infrastructure.
Access your VM as the root user by using the sudo command after logging in as another user:
sudo -i
Use the following command to install the growpart package, which will be used to resize the partition, if it isn't already present:
zypper install growpart
Use the lsblk command to find the partition mounted on the root of the file system (/). In this case, we see that partition 4 of device sda is mounted on /:
lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   48G  0 disk
├─sda1   8:1    0    2M  0 part
├─sda2   8:2    0  512M  0 part /boot/efi
├─sda3   8:3    0    1G  0 part /boot
└─sda4   8:4    0 28.5G  0 part /
sdb      8:16   0    4G  0 disk
└─sdb1   8:17   0    4G  0 part /mnt/resource
Resize the required partition by using the growpart command and the partition number determined in the preceding step:
growpart /dev/sda 4
CHANGED: partition=4 start=3151872 old: size=59762655 end=62914527 new: size=97511391 end=100663263
Run the lsblk command again to check whether the partition has been increased.
The following output shows that the /dev/sda4 partition has been resized to 46.5 GB:
lsblk
NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda      8:0    0   48G  0 disk
├─sda1   8:1    0    2M  0 part
├─sda2   8:2    0  512M  0 part /boot/efi
├─sda3   8:3    0    1G  0 part /boot
└─sda4   8:4    0 46.5G  0 part /
sdb      8:16   0    4G  0 disk
└─sdb1   8:17   0    4G  0 part /mnt/resource
Identify the type of file system on the OS disk by using the lsblk command with the -f flag:
lsblk -f
NAME   FSTYPE LABEL UUID                                 MOUNTPOINT
sda
├─sda1
├─sda2 vfat   EFI   AC67-D22D                            /boot/efi
├─sda3 xfs    BOOT  5731a128-db36-4899-b3d2-eb5ae8126188 /boot
└─sda4 xfs    ROOT  70f83359-c7f2-4409-bba5-37b07534af96 /
sdb
└─sdb1 ext4         8c4ca904-cd93-4939-b240-fb45401e2ec6 /mnt/resource
Based on the file system type, use the appropriate commands to resize the file system.
For xfs, use this command:
xfs_growfs /
Example output:
meta-data=/dev/sda4              isize=512    agcount=4, agsize=1867583 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0 rmapbt=0
         =                       reflink=0
data     =                       bsize=4096   blocks=7470331, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=3647, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 7470331 to 12188923
For ext4, use this command:
resize2fs /dev/sda4
Verify the increased file system size for df -Th by using this command:
df -Thl
Example output:
Filesystem     Type      Size  Used Avail Use% Mounted on
devtmpfs       devtmpfs  445M  4.0K  445M   1% /dev
tmpfs          tmpfs     458M     0  458M   0% /dev/shm
tmpfs          tmpfs     458M   14M  445M   3% /run
tmpfs          tmpfs     458M     0  458M   0% /sys/fs/cgroup
/dev/sda4      xfs        47G  2.2G   45G   5% /
/dev/sda3      xfs      1014M   86M  929M   9% /boot
/dev/sda2      vfat      512M  1.1M  511M   1% /boot/efi
/dev/sdb1      ext4      3.9G   16M  3.7G   1% /mnt/resource
tmpfs          tmpfs      92M     0   92M   0% /run/user/1000
tmpfs          tmpfs      92M     0   92M   0% /run/user/490
In the preceding example, we can see that the file system size for the OS disk has been increased.
Follow the procedure above to expand the disk in the Azure infrastructure.
Access your VM as the root user by using the sudo command after logging in as another user:
sudo -i
Use the lsblk command to determine which logical volume (LV) is mounted on the root of the file system (/). In this case, we see that rootvg-rootlv is mounted on /. If a different filesystem is in need of resizing, substitute the LV and mount point throughout this section.
lsblk -f
NAME                  FSTYPE      LABEL   UUID                                   MOUNTPOINT
fd0
sda
├─sda1                vfat                C13D-C339                              /boot/efi
├─sda2                xfs                 8cc4c23c-fa7b-4a4d-bba8-4108b7ac0135   /boot
├─sda3
└─sda4                LVM2_member         zx0Lio-2YsN-ukmz-BvAY-LCKb-kRU0-ReRBzh
   ├─rootvg-tmplv      xfs                 174c3c3a-9e65-409a-af59-5204a5c00550   /tmp
   ├─rootvg-usrlv      xfs                 a48dbaac-75d4-4cf6-a5e6-dcd3ffed9af1   /usr
   ├─rootvg-optlv      xfs                 85fe8660-9acb-48b8-98aa-bf16f14b9587   /opt
   ├─rootvg-homelv     xfs                 b22432b1-c905-492b-a27f-199c1a6497e7   /home
   ├─rootvg-varlv      xfs                 24ad0b4e-1b6b-45e7-9605-8aca02d20d22   /var
   └─rootvg-rootlv     xfs                 4f3e6f40-61bf-4866-a7ae-5c6a94675193   /
Check whether there's free space in the LVM volume group (VG) containing the root partition.  If there's free space, skip to step 12.
vgdisplay rootvg
--- Volume group ---
VG Name               rootvg
System ID
Format                lvm2
Metadata Areas        1
Metadata Sequence No  7
VG Access             read/write
VG Status             resizable
MAX LV                0
Cur LV                6
Open LV               6
Max PV                0
Cur PV                1
Act PV                1
VG Size               <63.02 GiB
PE Size               4.00 MiB
Total PE              16132
Alloc PE / Size       6400 / 25.00 GiB
Free  PE / Size       9732 / <38.02 GiB
VG UUID               lPUfnV-3aYT-zDJJ-JaPX-L2d7-n8sL-A9AgJb
In this example, the line Free  PE / Size shows that there's 38.02 GB free in the volume group, as the disk has already been resized.
Install the cloud-utils-growpart package to provide the growpart command, which is required to increase the size of the OS disk and the gdisk handler for GPT disk layouts  This package is preinstalled on most marketplace images
yum install cloud-utils-growpart gdisk
In RHEL/CentOS 8.x VMs you can use dnf command instead of yum.
Determine which disk and partition holds the LVM physical volume (PV) or volumes in the volume group named rootvg by using the pvscan command. Note the size and free space listed between the brackets ([ and ]).
pvscan
PV /dev/sda4   VG rootvg          lvm2 [<63.02 GiB / <38.02 GiB free]
Verify the size of the partition by using lsblk.
lsblk /dev/sda4
NAME            MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda4              8:4    0  63G  0 part
├─rootvg-tmplv  253:1    0   2G  0 lvm  /tmp
├─rootvg-usrlv  253:2    0  10G  0 lvm  /usr
├─rootvg-optlv  253:3    0   2G  0 lvm  /opt
├─rootvg-homelv 253:4    0   1G  0 lvm  /home
├─rootvg-varlv  253:5    0   8G  0 lvm  /var
└─rootvg-rootlv 253:6    0   2G  0 lvm  /
Expand the partition containing this PV using growpart, the device name, and partition number. Doing so will expand the specified partition to use all the free contiguous space on the device.
growpart /dev/sda 4
CHANGED: partition=4 start=2054144 old: size=132161536 end=134215680 new: size=199272414 end=201326558
Verify that the partition has resized to the expected size by using the lsblk command again. Notice that in the example sda4 has changed from 63G to 95G.
lsblk /dev/sda4
NAME            MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda4              8:4    0  95G  0 part
├─rootvg-tmplv  253:1    0   2G  0 lvm  /tmp
├─rootvg-usrlv  253:2    0  10G  0 lvm  /usr
├─rootvg-optlv  253:3    0   2G  0 lvm  /opt
├─rootvg-homelv 253:4    0   1G  0 lvm  /home
├─rootvg-varlv  253:5    0   8G  0 lvm  /var
└─rootvg-rootlv 253:6    0   2G  0 lvm  /
Expand the PV to use the rest of the newly expanded partition
pvresize /dev/sda4
Physical volume "/dev/sda4" changed
1 physical volume(s) resized or updated / 0 physical volume(s) not resized
Verify the new size of the PV is the expected size, comparing to original [size / free] values.
pvscan
PV /dev/sda4   VG rootvg          lvm2 [<95.02 GiB / <70.02 GiB free]
Expand the LV by the required amount, which doesn't need to be all the free space in the volume group.  In the following example, /dev/mapper/rootvg-rootlv is resized from 2 GB to 12 GB (an increase of 10 GB) through the following command. This command will also resize the file system on the LV.
lvresize -r -L +10G /dev/mapper/rootvg-rootlv
Example output:
Size of logical volume rootvg/rootlv changed from 2.00 GiB (512 extents) to 12.00 GiB (3072 extents).
Logical volume rootvg/rootlv successfully resized.
meta-data=/dev/mapper/rootvg-rootlv isize=512    agcount=4, agsize=131072 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=524288, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=2560, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 524288 to 3145728
The lvresize command automatically calls the appropriate resize command for the filesystem in the LV. Verify whether /dev/mapper/rootvg-rootlv, which is mounted on /, has an increased file system size by using the df -Th command:
Example output:
df -Th /
Filesystem                Type  Size  Used Avail Use% Mounted on
/dev/mapper/rootvg-rootlv xfs    12G   71M   12G   1% /
Note
To use the same procedure to resize any other logical volume, change the lv name in step 12.
Follow the procedure above to expand the disk in the Azure infrastructure.
Access your VM as the root user by using the sudo command after logging in as another user:
sudo -i
When the VM has restarted, perform the following steps:
Install the cloud-utils-growpart package to provide the growpart command, which is required to increase the size of the OS disk and the gdisk handler for GPT disk layouts. This package is preinstalled on most marketplace images
yum install cloud-utils-growpart gdisk
In RHEL/CentOS 8.x VMs you can use dnf command instead of yum.
Use the lsblk -f command to verify the partition and filesystem type holding the root (/) partition
lsblk -f
NAME    FSTYPE LABEL UUID                                 MOUNTPOINT
sda
├─sda1  xfs          2a7bb59d-6a71-4841-a3c6-cba23413a5d2 /boot
├─sda2  xfs          148be922-e3ec-43b5-8705-69786b522b05 /
├─sda14
└─sda15 vfat         788D-DC65                            /boot/efi
sdb
└─sdb1  ext4         923f51ff-acbd-4b91-b01b-c56140920098 /mnt/resource
For verification, start by listing the partition table of the sda disk with gdisk.  In this example, we see a 48.0 GiB disk with partition #2 sized 29.0 GiB.  The disk was expanded from 30 GB to 48 GB in the Azure portal.
gdisk -l /dev/sda
GPT fdisk (gdisk) version 0.8.10
Partition table scan:
MBR: protective
BSD: not present
APM: not present
GPT: present
Found valid GPT with protective MBR; using GPT.
Disk /dev/sda: 100663296 sectors, 48.0 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): 78CDF84D-9C8E-4B9F-8978-8C496A1BEC83
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 62914526
Partitions will be aligned on 2048-sector boundaries
Total free space is 6076 sectors (3.0 MiB)
Number  Start (sector)    End (sector)  Size       Code  Name
1         1026048         2050047   500.0 MiB   0700
2         2050048        62912511   29.0 GiB    0700
14            2048           10239   4.0 MiB     EF02
15           10240         1024000   495.0 MiB   EF00  EFI System Partition
Expand the partition for root, in this case sda2 by using the growpart command.  Using this command expands the partition to use all of the contiguous space on the disk.
growpart /dev/sda 2
CHANGED: partition=2 start=2050048 old: size=60862464 end=62912512 new: size=98613214 end=100663262
Now print the new partition table with gdisk again.  Notice that partition 2 has is now sized 47.0 GiB
gdisk -l /dev/sda
GPT fdisk (gdisk) version 0.8.10
Partition table scan:
MBR: protective
BSD: not present
APM: not present
GPT: present
Found valid GPT with protective MBR; using GPT.
Disk /dev/sda: 100663296 sectors, 48.0 GiB
Logical sector size: 512 bytes
Disk identifier (GUID): 78CDF84D-9C8E-4B9F-8978-8C496A1BEC83
Partition table holds up to 128 entries
First usable sector is 34, last usable sector is 100663262
Partitions will be aligned on 2048-sector boundaries
Total free space is 4062 sectors (2.0 MiB)
Number  Start (sector)    End (sector)  Size       Code  Name
   1         1026048         2050047   500.0 MiB   0700
   2         2050048       100663261   47.0 GiB    0700
14            2048           10239   4.0 MiB     EF02
15           10240         1024000   495.0 MiB   EF00  EFI System Partition
Expand the filesystem on the partition with xfs_growfs, which is appropriate for a standard marketplace-generated RedHat system:
xfs_growfs /
meta-data=/dev/sda2              isize=512    agcount=4, agsize=1901952 blks
         =                       sectsz=4096  attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=7607808, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal               bsize=4096   blocks=3714, version=2
         =                       sectsz=4096  sunit=1 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 7607808 to 12326651
Verify the new size is reflected with the df command
df -hl
Filesystem      Size  Used Avail Use% Mounted on
devtmpfs        452M     0  452M   0% /dev
tmpfs           464M     0  464M   0% /dev/shm
tmpfs           464M  6.8M  457M   2% /run
tmpfs           464M     0  464M   0% /sys/fs/cgroup
/dev/sda2        48G  2.1G   46G   5% /
/dev/sda1       494M   65M  430M  13% /boot
/dev/sda15      495M   12M  484M   3% /boot/efi
/dev/sdb1       3.9G   16M  3.7G   1% /mnt/resource
tmpfs            93M     0   93M   0% /run/user/1000
Expanding without downtime classic VM SKU support
If you're using a classic VM SKU, it might not support expanding disks without downtime.
Use the following PowerShell script to determine which VM SKUs it's available with:
Connect-AzAccount
$subscriptionId="yourSubID"
$location="desiredRegion"
Set-AzContext -Subscription $subscriptionId
$vmSizes=Get-AzComputeResourceSku -Location $location | where{$_.ResourceType -eq 'virtualMachines'}
foreach($vmSize in $vmSizes){
    foreach($capability in $vmSize.Capabilities)
    {
       if(($capability.Name -eq "EphemeralOSDiskSupported" -and $capability.Value -eq "True") -or ($capability.Name -eq "PremiumIO" -and $capability.Value -eq "True") -or ($capability.Name -eq "HyperVGenerations" -and $capability.Value -match "V2"))
        {
            $vmSize.Name
       }
   }
}
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

7362
Expand the size of the virtual hard disks attached to a virtual machine using Azure PowerShell in the Resource Manager deployment model.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/expand-os-disk 

>>>
Expand virtual hard disks attached to a Windows VM in an Azure - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
How to expand virtual hard disks attached to a Windows virtual machine

Article
02/08/2023

																	17 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs ✔️ Flexible scale sets
When you create a new virtual machine (VM) in a resource group by deploying an image from Azure Marketplace, the default operating system (OS) disk is usually 127 GiB (some images have smaller OS disk sizes by default). You can add data disks to your VM (the amount depends on the VM SKU you selected) and we recommend installing applications and CPU-intensive workloads on data disks. You may need to expand the OS disk if you're supporting a legacy application that installs components on the OS disk or if you're migrating a physical PC or VM from on-premises that has a larger OS disk. This article covers expanding either OS disks or data disks.
Important
Unless you use Expand without downtime, expanding a data disk requires the VM to be deallocated.
Shrinking an existing disk isn’t supported and may result in data loss.
After expanding the disks, you need to Expand the volume in the operating system to take advantage of the larger disk.
Expand without downtime
You can expand data disks without deallocating your VM. The host cache setting of your disk doesn't change whether or not you can expand a data disk without deallocating your VM.
This feature has the following limitations:
Only supported for data disks.
If a disk is 4 TiB or less, you should deallocate your VM and detach the disk before expanding it beyond 4 TiB. If a disk is already greater than 4 TiB, you can expand it without deallocating the VM and detaching the disk.
Not supported for Ultra disks or Premium SSD v2 disks.
Not supported for shared disks.
Install and use either:
The latest Azure CLI
The latest Azure PowerShell module
The Azure portal
Or an Azure Resource Manager template with an API version that's 2021-04-01 or newer.
Not available on some classic VMs. Use this script to get a list of classic VM SKUs that support expanding without downtime.
Resize a managed disk in the Azure portal
Important
If your disk meets the requirements in Expand without downtime, you can skip step 1.
In the Azure portal, go to the virtual machine in which you want to expand the disk. Select Stop to deallocate the VM.
In the left menu under Settings, select Disks.
Under Disk name, select the disk you want to expand.
In the left menu under Settings, select Size + performance.
In Size + performance, select the disk size you want.
Warning
The new size should be greater than the existing disk size. The maximum allowed is 4,095 GB for OS disks. (It's possible to expand the VHD blob beyond that size, but the OS works only with the first 4,095 GB of space.)
Select Resize at the bottom of the page.
Resize a managed disk by using PowerShell
Open your PowerShell ISE or PowerShell window in administrative mode and follow the steps below:
Sign in to your Microsoft Azure account in resource management mode and select your subscription:
Connect-AzAccount
Select-AzSubscription –SubscriptionName 'my-subscription-name'
Set your resource group name and VM name:
$rgName = 'my-resource-group-name'
$vmName = 'my-vm-name'
$diskName = 'my-disk-name'
Obtain a reference to your VM:
$vm = Get-AzVM -ResourceGroupName $rgName -Name $vmName
Important
If your disk meets the requirements in expand without downtime, you can skip step 4 and 6.
Stop the VM before resizing the disk:
Stop-AzVM -ResourceGroupName $rgName -Name $vmName
Obtain a reference to the managed OS disk. Set the size of the managed OS disk to the desired value and update the Disk:
$disk= Get-AzDisk -ResourceGroupName $rgName -DiskName $diskName
$disk.DiskSizeGB = 1023
Update-AzDisk -ResourceGroupName $rgName -Disk $disk -DiskName $disk.Name
Warning
The new size should be greater than the existing disk size. The maximum allowed is 4,095 GB for OS disks. (It is possible to expand the VHD blob beyond that size, but the OS works only with the first 4,095 GB of space.)
Updating the VM might take a few seconds. When the command finishes executing, restart the VM:
Start-AzVM -ResourceGroupName $rgName -Name $vmName
Remote into the VM, open Computer Management (or Disk Management) and expand the drive using the newly allocated space.
Expand the volume in the operating system
When you've expanded the disk for the VM, you need to go into the OS and expand the volume to encompass the new space. There are several methods for expanding a partition. This section covers connecting the VM using an RDP connection to expand the partition using Using Diskpart or Using Disk Manager.
Using DiskPart
When you've expanded the disk for the VM, you need to go into the OS and expand the volume to encompass the new space. There are several methods for expanding a partition. This section covers connecting the VM using an RDP connection to expand the partition using DiskPart.
Open an RDP connection to your VM.
Open a command prompt and type diskpart.
At the DISKPART prompt, type list volume. Make note of the volume you want to extend.
At the DISKPART prompt, type select volume <volumenumber>. This selects the volume volumenumber that you want to extend into contiguous, empty space on the same disk.
At the DISKPART prompt, type extend [size=<size>]. This extends the selected volume by size in megabytes (MB).
Using Disk Manager
Start a remote desktop session with the VM.
Open Disk Management.
Right-click on existing C: drive partition -> Extend Volume.
Follow the steps you should be able to see the disk with updated capacity:
Expanding without downtime classic VM SKU support
If you're using a classic VM SKU, it might not support expanding disks without downtime.
Use the following PowerShell script to determine which VM SKUs it's available with:
Connect-AzAccount
$subscriptionId="yourSubID"
$location="desiredRegion"
Set-AzContext -Subscription $subscriptionId
$vmSizes=Get-AzComputeResourceSku -Location $location | where{$_.ResourceType -eq 'virtualMachines'}
foreach($vmSize in $vmSizes){
    foreach($capability in $vmSize.Capabilities)
    {
       if(($capability.Name -eq "EphemeralOSDiskSupported" -and $capability.Value -eq "True") -or ($capability.Name -eq "PremiumIO" -and $capability.Value -eq "True") -or ($capability.Name -eq "HyperVGenerations" -and $capability.Value -match "V2"))
        {
            $vmSize.Name
       }
   }
}
Next steps
You can also attach disks using the Azure portal.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3804
Expand the size of an unmanaged virtual hard disks attached to a virtual machine using Azure PowerShell in the Resource Manager deployment model.
https://learn.microsoft.com/en-us/azure/virtual-machines/expand-unmanaged-disks 

>>>
Expand unmanaged disks in Azure - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Expand unmanaged virtual hard disks attached to a virtual machine

Article
08/18/2022

																	2 contributors
Feedback
In this article
This article covers how to expand unmanaged disks. To learn how to expand a managed disk, use either the Windows or Linux articles.
Applies to: ✔️ Windows VMs ✔️ Linux VMs ✔️ Flexible scale sets
When you create a new virtual machine (VM) in a resource group by deploying an image from Azure Marketplace, the default operating system (OS) drive is often 127 GB (some images have smaller OS disk sizes by default). Even though it's possible to add data disks to the VM (the number depends on the SKU you chose) and we recommend installing applications and CPU-intensive workloads on these addendum disks, often, customers need to expand the OS drive to support specific scenarios:
To support legacy applications that install components on the OS drive.
To migrate a physical PC or VM from on-premises with a larger OS drive.
Important
Resizing an OS or data disk of an Azure VM requires the VM to be deallocated.
Shrinking an existing disk isn’t supported, and can potentially result in data loss.
After expanding the disks, you need to expand the volume within the OS in either Windows or Linux to take advantage of the larger disk.
Resize an unmanaged disk by using PowerShell
Open your PowerShell ISE or PowerShell window in administrative mode and follow the steps below:
Sign in to your Microsoft Azure account in resource management mode and select your subscription:
Connect-AzAccount
Select-AzSubscription –SubscriptionName 'my-subscription-name'
Set your resource group name and VM names:
$rgName = 'my-resource-group-name'
$vmName = 'my-vm-name'
Obtain a reference to your VM:
$vm = Get-AzVM -ResourceGroupName $rgName -Name $vmName
Stop the VM before resizing the disk:
Stop-AzVM -ResourceGroupName $rgName -Name $vmName
Set the size of the unmanaged OS disk to the desired value and update the VM:
$vm.StorageProfile.OSDisk.DiskSizeGB = 1023
Update-AzVM -ResourceGroupName $rgName -VM $vm
Warning
The new size should be greater than the existing disk size. The maximum allowed is 2,048 GB for OS disks. (It's possible to expand the VHD blob beyond that size, but the OS will only be able to work with the first 2,048 GB of space.)
Update the size of any data disks you want to resize. To expand the first data disk attached to the VM, use a numeric index to obtain a reference to first attached data disk:
$vm.StorageProfile.DataDisks[0].DiskSizeGB = 1023
Similarly, you can reference other data disks attached to the VM, either by using an index or the Name property of the disk:
($vm.StorageProfile.DataDisks | Where ({$_.Name -eq 'my-second-data-disk'})).DiskSizeGB = 1023
Updating the VM might take a few seconds. When the command finishes executing, restart the VM:
Start-AzVM -ResourceGroupName $rgName -Name $vmName
Next steps
You can also attach disks using the Azure portal.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

12075
Details how to use managed and unmanaged disks in Azure Resource Manager templates for Azure VMs.
https://learn.microsoft.com/en-us/azure/virtual-machines/using-managed-disks-template-deployments 

>>>
Deploying disks with Azure Resource Manager templates - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Using disks in Azure Resource Manager Templates

Article
03/31/2023

																	5 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
This document walks through the differences between managed and unmanaged disks when using Azure Resource Manager templates to provision virtual machines. The examples help you to update existing templates that are using unmanaged Disks to managed disks. For reference, we are using the vm-simple-windows template as a guide. You can see the template using both managed Disks and a prior version using unmanaged disks if you'd like to directly compare them.
Unmanaged Disks template formatting
To begin, let's take a look at how unmanaged disks are deployed. When creating unmanaged disks, you need a storage account to hold the VHD files. You can create a new storage account or use one that already exists. This article shows you how to create a new storage account. Create a storage account resource in the resources block as shown below.
{
    "type": "Microsoft.Storage/storageAccounts",
    "apiVersion": "2018-07-01",
    "name": "[variables('storageAccountName')]",
    "location": "[resourceGroup().location]",
    "sku": {
        "name": "Standard_LRS"
    },
    "kind": "Storage",
    "properties": {}
}
Within the virtual machine object, add a dependency on the storage account to ensure that it's created before the virtual machine. Within the storageProfile section, specify the full URI of the VHD location, which references the storage account and is needed for the OS disk and any data disks.
{
    "type": "Microsoft.Compute/virtualMachines",
    "apiVersion": "2018-10-01",
    "name": "[variables('vmName')]",
    "location": "[resourceGroup().location]",
    "dependsOn": [
    "[resourceId('Microsoft.Storage/storageAccounts/', variables('storageAccountName'))]",
    "[resourceId('Microsoft.Network/networkInterfaces/', variables('nicName'))]"
    ],
    "properties": {
        "hardwareProfile": {...},
        "osProfile": {...},
        "storageProfile": {
            "imageReference": {
                "publisher": "MicrosoftWindowsServer",
                "offer": "WindowsServer",
                "sku": "[parameters('windowsOSVersion')]",
                "version": "latest"
            },
            "osDisk": {
                "name": "osdisk",
                "vhd": {
                    "uri": "[concat(reference(resourceId('Microsoft.Storage/storageAccounts/', variables('storageAccountName'))).primaryEndpoints.blob, 'vhds/osdisk.vhd')]"
                },
                "caching": "ReadWrite",
                "createOption": "FromImage"
            },
            "dataDisks": [
                {
                    "name": "datadisk1",
                    "diskSizeGB": 1023,
                    "lun": 0,
                    "vhd": {
                        "uri": "[concat(reference(resourceId('Microsoft.Storage/storageAccounts/', variables('storageAccountName'))).primaryEndpoints.blob, 'vhds/datadisk1.vhd')]"
                    },
                    "createOption": "Empty"
                }
            ]
        },
        "networkProfile": {...},
        "diagnosticsProfile": {...}
    }
}
Managed disks template formatting
With Azure Managed Disks, the disk becomes a top-level resource and no longer requires a storage account to be created by the user. Managed disks were first exposed in the 2016-04-30-preview API version, they are available in all subsequent API versions and are now the default disk type. The following sections walk through the default settings and detail how to further customize your disks.
Note
It is recommended to use an API version later than 2016-04-30-preview as there were breaking changes between 2016-04-30-preview and 2017-03-30.
Default managed disk settings
To create a VM with managed disks, you no longer need to create the storage account resource. Referencing the template example below, there are some differences from the previous unmanaged disk examples to note:
The apiVersion is a version that supports managed disks.
osDisk and dataDisks no longer refer to a specific URI for the VHD.
When deploying without specifying additional properties, the disk will use a storage type based on the size of the VM. For example, if you are using a VM size that supports premium storage (sizes with "s" in their name such as Standard_D2s_v3) then premium disks will be configured by default. You can change this by using the sku setting of the disk to specify a storage type.
If no name for the disk is specified, it takes the format of <VMName>_OsDisk_1_<randomstring> for the OS disk and <VMName>_disk<#>_<randomstring> for each data disk.
If a VM is being created from a custom image then the default settings for storage account type and disk name are retrieved from the disk properties defined in the custom image resource. These can be overridden by specifying values for these in the template.
By default, Azure disk encryption is disabled.
By default, disk caching is Read/Write for the OS disk and None for data disks.
In the example below there is still a storage account dependency, though this is only for storage of diagnostics and is not needed for disk storage.
{
    "type": "Microsoft.Compute/virtualMachines",
    "apiVersion": "2018-10-01",
    "name": "[variables('vmName')]",
    "location": "[resourceGroup().location]",
    "dependsOn": [
        "[resourceId('Microsoft.Storage/storageAccounts/', variables('storageAccountName'))]",
        "[resourceId('Microsoft.Network/networkInterfaces/', variables('nicName'))]"
    ],
    "properties": {
        "hardwareProfile": {...},
        "osProfile": {...},
        "storageProfile": {
            "imageReference": {
                "publisher": "MicrosoftWindowsServer",
                "offer": "WindowsServer",
                "sku": "[parameters('windowsOSVersion')]",
                "version": "latest"
            },
            "osDisk": {
                "createOption": "FromImage"
            },
            "dataDisks": [
                {
                    "diskSizeGB": 1023,
                    "lun": 0,
                    "createOption": "Empty"
                }
            ]
        },
        "networkProfile": {...},
        "diagnosticsProfile": {...}
    }
}
Using a top-level managed disk resource
As an alternative to specifying the disk configuration in the virtual machine object, you can create a top-level disk resource and attach it as part of the virtual machine creation. For example, you can create a disk resource as follows to use as a data disk.
{
    "type": "Microsoft.Compute/disks",
    "apiVersion": "2018-06-01",
    "name": "[concat(variables('vmName'),'-datadisk1')]",
    "location": "[resourceGroup().location]",
    "sku": {
        "name": "Standard_LRS"
    },
    "properties": {
        "creationData": {
            "createOption": "Empty"
        },
        "diskSizeGB": 1023
    }
}
Within the VM object, reference the disk object to be attached. Specifying the resource ID of the managed disk created in the managedDisk property allows the attachment of the disk as the VM is created. The apiVersion for the VM resource is set to 2017-03-30. A dependency on the disk resource is added to ensure it's successfully created before VM creation.
{
    "type": "Microsoft.Compute/virtualMachines",
    "apiVersion": "2018-10-01",
    "name": "[variables('vmName')]",
    "location": "[resourceGroup().location]",
    "dependsOn": [
        "[resourceId('Microsoft.Storage/storageAccounts/', variables('storageAccountName'))]",
        "[resourceId('Microsoft.Network/networkInterfaces/', variables('nicName'))]",
        "[resourceId('Microsoft.Compute/disks/', concat(variables('vmName'),'-datadisk1'))]"
    ],
    "properties": {
        "hardwareProfile": {...},
        "osProfile": {...},
        "storageProfile": {
            "imageReference": {
                "publisher": "MicrosoftWindowsServer",
                "offer": "WindowsServer",
                "sku": "[parameters('windowsOSVersion')]",
                "version": "latest"
            },
            "osDisk": {
                "createOption": "FromImage"
            },
            "dataDisks": [
                {
                    "lun": 0,
                    "name": "[concat(variables('vmName'),'-datadisk1')]",
                    "createOption": "attach",
                    "managedDisk": {
                        "id": "[resourceId('Microsoft.Compute/disks/', concat(variables('vmName'),'-datadisk1'))]"
                    }
                }
            ]
        },
        "networkProfile": {...},
        "diagnosticsProfile": {...}
    }
}
Create managed availability sets with VMs using managed disks
To create managed availability sets with VMs using managed disks, add the sku object to the availability set resource and set the name property to Aligned. This property ensures that the disks for each VM are sufficiently isolated from each other to avoid single points of failure. Also note that the apiVersion for the availability set resource is set to 2018-10-01.
{
    "type": "Microsoft.Compute/availabilitySets",
    "apiVersion": "2018-10-01",
    "location": "[resourceGroup().location]",
    "name": "[variables('avSetName')]",
    "properties": {
        "PlatformUpdateDomainCount": 3,
        "PlatformFaultDomainCount": 2
    },
    "sku": {
        "name": "Aligned"
    }
}
Standard SSD disks
Below are the parameters needed in the Resource Manager template to create Standard SSD Disks:
apiVersion for Microsoft.Compute must be set as 2018-04-01 (or later)
Specify managedDisk.storageAccountType as StandardSSD_LRS
The following example shows the properties.storageProfile.osDisk section for a VM that uses Standard SSD Disks:
"osDisk": {
    "osType": "Windows",
    "name": "myOsDisk",
    "caching": "ReadWrite",
    "createOption": "FromImage",
    "managedDisk": {
        "storageAccountType": "StandardSSD_LRS"
    }
}
For a complete template example of how to create a Standard SSD disk with a template, see Create a VM from a Windows Image with Standard SSD Data Disks.
Additional scenarios and customizations
To find full information on the REST API specifications, please review the create a managed disk REST API documentation. You will find additional scenarios, as well as default and acceptable values that can be submitted to the API through template deployments.
Next steps
For full templates that use managed disks visit the following Azure Quickstart Repo links.
Windows VM with managed disk
Linux VM with managed disk
Visit the Azure Managed Disks Overview document to learn more about managed disks.
Review the template reference documentation for virtual machine resources by visiting the Microsoft.Compute/virtualMachines template reference document.
Review the template reference documentation for disk resources by visiting the Microsoft.Compute/disks template reference document.
For information on how to use managed disks in Azure virtual machine scale sets, visit the Use data disks with scale sets document.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4853
Learn how to upload, download, and migrate an Azure managed disk across regions and create a snapshot of a managed disk, using the Azure Storage Explorer.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-use-storage-explorer-managed-disks 

>>>
Use Azure Storage Explorer to manage Azure managed disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Use Azure Storage Explorer to manage Azure managed disks

Article
10/22/2021

																	4 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
Azure Storage Explorer contains a rich set of features that allows you to:
Upload, download, and copy managed disks.
Create snapshots from operating system or data disk virtual hard disk.
Migrate data from on-premises to Azure.
Migrate data across Azure regions.
Prerequisites
To complete this article, you'll need:
An Azure subscription.
At least one Azure managed disk.
The latest version of Azure Storage Explorer.
If you don't have an Azure subscription, create a free account before you begin.
Connect to an Azure subscription
If your Storage Explorer isn't connected to Azure, you can't use it to manage resources. Follow the steps in this section to connect Storage Explorer to your Azure account. Afterward, you can use it to manage your disks.
Open Azure Storage Explorer and select the Connect icon in the toolbar.
In the Connect to Azure Storage dialog box, select Subscription.
Select the appropriate environment and select Next. You can also select Manage custom environments to configure and add a custom environment.
In the Sign in dialog box, enter your Azure credentials.
Select your subscription from the list and then select Open Explorer.
Upload an on-premises VHD
You can upload an on-premises virtual hard disk (VHD) file to Azure and use it to create an image. Follow the steps in this section to upload your source file.
In the Explorer pane, expand Disks and select the resource group to which you'll upload your disk.
In the resource group details pane, select Upload.
In the Upload VHD dialog box, specify your VHD source file, the name of the disk, the operating system type, the region to which you want to upload the disk, and the account type. If the region supports availability zones, you can select a zone of your choice. Select Create to begin uploading your disk.
The status of the upload will now display in Activities.
If the upload has finished and you don't see the disk in the Activities pane, select Refresh.
Download a managed disk
Follow the steps in this section to download a managed disk to an on-premises VHD. A disk's state must be Unattached before it can be downloaded.
In the Explorer pane, expand Disks and select the resource group from which you'll download your disk.
In the resource group details pane, select the disk you want to download.
Select Download and then choose where you would like to save the disk.
Select Save the begin the download. The download status will display in Activities.
Copy a managed disk
With Storage Explorer, you can copy a manged disk within or across regions. To copy a disk:
In the Explorer pane, expand the Disks dropdown and select the resource group that contains the disk you want to copy.
In the resource group details pane, select the disk you'd like to copy and select Copy.
In the Explorer pane, expand Disks and select the resource group in which you'd like to paste the disk.
Select Paste in the resource group details pane.
In the Paste Disk dialog box, fill in the values. You can also specify an availability zone in supported regions.
Select Paste to begin the disk copy. The status is displayed in Activities.
Create a snapshot
In the Explorer pane, expand Disks and select the resource group that contains the disk you want to snapshot.
In the resource group details pane, select the disk you'd like to snapshot and select Create Snapshot.
In Create Snapshot, specify the name of the snapshot and the resource group in which you'll create it. Select Create.
After the snapshot has been created, you can select Open in Portal in Activities to view the snapshot in the Azure portal.
Next steps
Create a virtual machine from a VHD by using the Azure portal
Attach a managed data disk to a Windows virtual machine by using the Azure portal
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

2573
Change the operating system disk used by an Azure virtual machine using the Azure CLI.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/os-disk-swap 

>>>
Swap between OS disks using the Azure CLI ' - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Change the OS disk used by an Azure VM using the Azure CLI

Article
08/18/2022

																	6 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
If you have an existing VM, but you want to swap the disk for a backup disk or another OS disk, you can use the Azure CLI to swap the OS disks. You don't have to delete and recreate the VM. You can even use a managed disk in another resource group, as long as it isn't already in use.
The VM does not need to be stopped\deallocated. The resource ID of the managed disk can be replaced with the resource ID of a different managed disk.
Make sure that the VM size and storage type are compatible with the disk you want to attach. For example, if the disk you want to use is in Premium Storage, then the VM needs to be capable of Premium Storage (like a DS-series size).
This article requires Azure CLI version 2.0.25 or greater. Run az --version to find the version. If you need to install or upgrade, see Install Azure CLI.
Use az disk list to get a list of the disks in your resource group.
az disk list \
   -g myResourceGroupDisk \
   --query '[*].{diskId:id}' \
   --output table
(Optional) Use az vm stop to stop\deallocate the VM before swapping the disks.
az vm stop \
   -n myVM \
   -g myResourceGroup
Use az vm update with the full resource ID of the new disk for the --osdisk parameter
az vm update \
   -g myResourceGroup \
   -n myVM \
   --os-disk /subscriptions/<subscription ID>/resourceGroups/<resource group>/providers/Microsoft.Compute/disks/myDisk
Restart the VM using az vm start.
az vm start \
   -n myVM \
   -g myResourceGroup
Next steps
To create a copy of a disk, see Snapshot a disk.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3074
Change the operating system disk used by an Azure virtual machine using PowerShell.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/os-disk-swap 

>>>
Swap OS disk for an Azure VM with PowerShell - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Change the OS disk used by an Azure VM using PowerShell

Article
08/18/2022

																	8 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets
If you have an existing VM, but you want to swap the disk for a backup disk or another OS disk, you can use Azure PowerShell to swap the OS disks. You don't have to delete and recreate the VM. You can even use a managed disk in another resource group, as long as it isn't already in use.
The VM does not need to be stopped\deallocated. The resource ID of the managed disk can be replaced with the resource ID of a different managed disk.
Make sure that the VM size and storage type are compatible with the disk you want to attach. For example, if the disk you want to use is in Premium Storage, then the VM needs to be capable of Premium Storage (like a DS-series size). Both disks must also be the same size.
And ensure that you're not mixing an un-encrypted VM with an encrypted OS disk, this is not supported. If the VM doesn't use Azure Disk Encryption, then the OS disk being swapped in shouldn't be using Azure Disk Encryption. If disks are using Disk Encryption Sets, both disks should belong to same Disk Encryption set.
Get a list of disks in a resource group using Get-AzDisk
Get-AzDisk -ResourceGroupName myResourceGroup | Format-Table -Property Name
When you have the name of the disk that you would like to use, set that as the OS disk for the VM. This example stop\deallocates the VM named myVM and assigns the disk named newDisk as the new OS disk.
# Get the VM
$vm = Get-AzVM -ResourceGroupName myResourceGroup -Name myVM
# (Optional) Stop/ deallocate the VM
Stop-AzVM -ResourceGroupName myResourceGroup -Name $vm.Name -Force
# Get the new disk that you want to swap in
$disk = Get-AzDisk -ResourceGroupName myResourceGroup -Name newDisk
# Set the VM configuration to point to the new disk
Set-AzVMOSDisk -VM $vm -ManagedDiskId $disk.Id -Name $disk.Name
# Update the VM with the new OS disk
Update-AzVM -ResourceGroupName myResourceGroup -VM $vm
# Start the VM
Start-AzVM -Name $vm.Name -ResourceGroupName myResourceGroup
Next steps
To create a copy of a disk, see Snapshot a disk.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

2780
How to determine the Azure Disks that underlay a Linux VM's guest disks.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/azure-to-guest-disk-mapping 

>>>
How to map Azure Disks to Linux VM guest disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
How to map Azure Disks to Linux VM guest disks

Article
08/18/2022

																	3 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
You may need to determine the Azure Disks that back a VM's guest disks. In some scenarios, you can compare the disk or volume size to the size of the attached Azure Disks. In scenarios where there are multiple Azure Disks of the same size attached to the VM you need to use the Logical Unit Number (LUN) of the data disks.
What is a LUN?
A Logical Unit Number (LUN) is a number that is used to identify a specific storage device. Each storage device is assigned a unique numeric identifier, starting at zero. The full path to a device is represented by the bus number, target ID number, and Logical Unit Number (LUN).
For example:
Bus Number 0, Target ID 0, LUN 3
For our exercise, you only need to use the LUN.
Finding the LUN
Below we have listed two methods for finding the LUN of a disk in Linux.
lsscsi
Connect to the VM
sudo lsscsi
The first column listed will contain the LUN, the format is [Host:Channel:Target:LUN].
Listing block devices
Connect to the VM
sudo ls -l /sys/block/*/device
The last column listed will contain the LUN, the format is [Host:Channel:Target:LUN]
Finding the LUN for the Azure Disks
You can locate the LUN for an Azure Disk using the Azure portal, Azure CLI.
Finding an Azure Disk's LUN in the Azure portal
In the Azure portal, select "Virtual Machines" to display a list of your Virtual Machines
Select the Virtual Machine
Select "Disks"
Select a data disk from the list of attached disks.
The LUN of the disk will be displayed in the disk detail pane. The LUN displayed here correlate to the LUNs that you looked up in the Guest using lsscsi, or listing the block devices.
Finding an Azure Disk's LUN using Azure CLI
az vm show -g myResourceGroup -n myVM --query "storageProfile.dataDisks"
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3392
How to determine the Azure Disks that underlay a Windows VM's guest disks.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/azure-to-guest-disk-mapping 

>>>
How to map Azure Disks to Windows VM guest disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
How to map Azure Disks to Windows VM guest disks

Article
03/08/2023

																	6 contributors
Feedback
In this article
Applies to: ✔️ Windows VMs
You may need to determine the Azure Disks that back a VM's guest disks. In some scenarios, you can compare the disk or volume size to the size of the attached Azure Disks. In scenarios where there are multiple Azure Disks of the same size attached to the VM you need to use the Logical Unit Number (LUN) of the data disks.
What is a LUN?
A Logical Unit Number (LUN) is a number that is used to identify a specific storage device. Each storage device is assigned a unique numeric identifier, starting at zero. The full path to a device is represented by the bus number, target ID number, and Logical Unit Number (LUN).
For example:
Bus Number 0, Target ID 0, LUN 3
For our exercise, you only need to use the LUN.
Finding the LUN
There are two methods to finding the LUN, which one you choose will depend on if you are using Storage Spaces or not.
Disk Management
If you are not using Storage Pools, you can use Disk Management to find the LUN.
Connect to the VM and open Disk Management
a. Right-click on the Start button and choose "Disk Management"
a. You can also type diskmgmt.msc into the Start Search box
In the lower pane, right-click any of the Disks and choose "Properties"
The LUN will be listed in the "Location" property on the "General" tab
Storage Pools
Connect to the VM and open Server Manager
Select "File and Storage Services", "Volumes", "Storage Pools"
In the bottom-right corner of Server Manager, there will be a "Physical Disks" section. The disks that make up the Storage Pool are listed here as well as the LUN for each disk.
Finding the LUN for the Azure Disks
You can locate the LUN for an Azure Disk using the Azure portal, Azure CLI, or Azure PowerShell
Finding an Azure Disk's LUN in the Azure portal
In the Azure portal, select "Virtual Machines" to display a list of your Virtual Machines
Select the Virtual Machine
Select "Disks"
Select a data disk from the list of attached disks.
The LUN of the disk will be displayed in the disk detail pane. The LUN displayed here correlates to the LUNs that were looked up in the Guest using Device Manager or Server Manager.
Finding an Azure Disk's LUN using Azure CLI or Azure PowerShell
Azure CLI
Azure PowerShell
az vm show -g myResourceGroup -n myVM --query "storageProfile.dataDisks"
$vm = Get-AzVM -ResourceGroupName myResourceGroup -Name myVM
$vm.StorageProfile.DataDisks | ft
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

4434
Securely move files to and from a Linux VM in Azure using SCP and an SSH key pair.
https://learn.microsoft.com/en-us/azure/virtual-machines/copy-files-to-vm-using-scp 

>>>
Use SCP to move files to and from a VM - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Use SCP to move files to and from a VM

Article
01/11/2023

																	5 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets
This article shows how to move files from your workstation up to an Azure VM, or from an Azure VM down to your workstation, using Secure Copy (SCP). Moving files between your workstation and a VM, quickly and securely, is critical for managing your Azure infrastructure.
For this article, you need a VM deployed in Azure with SSH enabled. You also need an SCP client for your local computer. It's built on top of SSH and included in the default shell of most Linux and Windows (10 and newer) installations.
Quick commands
Upload a file to the VM
scp file azureuser@azurehost:directory/targetfile
Download a file from the VM
scp azureuser@azurehost:directory/file targetfile
Detailed walkthrough
As examples, we move an Azure configuration file up to a VM and pull down a log file directory, both using SCP.
SSH key pair authentication
SCP uses SSH for the transport layer. SSH handles the authentication on the destination host, and it moves the file in an encrypted tunnel provided by default with SSH. For SSH authentication, usernames and passwords can be used. However, SSH public and private key authentication are recommended as a security best practice. Once SSH has authenticated the connection, SCP then begins copying the file. When you use a properly configured ~/.ssh/config and SSH public and private keys, the SCP connection can be established by just using a server name (or IP address). If you only have one SSH key, SCP looks for it in the ~/.ssh/ directory, and uses it by default to log in to the VM.
For more information on configuring your ~/.ssh/config and SSH public and private keys, see Create SSH keys.
Upload a file to a VM
For the first example, we copy an Azure configuration file up to a VM that is used to deploy automation. Because this file contains Azure API credentials, which include secrets, security is important. The encrypted tunnel provided by SSH protects the contents of the file.
The following command copies the local .azure/config file to an Azure VM with FQDN myserver.eastus.cloudapp.azure.com. If you don't have an FQDN set, you can also use the IP address of the VM. The admin user name on the Azure VM is azureuser. The file is targeted to the /home/azureuser/ directory. Substitute your own values in this command.
scp ~/.azure/config azureuser@myserver.eastus.cloudapp.com:/home/azureuser/config
Download a directory from a VM
For this example, we copy a directory of log files from the VM down to your workstation. A log file may or may not contain sensitive or secret data. However, using SCP ensures the contents of the log files are encrypted. A log directory may contain too many relevant files to copy one at a time, so downloading the whole directory is preferred in this situation. Using SCP to transfer the files is the easiest way to get the log directory and files down to your workstation while also being secure.
The following command copies files in the /home/azureuser/logs/ directory on the Azure VM to the local /tmp directory:
scp -r azureuser@myserver.eastus.cloudapp.com:/home/azureuser/logs/. /tmp/
The -r flag instructs SCP to recursively copy the files and directories from the point of the directory listed in the command.  Also notice that the command-line syntax is similar to a cp copy command.
Next steps
Manage users, SSH, and check or repair disks on Azure Linux VMs using the 'VMAccess' Extension
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5496
How to find and delete unattached Azure managed and unmanaged (VHDs/page blobs) disks by using Azure CLI.
https://learn.microsoft.com/en-us/azure/virtual-machines/linux/find-unattached-disks 

>>>
Azure CLI - Find and delete unattached managed and unmanaged disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Find and delete unattached Azure managed and unmanaged disks using the Azure CLI

Article
03/08/2023

																	7 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Flexible scale sets
When you delete a virtual machine (VM) in Azure, by default, any disks that are attached to the VM aren't deleted. This feature helps to prevent data loss due to the unintentional deletion of VMs. After a VM is deleted, you will continue to pay for unattached disks. This article shows you how to find and delete any unattached disks and reduce unnecessary costs.
Managed disks: Find and delete unattached disks
The following script looks for unattached managed disks by examining the value of the ManagedBy property. When a managed disk is attached to a VM, the ManagedBy property contains the resource ID of the VM. When a managed disk is unattached, the ManagedBy property is null. The script examines all the managed disks in an Azure subscription. When the script locates a managed disk with the ManagedBy property set to null, the script determines that the disk is unattached.
Important
First, run the script by setting the deleteUnattachedDisks variable to 0. This action lets you find and view all the unattached managed disks.
After you review all the unattached disks, run the script again and set the deleteUnattachedDisks variable to 1. This action lets you delete all the unattached managed disks.
# Set deleteUnattachedDisks=1 if you want to delete unattached Managed Disks
# Set deleteUnattachedDisks=0 if you want to see the Id of the unattached Managed Disks
deleteUnattachedDisks=0
unattachedDiskIds=$(az disk list --query '[?managedBy==`null`].[id]' -o tsv)
for id in ${unattachedDiskIds[@]}
do
    if (( $deleteUnattachedDisks == 1 ))
    then
        echo "Deleting unattached Managed Disk with Id: "$id
        az disk delete --ids $id --yes
        echo "Deleted unattached Managed Disk with Id: "$id
    else
        echo $id
    fi
done
Unmanaged disks: Find and delete unattached disks
Unmanaged disks are VHD files that are stored as page blobs in Azure storage accounts. The following script looks for unattached unmanaged disks (page blobs) by examining the value of the LeaseStatus property. When an unmanaged disk is attached to a VM, the LeaseStatus property is set to Locked. When an unmanaged disk is unattached, the LeaseStatus property is set to Unlocked. The script examines all the unmanaged disks in all the Azure storage accounts in an Azure subscription. When the script locates an unmanaged disk with a LeaseStatus property set to Unlocked, the script determines that the disk is unattached.
Important
First, run the script by setting the deleteUnattachedVHDs variable to 0. This action lets you find and view all the unattached unmanaged VHDs.
After you review all the unattached disks, run the script again and set the deleteUnattachedVHDs variable to 1. This action lets you delete all the unattached unmanaged VHDs.
# Set deleteUnattachedVHDs=1 if you want to delete unattached VHDs
# Set deleteUnattachedVHDs=0 if you want to see the details of the unattached VHDs
deleteUnattachedVHDs=0
storageAccountIds=$(az storage account list --query [].[id] -o tsv)
for id in ${storageAccountIds[@]}
do
    connectionString=$(az storage account show-connection-string --ids $id --query connectionString -o tsv)
    containers=$(az storage container list --connection-string $connectionString --query [].[name] -o tsv)
    for container in ${containers[@]}
    do
        blobs=$(az storage blob list --show-next-marker -c $container --connection-string $connectionString --query "[?properties.blobType=='PageBlob' && ends_with(name,'.vhd')].[name]" -o tsv)
        for blob in ${blobs[@]}
        do
            leaseStatus=$(az storage blob show -n $blob -c $container --connection-string $connectionString --query "properties.lease.status" -o tsv)
            if [ "$leaseStatus" == "unlocked" ]
            then
                if (( $deleteUnattachedVHDs == 1 ))
                then
                    echo "Deleting VHD: "$blob" in container: "$container" in storage account: "$id
                    az storage blob delete --delete-snapshots include  -n $blob -c $container --connection-string $connectionString
                    echo "Deleted VHD: "$blob" in container: "$container" in storage account: "$id
                else
                    echo "StorageAccountId: "$id" container: "$container" VHD: "$blob
                fi
            fi
        done
    done
done
Next steps
For more information, see Delete a storage account.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

5760
How to find and delete unattached Azure managed and unmanaged (VHDs/page blobs) disks by using Azure PowerShell.
https://learn.microsoft.com/en-us/azure/virtual-machines/windows/find-unattached-disks 

>>>
Find and delete unattached Azure managed and unmanaged disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Find and delete unattached Azure managed and unmanaged disks

Article
08/23/2021

																	12 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
When you delete a virtual machine (VM) in Azure, by default, any disks that are attached to the VM aren't deleted. This feature helps to prevent data loss due to the unintentional deletion of VMs. After a VM is deleted, you will continue to pay for unattached disks. This article shows you how to find and delete any unattached disks and reduce unnecessary costs.
Managed disks: Find and delete unattached disks
The following script looks for unattached managed disks by examining the value of the ManagedBy property. When a managed disk is attached to a VM, the ManagedBy property contains the resource ID of the VM. When a managed disk is unattached, the ManagedBy property is null. The script examines all the managed disks in an Azure subscription. When the script locates a managed disk with the ManagedBy property set to null, the script determines that the disk is unattached.
Important
First, run the script by setting the deleteUnattachedDisks variable to 0. This action lets you find and view all the unattached managed disks.
After you review all the unattached disks, run the script again and set the deleteUnattachedDisks variable to 1. This action lets you delete all the unattached managed disks.
# Set deleteUnattachedDisks=1 if you want to delete unattached Managed Disks
# Set deleteUnattachedDisks=0 if you want to see the Id of the unattached Managed Disks
$deleteUnattachedDisks=0
$managedDisks = Get-AzDisk
foreach ($md in $managedDisks) {
    # ManagedBy property stores the Id of the VM to which Managed Disk is attached to
    # If ManagedBy property is $null then it means that the Managed Disk is not attached to a VM
    if($md.ManagedBy -eq $null){
        if($deleteUnattachedDisks -eq 1){
            Write-Host "Deleting unattached Managed Disk with Id: $($md.Id)"
            $md | Remove-AzDisk -Force
            Write-Host "Deleted unattached Managed Disk with Id: $($md.Id) "
        }else{
            $md.Id
        }
    }
 }
Unmanaged disks: Find and delete unattached disks
Unmanaged disks are VHD files that are stored as page blobs in Azure storage accounts. The following script looks for unattached unmanaged disks (page blobs) by examining the value of the LeaseStatus property. When an unmanaged disk is attached to a VM, the LeaseStatus property is set to Locked. When an unmanaged disk is unattached, the LeaseStatus property is set to Unlocked. The script examines all the unmanaged disks in all the Azure storage accounts in an Azure subscription. When the script locates an unmanaged disk with a LeaseStatus property set to Unlocked, the script determines that the disk is unattached.
Important
First, run the script by setting the deleteUnattachedVHDs variable to $false. This action lets you find and view all the unattached unmanaged VHDs.
After you review all the unattached disks, run the script again and set the deleteUnattachedVHDs variable to $true. This action lets you delete all the unattached unmanaged VHDs.
# Set deleteUnattachedVHDs=$true if you want to delete unattached VHDs
# Set deleteUnattachedVHDs=$false if you want to see the Uri of the unattached VHDs
$deleteUnattachedVHDs=$false
$storageAccounts = Get-AzStorageAccount
foreach($storageAccount in $storageAccounts){
    $storageKey = (Get-AzStorageAccountKey -ResourceGroupName $storageAccount.ResourceGroupName -Name $storageAccount.StorageAccountName)[0].Value
    $context = New-AzStorageContext -StorageAccountName $storageAccount.StorageAccountName -StorageAccountKey $storageKey
    $containers = Get-AzStorageContainer -Context $context
    foreach($container in $containers){
        $blobs = Get-AzStorageBlob -Container $container.Name -Context $context
        #Fetch all the Page blobs with extension .vhd as only Page blobs can be attached as disk to Azure VMs
        $blobs | Where-Object {$_.BlobType -eq 'PageBlob' -and $_.Name.EndsWith('.vhd')} | ForEach-Object {
            #If a Page blob is not attached as disk then LeaseStatus will be unlocked
            if($_.ICloudBlob.Properties.LeaseStatus -eq 'Unlocked'){
                    if($deleteUnattachedVHDs){
                        Write-Host "Deleting unattached VHD with Uri: $($_.ICloudBlob.Uri.AbsoluteUri)"
                        $_ | Remove-AzStorageBlob -Force
                        Write-Host "Deleted unattached VHD with Uri: $($_.ICloudBlob.Uri.AbsoluteUri)"
                    }
                    else{
                        $_.ICloudBlob.Uri.AbsoluteUri
                    }
            }
        }
    }
}
Next steps
For more information, see Delete a storage account and Identify Orphaned Disks Using PowerShell
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

3043
How to find unattached Azure managed and unmanaged (VHDs/page blobs) disks by using the Azure portal.
https://learn.microsoft.com/en-us/azure/virtual-machines/disks-find-unattached-portal 

>>>
Identify unattached Azure disks - Azure portal - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Find and delete unattached Azure managed and unmanaged disks - Azure portal

Article
04/25/2022

																	3 contributors
Feedback
In this article
Applies to: ✔️ Linux VMs ✔️ Windows VMs ✔️ Flexible scale sets ✔️ Uniform scale sets
When you delete a virtual machine (VM) in Azure, by default, any disks that are attached to the VM aren't deleted. This helps to prevent data loss due to the unintentional deletion of VMs. After a VM is deleted, you will continue to pay for unattached disks. This article shows you how to find and delete any unattached disks using the Azure portal, and reduce unnecessary costs. Deletions are permanent, you will not be able to recover data once you delete a disk.
Managed disks: Find and delete unattached disks
If you have unattached managed disks and no longer need the data on them, the following process explains how to find them from the Azure portal:
Sign in to the Azure portal.
Search for and select Disks.
On the Disks blade, you are presented with a list of all your disks.
Select the disk you'd like to delete, this brings you to the individual disk's blade.
On the individual disk's blade, confirm the disk state is unattached, then select Delete.
Unmanaged disks: Find and delete unattached disks
Unmanaged disks are VHD files that are stored as page blobs in Azure storage accounts.
If you have unmanaged disks that aren't attached to a VM, no longer need the data on them, and would like to delete them, the following process explains how to do so from the Azure portal:
Sign in to the Azure portal.
Search for and select Disks (Classic).
You are presented with a list of all your unmanaged disks. Any disk that has "-" in the Attached to column is an unattached disk.
Select the unattached disk you'd like to delete, this brings up the individual disk's blade.
On that individual disk's blade, you can confirm it is unattached, since Attached to will still be -.
Select Delete.
Next steps
If you'd like an automated way of finding and deleting unattached storage accounts, see our CLI or PowerShell articles.
For more information, see Delete a storage account and Identify Orphaned Disks Using PowerShell
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

21712
Frequently asked questions about Azure IaaS Linux VM disks and premium disks (managed and unmanaged)
https://learn.microsoft.com/en-us/azure/virtual-machines/faq-for-disks 

>>>
Frequently asked questions about disks - Azure Virtual Machines | Microsoft Learn
Skip to main content
This browser is no longer supported.
Upgrade to Microsoft Edge to take advantage of the latest features, security updates, and technical support.

Download Microsoft Edge

More info about Internet Explorer and Microsoft Edge

Table of contents
Exit focus mode
Read in English
Save
Table of contents
Read in English
Save
Edit
Print
Twitter
LinkedIn
Facebook
Email
Table of contents
Frequently asked questions about Azure IaaS VM disks and managed and unmanaged premium disks

FAQ

																	6 contributors
Feedback
In this article
This article answers some frequently asked questions about Azure Managed Disks and Azure Premium SSD disks.
Managed Disks
If I create a standard managed disk from an existing VHD that's 80 GiB, how much will that cost me?
A standard managed disk created from an 80-GiB VHD is treated as the next available standard disk size, which is an S10 disk. You're charged according to the S10 disk pricing. For more information, see the pricing page.
For a standard managed disk, will I be charged for the actual size of the data on the disk or for the provisioned capacity of the disk?
You're charged based on the provisioned capacity of the disk. For more information, see the pricing page.
Can I use a VHD file in an Azure storage account to create a managed disk with a different subscription?
Yes.
Can I use a VHD file in an Azure storage account to create a managed disk in a different region?
No.
Are there limits on how many managed disks I can have?
Yes. The maximum limit is 50,000 managed disks per region and per disk type for a subscription.
Can VMs in an availability set consist of a combination of managed and unmanaged disks?
No. The VMs in an availability set must use either all managed disks or all unmanaged disks. When you create an availability set, you can choose which type of disks you want to use.
Can I create an empty managed disk?
Yes. You can create an empty disk. A managed disk can be created independently of a VM, for example, without attaching it to a VM.
What is the supported fault domain count for an availability set that uses managed disks?
Depending on the region where the availability set that uses managed disks is located, the supported fault domain count is 2 or 3.
What kind of Azure role-based access control support is available for Managed Disks?
Managed Disks supports three key default roles:
Owner: Can manage everything, including access
Contributor: Can manage everything except access
Reader: Can view everything, but can't make changes
Can I copy or export a managed disk to a private storage account?
You can generate a read-only shared access signature (SAS) URI for the managed disk and use it to copy the contents to a private storage account or on-premises storage. You can use the SAS URI using the Azure portal, Azure PowerShell, the Azure CLI, or AzCopy
Can I create a copy of my managed disk?
You can take a snapshot of a managed disk and then use the snapshot to create another managed disk. You can also create a new managed disk from an existing managed disk.
Are unmanaged disks still supported?
Yes, but they'll be retired by September 30, 2025, and as of November 18, 2022, new customer subscriptions aren't eligible to create unmanaged disks. We recommend that you use managed disks for new workloads and migrate your current workloads to managed disks.
Can I colocate unmanaged and managed disks on the same VM?
No.
Can I shrink or downsize my managed disks?
No.
Can I change the computer name property when a specialized (not created by using the System Preparation tool or generalized) operating system disk is used to provision a VM?
No. You can't update the computer name property. The new VM inherits it from the parent VM, which was used to create the operating system disk.
Where can I find sample Azure Resource Manager templates to create VMs with managed disks?
List of templates using Managed Disks
https://github.com/chagarw/MDPP
When creating a disk from a blob, is there any continually existing relationship with that source blob?
No, when the new disk is created it is a full standalone copy of that blob at that time and there is no connection between the two. If you like, once you've created the disk, the source blob may be deleted without affecting the newly created disk in any way.
Can I rename a managed or unmanaged disk after it has been created?
Managed disks can't be renamed. However, you may rename an unmanaged disk as long as it is not currently attached to a VHD or VM.
Can I use GPT partitioning on an Azure Disk?
Generation 1 images can only use GPT partitioning on data disks, not OS disks. OS disks must use the MBR partition style.
Generation 2 images can use GPT partitioning on the OS disk as well as the data disks.
What options does Azure disk reservation offer?
Azure disk reservation provides the option to purchase Premium SSDs in the specified SKUs from P30 (1 TiB) up to P80 (32 TiB) for a one-year term. There is no limitation on the minimum amount of disks necessary to purchase a disk reservation. Additionally, you can choose to pay with a single, upfront payment or monthly payments. There is no additional transactional cost applied for Premium SSD Managed Disks.
Reservations are made in the form of disks, not capacity. In other words, when you reserve a P80 (32 TiB) disk, you get a single P80 disk, you can't then divide that specific reservation up into two smaller P70 (16 TiB) disks. You can reserve as many or as few disks as you like, including two separate P70 (16 TiB) disks.
How is Azure disk reservation applied?
Disks reservation follows a model similar to reserved virtual machine (VM) instances. The difference is that a disk reservation can't be applied to different SKUs, while a VM instance can. See Save costs with Azure Reserved VM Instances for more information on VM instances.
Can I use my data storage purchased through Azure disks reservation across multiple regions?
Azure disks reservation are purchased for a specific region and SKU (like P30 in East US 2), and can't be used outside these constructs. You can always purchase an additional Azure Disks Reservation for your disk storage needs in other regions or SKUs.
Do managed disks support "single instance VM SLA"?
Yes, all disk types support single instance VM SLA.
Can I attach a disk to a VM in another region?
No. All managed disks, even shared disks, must be in the same region as the VM they are attaching to.
Snapshots
Can an encrypted incremental snapshot be copied across regions?
Yes.
Can I copy snapshots in an order other than their order of creation to another region?
No. Snapshots must be copied to other regions in creation order.
If a source incremental snapshot is deleted before a copy across regions completes, what happens?
The copy fails.
Are managed snapshots and images encrypted?
Yes. All managed snapshots and images are automatically encrypted.
What disk types support snapshots?
All disk types support some form of snapshot. For Ultra Disks and Premium SSD v2 disks, they only support incremental snapshots and have some limitations. For details, see Create an incremental snapshot for managed disks. The other disk types support both types of snapshots for all their disk sizes.
What happens if I have multiple incremental snapshots and delete one of them?
Deleting one of your incremental snapshots doesn't affect subsequent incremental snapshots. The system merges the data occupied by the first snapshot with the next snapshot under the hood to ensure that the subsequent snapshots are not impacted due to the deletion of the first snapshot.
Azure shared disks
If I have an existing disk, can I enable shared disks on it?
Compatible managed disks created with API version 2019-07-01 or newer can enable shared disks. To do this, you need to unmount the disk from all VMs that it is attached to. Then, edit the maxShares property on the disk.
If I no longer want to use a disk in shared mode, how do I disable it?
Unmount the disk from all VMs that it is attached to. Then edit the maxShare property on the disk to 1.
Can you increase the size of a shared disk?
Yes.
Ultra disks
What should I set my ultra disk throughput to?
If you are unsure what to set your disk throughput to, we recommend you start by assuming an IO size of 16 KiB and adjust the performance from there as you monitor your application. The formula is: Throughput in MB/s = # of IOPS * 16 / 1000.
I configured my disk to 40000 IOPS but I'm only seeing 12800 IOPS, why am I not seeing the performance of the disk?
In addition to the disk throttle, there is an IO throttle that gets imposed at the VM level. Ensure that the VM size you are using can support the levels that are configured on your disks. For details regarding IO limits imposed by your VM, see Sizes for virtual machines in Azure.
Can I use caching levels with an ultra disk?
No, ultra disks don't support the different caching methods that are supported on other disk types. Set the disk caching to None.
Can I attach an ultra disk to my existing VM?
Maybe, your VM has to be in a region and availability zone pair that supports Ultra disks. See getting started with ultra disks for details.
Can I use an ultra disk as the OS disk for my VM?
No, ultra Disks are only supported as data disks. You can migrate data from an existing data disk to an Ultra Disk. Attach both disks to the same VM and directly copy the data to the Ultra Disk, or utilize a third party solution for data migration.
Can I convert an existing disk to an ultra disk?
No, but you can migrate the data from an existing disk to an ultra disk. To migrate an existing disk to an ultra Disk, attach both disks to the same VM, and copy the disk's data from one disk to the other or leverage a 3rd party solution for data migration.
Can I attach an ultra disk to a VM running in an availability set?
No, this is not currently supported.
Uploading to a managed disk
Can I upload data to an existing managed disk?
No, upload can only be used during the creation of a new empty disk with the ReadyToUpload state.
Can I attach a disk to a VM while it is in an upload state?
No.
Migrate to Managed Disks
Is there any impact of migration on the managed disks performance?
Migration involves movement of the disk from one storage location to another. This is orchestrated via background copy of data, which can take several hours to complete, typically less than 24 Hrs depending on the amount of data in the disks. During that time your application can experience higher than usual read latency as some reads can get redirected to the original location, and can take longer to complete. There is no impact on write latency during this period.
What changes are required in a pre-existing Azure Backup service configuration prior/after migration to Managed Disks?
No changes are required.
Will my VM backups created via Azure Backup service before the migration continue to work?
Yes, backups work seamlessly.
What changes are required in a pre-existing Azure Disks Encryption configuration prior/after migration to managed disks?
No changes are required.
Is automated migration of an existing virtual machine scale set from unmanaged disks to managed disks supported?
No. You can create a new scale set with managed disks using the image from your old scale set with unmanaged disks.
Can I create a managed disk from a page blob snapshot taken before migrating to managed disks?
No. You can export a page blob snapshot as a page blob and then create a managed disk from the exported page blob.
Can I fail over my on-premises machines protected by Azure Site Recovery to a VM with managed disks?
Yes, you can choose to failover to a VM with Managed Disks.
Is there any impact of migration on Azure VMs protected by Azure Site Recovery via Azure to Azure replication?
No. Azure Site Recovery Azure to Azure protection for VMs with Managed Disks is available.
Can I migrate VMs with unmanaged disks that are located on storage accounts that are or were previously encrypted to managed disks?
Yes
Managed Disks and Storage Service Encryption
Is Server-side Encryption enabled by default when I create a managed disk?
Yes. Managed disks are encrypted with server-side encryption with platform managed keys.
Is the boot volume encrypted by default on a managed disk?
Yes. By default, all managed disks are encrypted, including the OS disk.
Can I disable Server-side Encryption for my managed disks?
No.
Does Azure Site Recovery support server-side encryption with customer-managed key for on-premises to Azure and Azure to Azure disaster recovery scenarios?
Yes.
Can I backup Managed Disks encrypted with server-side encryption with customer-managed key using Azure Backup service?
Yes.
Can I convert VMs with unmanaged disks that are located on storage accounts that are or were previously encrypted to managed disks?
Yes
Will an exported VHD from a managed disk or a snapshot also be encrypted?
No. But if you export a VHD to an encrypted storage account from an encrypted managed disk or snapshot, then it's encrypted.
Can I switch from Azure Disk Encryption to server-side encryption with customer-managed keys?
For Windows VMs, yes. For Linux VMs, maybe. If you encrypted the OS disk of a Linux VM with ADE, you can't disable ADE on either the OS or data disks. First disable encryption and remove the encryption extension, then make a new managed disk using the current disk as a source, and encrypt that new disk with customer-managed keys.
Can I switch from server-side encryption with customer-managed keys to Azure Disk Encryption?
Yes. First, switch your disk to use platform-managed keys, and then encrypt your current disk with Azure Disk Encryption.
Premium disks: Managed and unmanaged
If a VM uses a size series that supports Premium SSD disks, such as a DSv2, can I attach both premium and standard data disks?
Yes.
Can I deploy a VM with an unmanaged disk in the Azure portal?
Not all OS images support deploying with an unmanaged disk in the Azure portal. If your chosen image doesn't support this method of deployment, we recommend that you use managed disks for new workloads and convert your existing disk to a managed disk. If you’re unable to use managed disks, you can deploy a VM using unmanaged disks with either the Azure PowerShell module or the Azure CLI.
Can I attach both premium and standard data disks to a size series that doesn't support Premium SSD disks, such as D, Dv2, G, or F series?
No. You can attach only standard data disks to VMs that don't use a size series that supports Premium SSD disks.
Are there transaction costs to use Premium SSD disks?
There is a fixed cost for each disk size, which comes provisioned with specific limits on IOPS and throughput. The other costs are outbound bandwidth, snapshot capacity, and costs associated with on-demand bursting, if applicable. For more information, see the pricing page.
What are the limits for IOPS and throughput that I can get from the disk cache?
The combined limits for cache and local SSD for a DS series are 4,000 IOPS per core and 33 MB/s per core. The GS series offers 5,000 IOPS per core and 50 MB/s per core.
Is the local SSD supported for a VM using managed disks?
The local SSD is temporary storage that is included with a VM using managed disks. There is no extra cost for this temporary storage. You shouldn't use this local SSD to store application data because it isn't persisted in Azure Storage.
Are there any repercussions for the use of TRIM on premium disks?
There is no downside to the use of TRIM on Azure disks on either premium or standard disks.
New disk sizes
What is the largest managed disk size supported for operating system and data disks on Gen1 VMs?
The partition type that Azure supports for Gen1 operating system disks is the master boot record (MBR). Although Gen1 OS disks only support MBR the data disks support GPT. While you can allocate up to a 4 TiB OS disk, the MBR partition type can only use up to 2 TiB of this disk space for the operating system. Azure supports up to 32 TiB for managed data disks.
What is the largest Managed disk size supported for operating system and data disks on Gen2 VMs?
The partition type that Azure supports for Gen2 operating system disks is GUID Partition Table (GPT). Gen2 VMs support up to a 4 TiB OS disk. Azure supports up to 32 TiB for managed data disks.
What is the largest umanaged Disk size supported for operating system and data disks?
The partition type that Azure supports for an operating system disk using unmanaged disks is the master boot record (MBR). While you can allocate up to 4 TiB for an OS disk, the MBR partition type can only use up to 2 TiB of this disk space for the operating system. Azure supports up to 4 TiB for unmanaged data disks.
What is the largest supported page blob size?
The largest page blob size that Azure supports is 8 TiB (8,191 GiB). The maximum page blob size when attached to a VM as data or operating system disks is 4 TiB (4,095 GiB).
Are P4 and P6 disk sizes supported for unmanaged disks or page blobs?
P4 (32 GiB) and P6 (64 GiB) disk sizes are not supported as the default disk tiers for unmanaged disks and page blobs. You need to explicitly set the Blob Tier to P4 and P6 to have your disk mapped to these tiers. If you deploy an unmanaged disk or page blob with the disk size or content length less than 32 GiB or between 32 GiB to 64 GiB without setting the Blob Tier, you will continue to land on P10 with 500 IOPS and 100 MB/s and the mapped pricing tier.
If my existing premium managed disk less than 64 GiB was created before the small disk was enabled (around June 15, 2017), how is it billed?
Existing small premium disks less than 64 GiB continue to be billed according to the P10 pricing tier.
How can I switch the disk tier of small premium disks less than 64 GiB from P10 to P4 or P6?
You can take a snapshot of your small disks and then create a disk to automatically switch the pricing tier to P4 or P6 based on the provisioned size. You can also use performance tiers, see the articles for changing performance tiers with either the Azure CLI/PowerShell module or the Azure portal.
Can I resize existing managed disks from sizes fewer than 4 tebibytes (TiB) to 32 TiB?
Yes.
What are the largest disk sizes supported by Azure Backup and Azure Site Recovery service?
The largest disk size supported by Azure Backup is 32 TiB (4 TiB for encrypted disks). The largest disk size supported by Azure Site Recovery is 8 TiB. Support for the larger disks up to 32 TiB is not yet available in Azure Site Recovery.
What are the recommended VM sizes for larger disk sizes (>4 TiB) for Standard SSD and Standard HDD disks to achieve optimized disk IOPS and Bandwidth?
To achieve the disk throughput of Standard SSD and Standard HDD large disk sizes (>4 TiB) beyond 500 IOPS and 60 MB/s, we recommend you deploy a new VM from one of the following VM sizes to optimize your performance: B-series, DSv2-series, Dsv3-Series, ESv3-Series, Fs-series, Fsv2-series, M-series, GS-series, NCv2-series, NCv3-series, or Ls-series VMs. Attaching large disks to existing VMs or VMs that are not using the recommended sizes above may experience lower performance.
How can I upgrade my disks (>4 TiB) which were deployed during the larger disk sizes preview in order to get the higher IOPS & bandwidth at GA?
You can either stop and start the VM that the disk is attached to or, detach and re-attach your disk. The performance targets of larger disk sizes have been increased for both premium SSDs and standard SSDs at GA.
Do we support enabling Host Caching on all disk sizes?
Host Caching (ReadOnly and Read/Write) is supported on disk sizes less than 4 TiB. This means any disk that is provisioned up to 4095 GiB can take advantage of Host Caching. Host caching is not supported for disk sizes more than or equal to 4096 GiB. For example, a P50 premium disk provisioned at 4095 GiB can take advantage of Host caching and a P50 disk provisioned at 4096 GiB cannot take advantage of Host Caching. We recommend leveraging caching for smaller disk sizes where you can expect to observe better performance boost with data cached to the VM.
Private Links for managed disks
How can I ensure that a disk can be exported or imported only via Private Links?
Set the DiskAccessId property to an instance of a disk access object and set the NetworkAccessPolicy property to AllowPrivate.
Can I use the SAS URI of a disk or snapshot to download the underlying VHD of a VM in the same subnet as the subnet of the private endpoint associated with the disk?
Yes.
Can I use a SAS URI of a disk/snapshot to download the underlying VHD of a VM not in the same subnet as the subnet of the private endpoint not associated with the disk?
No.
What if my question isn't answered here?
If your question isn't listed here, let us know and we'll help you find an answer. You can post a question at the end of this article in the comments. To engage with the Azure Storage team and other community members about this article, use the Microsoft Q&A question page for Azure Storage.
To request features, submit your requests and ideas to the Azure Storage feedback forum.
Feedback
Submit and view feedback for
This product
This page
View all page feedback
Additional resources
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
Additional resources
In this article
Theme

Light

Dark

High contrast
Previous Versions
Blog
Contribute
Privacy
Terms of Use
Trademarks
© Microsoft 2023
<<<

