# Lsv3-series

* Article
* 01/18/2023
* 2 contributors

Feedback

## In this article

**Applies to:** âï¸ Linux VMs âï¸ Windows VMs âï¸ Flexible scale sets âï¸ Uniform scale sets

The Lsv3-series of Azure Virtual Machines (Azure VMs) features high-throughput, low latency, directly mapped local NVMe storage. These VMs run on the 3rd Generation IntelÂ® XeonÂ® Platinum 8370C (Ice Lake) processor in a [hyper-threaded configuration](https://www.intel.com/content/www/us/en/architecture-and-technology/hyper-threading/hyper-threading-technology.html). This new processor features an all-core turbo clock speed of 3.5 GHz with [IntelÂ® Turbo Boost Technology](https://www.intel.com/content/www/us/en/architecture-and-technology/turbo-boost/turbo-boost-technology.html), [IntelÂ® Advanced-Vector Extensions 512 (IntelÂ® AVX-512)](https://www.intel.com/content/www/us/en/architecture-and-technology/avx-512-overview.html) and [IntelÂ® Deep Learning Boost](https://software.intel.com/content/www/us/en/develop/topics/ai/deep-learning-boost.html).

The Lsv3-series VMs are available in sizes from 8 to 80 vCPUs. There are 8 GiB of memory allocated per vCPU, and one 1.92TB NVMe SSD device allocated per 8 vCPUs, with up to 19.2TB (10x1.92TB) available on the L80s\_v3 size.

Note

The Lsv3-series VMs are optimized to use the local disk on the node attached directly to the VM rather than using [durable data disks](disks-types). This method allows for greater IOPS and throughput for your workloads. The Lsv3, Lasv3, Lsv2, and Ls-series VMs don't support the creation of a host cache to increase the IOPS achievable by durable data disks.

The high throughput and IOPS of the local disk makes the Lsv3-series VMs ideal for NoSQL stores such as Apache Cassandra and MongoDB. These stores replicate data across multiple VMs to achieve persistence in the event of the failure of a single VM.

To learn more, see how to optimize performance on the Lsv3-series [Windows-based VMs](windows/storage-performance) or [Linux-based VMs](linux/storage-performance).

* [Premium Storage](premium-storage-performance): Supported
* [Premium Storage caching](premium-storage-performance): Not Supported
* [Live Migration](maintenance-and-updates): Not Supported
* [Memory Preserving Updates](maintenance-and-updates): Supported
* [VM Generation Support](generation-2): Generation 1 and 2
* [Accelerated Networking](../virtual-network/create-vm-accelerated-networking-cli): Supported
* [Ephemeral OS Disks](ephemeral-os-disks): Supported
* [Nested Virtualization](/en-us/virtualization/hyper-v-on-windows/user-guide/nested-virtualization): Supported

| Size | vCPU | Memory (GiB) | Temp disk (GiB) | NVMe Disks | NVMe Disk throughput (Read IOPS/MBps) | Uncached data disk throughput (IOPS/MBps) | Max burst uncached data disk throughput (IOPS/MBps) | Max Data Disks | Max NICs | Expected network bandwidth (Mbps) |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Standard\_L8s\_v3 | 8 | 64 | 80 | 1x1.92 TB | 400000/2000 | 12800/290 | 20000/1200 | 16 | 4 | 12500 |
| Standard\_L16s\_v3 | 16 | 128 | 160 | 2x1.92 TB | 800000/4000 | 25600/600 | 40000/1600 | 32 | 8 | 12500 |
| Standard\_L32s\_v3 | 32 | 256 | 320 | 4x1.92 TB | 1.5M/8000 | 51200/865 | 80000/2000 | 32 | 8 | 16000 |
| Standard\_L48s\_v3 | 48 | 384 | 480 | 6x1.92 TB | 2.2M/14000 | 76800/1315 | 80000/3000 | 32 | 8 | 24000 |
| Standard\_L64s\_v3 | 64 | 512 | 640 | 8x1.92 TB | 2.9M/16000 | 80000/1735 | 80000/3000 | 32 | 8 | 30000 |
| Standard\_L80s\_v3 | 80 | 640 | 800 | 10x1.92TB | 3.8M/20000 | 80000/2160 | 80000/3000 | 32 | 8 | 32000 |

1. **Temp disk**: Lsv3-series VMs have a standard SCSI-based temp resource disk for use by the OS paging or swap file (`D:` on Windows, `/dev/sdb` on Linux). This disk provides 80 GiB of storage, 4,000 IOPS, and 80 MBps transfer rate for every 8 vCPUs. For example, Standard\_L80s\_v3 provides 800 GiB at 40000 IOPS and 800 MBPS. This configuration ensures the NVMe drives can be fully dedicated to application use. This disk is ephemeral, and all data is lost on stop or deallocation.
2. **NVMe Disks**: NVMe disk throughput can go higher than the specified numbers. However, higher performance isn't guaranteed. Local NVMe disks are ephemeral. Data is lost on these disks if you stop or deallocate your VM.
3. **NVMe Disk encryption** Lsv3 VMs created or allocated on or after 1/1/2023 have their local NVME drives encrypted by default using hardware-based encryption with a Platform-managed key, except for the regions listed below.

Note

Central US and Qatar Central do not support Local NVME disk encryption, but will be added in the future.

4. **NVMe Disk throughput**: Hyper-V NVMe Direct technology provides unthrottled access to local NVMe drives mapped securely into the guest VM space. Lsv3 NVMe disk throughput can go higher than the specified numbers, but higher performance isn't guaranteed. To achieve maximum performance, see how to optimize performance on the Lsv3-series [Windows-based VMs](windows/storage-performance) or [Linux-based VMs](linux/storage-performance). Read/write performance varies based on IO size, drive load, and capacity utilization.
5. **Max burst uncached data disk throughput**: Lsv3-series VMs can [burst their disk performance](disk-bursting) for up to 30 minutes at a time.

Note

Lsv3-series VMs don't provide host cache for data disk as it doesn't benefit the Lsv3 workloads.

## Size table definitions

* Storage capacity is shown in units of GiB or 1024^3 bytes. When you compare disks measured in GB (1000^3 bytes) to disks measured in GiB (1024^3) remember that capacity numbers given in GiB may appear smaller. For example, 1023 GiB = 1098.4 GB.
* Disk throughput is measured in input/output operations per second (IOPS) and MBps where MBps = 10^6 bytes/sec.
* Data disks can operate in cached or uncached modes. For cached data disk operation, the host cache mode is set to **ReadOnly** or **ReadWrite**. For uncached data disk operation, the host cache mode is set to **None**.
* To learn how to get the best storage performance for your VMs, see [Virtual machine and disk performance](disks-performance).
* **Expected network bandwidth** is the maximum aggregated bandwidth allocated per VM type across all NICs, for all destinations. For more information, see [Virtual machine network bandwidth](../virtual-network/virtual-machine-network-throughput).

Upper limits aren't guaranteed. Limits offer guidance for selecting the right VM type for the intended application. Actual network performance will depend on several factors including network congestion, application loads, and network settings. For information on optimizing network throughput, see [Optimize network throughput for Azure virtual machines](../virtual-network/virtual-network-optimize-network-bandwidth). To achieve the expected network performance on Linux or Windows, you may need to select a specific version or optimize your VM. For more information, see [Bandwidth/Throughput testing (NTTTCP)](../virtual-network/virtual-network-bandwidth-testing).

## Other sizes and information

* [General purpose](sizes-general)
* [Memory optimized](sizes-memory)
* [Storage optimized](sizes-storage)
* [GPU optimized](sizes-gpu)
* [High performance compute](sizes-hpc)
* [Previous generations](sizes-previous-gen)

Pricing Calculator: [Pricing Calculator](https://azure.microsoft.com/pricing/calculator/)

More information on Disks Types: [Disk Types](disks-types#ultra-disks)

## Next steps

Learn more about how [Azure compute units (ACU)](acu) can help you compare compute performance across Azure SKUs.

## Feedback

Submit and view feedback for

[This product](https://feedback.azure.com/d365community/forum/ec2f1827-be25-ec11-b6e6-000d3a4f0f1c)
This page

[View all page feedback](https://github.com/MicrosoftDocs/azure-docs/issues)

---
